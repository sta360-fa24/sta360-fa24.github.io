[
  {
    "objectID": "labs/lab0.html",
    "href": "labs/lab0.html",
    "title": "Hello R.",
    "section": "",
    "text": "This ‘lab 0’ will introduce you to the course computing workflow. The main goal of today is to get you setup in RStudio and play around with a few fundamental skills."
  },
  {
    "objectID": "labs/lab0.html#r-and-r-studio",
    "href": "labs/lab0.html#r-and-r-studio",
    "title": "Hello R.",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file. Note: this is essentially the same as an Rmarkdown (.Rmd) file, with a couple built-in quality of life additions."
  },
  {
    "objectID": "labs/lab0.html#yaml",
    "href": "labs/lab0.html#yaml",
    "title": "Hello R.",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto or R markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nGo to file > new file, Quarto document. Input title “Lab 0”, and change the author name to your name. Select pdf output and press Create. Render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab0.html#latex",
    "href": "labs/lab0.html#latex",
    "title": "Hello R.",
    "section": "LaTeX",
    "text": "LaTeX\nAssignments in this course are not required to be written in LaTeX. You may write equations by hand and scan them as a pdf to submit to Gradescope. However, LaTeX is the typesetting system to communicate statistics and mathematics professionally. It’s worthwhile to use. Moreover, it’s fully supported within .Rmd and .qmd files.\nIf you’re using R on your local machine, you may need to install\n\nMiKTeX (if you’re using windows): https://miktex.org/\nMacTeX (if you’re using macOS): https://www.tug.org/mactex/\nTeXLive (if you’re using linux): https://tug.org/texlive/\n\nTo write a LaTeX equation within your markdown document, simply use $$ to surround blocks of math and $ to surround in-line math.\nExample: copy and paste the following and then render.\nWe can see that $\\beta_0 = 2 and \\beta_1 = 3$ is the OLS solution under our model\n\n$$\ny = \\beta_0 + \\beta_1 x\n$$\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere is no space between $ and math. Whitespace may cause the document to fail to render.\n\n\nCheck out this LaTeX cheatsheet to typeset a variety of math."
  },
  {
    "objectID": "labs/lab0.html#exercises",
    "href": "labs/lab0.html#exercises",
    "title": "Hello R.",
    "section": "Exercises",
    "text": "Exercises\nThe following exercises are designed to help you gain basic familiarity with R as well as the quirks of floating point arithmetic.\n\nFloating point algebra.\n\nDo floating point numbers obey the rules of algebra? For example, one of the rules of algebra is additive association. (x + y) + z == x + (y + z). Check if this is true in R using \\(x = 0.1\\), \\(y = 0.1\\) and \\(z = 1\\). Explain what you find.\n\nAdditional examples of floating point pecularity are provided below.\n\n# example 1\n0.2 == 0.6 / 3\n# example 2\npoint3 <- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\npoint3 == 0.3\n\nTo work around these issues, you could use all.equal() for checking the equality of two double quantities in R. What does all.equal() do?\n\n# example 1, all.equal()\nall.equal(0.2, 0.6 / 3)\n# example 2, all.equal()\npoint3 <- c(0.3, 0.4 - 0.1, 0.5 - 0.2, 0.6 - 0.3, 0.7 - 0.4)\npoint3\nall.equal(point3, rep(.3, length(point3)))\n\n\nWhat do these functions do?\n\nUse ?rnorm to read the documentation and explain the output of each of the following:\n\nrnorm(10, mean = 1, sd = 2)\npnorm(0)\ndnorm(0.5)\nqnorm(0.5)\n\nHow is dnorm(0.5) computed? Can you compute it manually?\n\nShow it numerically\n\n\\(X \\sim N(\\mu, \\sigma^2)\\) means that \\(X\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Show, using rnorm that if \\(X \\sim N(0, 1)\\) and \\(Y \\sim N(1, 2)\\) that \\(\\mathbb{E}(X + Y) = 1\\) and \\(\\mathbb{V}(X + Y) = 3\\)\n\n\n\n\nControl flow\n\n\n# for loop example\nfor (i in 1:5) {\n  cat(\"Hello\", i, \"\\n\")\n}\n\n# if else example\nx = 1\nif(x > 0) {\n  print(\"I'm positive x is greater than 0.\")\n} else {\n  print(\"I'm not so positive about x being positive\")\n}\n\nAssume there are 50 days of class. Suppose that, on any given day, there is a \\(X_i\\) probability student \\(i\\) will come to class. Every day you come to class, you obtain Y points towards your final grade. Every day that you don’t come to class, you obtain Z points towards your final grade.\nAssume \\(Y \\sim Uniform(1.9, 2)\\) and \\(Z \\sim Uniform(1, 2)\\).\nAssume student A has a 95% chance of coming to class any given day (X = 0.95) and student B has a 70% of coming to class any given day (X = 0.7). While there are more efficient ways to do this, practice using a for loop, a conditional if statement, rbinom and runif to simulate one possible final grade for each student."
  },
  {
    "objectID": "labs/lab0.html#style-guidelines",
    "href": "labs/lab0.html#style-guidelines",
    "title": "Hello R.",
    "section": "Style guidelines",
    "text": "Style guidelines\nAlthough coding is not the primary focus of this course, there are a short list below of fundamental principles we will follow. Note: some of these stylistic principles may not be followed in the text!\nFirst, it’s easy to write code that runs off the page when you render to pdf. This happens when you write more than 80 characters in a single line of code. To ensure this doesn’t happen, make sure your code doesn’t have 80 characters in a single line. To enable a vertical line in the RStudio IDE that helps you visually see the limit, go to Tools > Global Options > Code > Display > Show margin > 80. This will enable a vertical line in your .qmd files that shows you where the 80 character cutoff is for code chunks. Instructions may vary slightly for local installs of RStudio.\n\nAll binary operators should be surrounded by space. For example x + y is appropriate. x+y is not.\nAny and all pipes %>% or |> as well as ggplot layers + should be followed by a new line.\nYou should be consistent with stylistic choices, e.g. only use 1 of = vs <- and %>% vs |>\nYour name should be at the top (in the YAML) of each document under “author:”\n\nIf you have any questions about style, please ask a member of the teaching team."
  },
  {
    "objectID": "chapterSummaries.html",
    "href": "chapterSummaries.html",
    "title": "Chapter summaries",
    "section": "",
    "text": "Axioms of probability\nFor all sets \\(F\\), \\(G\\) and \\(H\\),\n\n\\(0 = Pr(\\neg H | H) \\leq Pr(F | H) \\leq Pr(H | H) = 1\\)\n\\(Pr(F \\cup G | H) = Pr(F|H) + Pr(G|H) \\text{ if } F \\cap G = \\emptyset\\)\n\\(Pr(F \\cap G | H) = Pr(G | H) Pr(F | G \\cap H)\\)\n\nPartitions and probability\nSuppose \\(\\{ H_1, \\ldots, H_K\\}\\) is a partition of \\(\\mathcal{H}\\), \\(Pr(\\mathcal{H}) = 1\\) and \\(E\\) is some specific event. From the axioms of probability one may prove:\n\nRule of total probability:\n\n\\[\\begin{equation}\n\\sum_{k = 1}^K Pr(H_k) = 1\n\\end{equation}\\]\n\nRule of marginal probability:\n\n\\[\\begin{equation}\n\\begin{aligned}\nPr(E) &= \\sum_{k = 1}^K Pr(E \\cap H_k)\\\\ &= \\sum_{k = 1}^K Pr(E | H_k) Pr(H_k)\n\\end{aligned}\n\\end{equation}\\]\n\nBayes’ theorem:\n\n\\[\\begin{equation}\nPr(H_j | E) = \\frac{Pr(E|H_j) Pr(H_j)}{Pr(E)}\n\\end{equation}\\]\nNote it is often useful to replace the denominator, \\(Pr(E)\\), using the rule of marginal probability.\nIndependence\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(Pr(F \\cap G |H) = Pr(F|H) Pr(G|H)\\).\n\n\n\nLaw of total expectation \\(E(X) = E(E(X|Y))\\)\nLaw of total variance \\(Var(X) = E(Var(X|Y)) + Var(E(X|Y))\\)\n\n\n\n\n\n\n\nNote\n\n\n\nRemember we can always add conditioning statements e.g.\n\nLaw of total expectation \\(E(X|Z) = E(E(X|Y)|Z)\\)\nLaw of total variance \\(Var(X|Z) = E(Var(X|Y)|Z) + Var(E(X|Y)|Z)\\)"
  },
  {
    "objectID": "hw/hw03.html",
    "href": "hw/hw03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Let \\(Y_1, \\ldots Y_n | \\theta\\) be an i.i.d. random sample from a population with pdf \\(p(y|\\theta)\\) where\n\\[\np(y|\\theta) = \\frac{2}{\\Gamma(a)} \\theta^{2a} y^{2a -1} e^{-\\theta^2 y^2}\n\\]\nand \\(y > 0\\), \\(\\theta > 0\\), \\(a > 0\\).\nFor this density,\n\\[\n\\begin{aligned}\nE~Y|\\theta &= \\frac{\\Gamma(a + \\frac{1}{2})}{\\theta \\Gamma(a)}\\\\\nE~Y^2|\\theta &= \\frac{a}{\\theta^2}\n\\end{aligned}\n\\]\nCall this density \\(g^2\\) such that \\(Y_1, \\ldots Y_n | \\theta \\sim g^2(a, \\theta)\\).\n\nFind the joint pdf of \\(Y_1, \\ldots Y_n | \\theta\\) and simplify as much as possible.\nSuppose \\(a\\) is known but \\(\\theta\\) is unknown. Identify a simple conjugate class of priors for \\(\\theta\\). For any arbitrary member of the class, identify the posterior density \\(p(\\theta | y_1, \\ldots y_n)\\).\nObtain a formula for \\(E~ \\theta | Y_1, \\ldots Y_n\\) when the prior is in the conjugate class."
  },
  {
    "objectID": "hw/hw03.html#exercise-2",
    "href": "hw/hw03.html#exercise-2",
    "title": "Homework 3",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose \\(Y|\\theta \\sim \\text{binary}(\\theta)\\) and we want to use \\(\\theta \\sim \\text{Uniform}(0, 1)\\) to represent our lack of knowledge about \\(\\theta\\). However, we are interested in the log-odds \\(\\gamma = \\log \\frac{\\theta}{1 - \\theta}\\).\n\nFind the prior distribution for \\(\\gamma\\) induced by our prior on \\(\\theta\\). Is the prior informative about \\(\\gamma\\)? Verify \\(p(\\gamma)\\) using Monte Carlo sampling and then plotting the empirical density of the samples along with the closed-form solution.\nAssume some data come in and \\(y = 7\\) out of \\(n = 10\\) trials. Report the posterior mean and 95% posterior confidence interval for \\(\\gamma\\)."
  },
  {
    "objectID": "hw/hw03.html#exercise-3",
    "href": "hw/hw03.html#exercise-3",
    "title": "Homework 3",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose an experimental machine in a lab is either fine, or comes from a bad batch of machines that are to be recalled by the manufacturer. Scientists in the lab want to estimate the failure rate of their machine and decide whether or not to return it. They encode their prior uncertainty about the failure rate \\(\\theta\\) with the following density:\n\\[\np(\\theta) = \\frac{1}{4} \\frac{\\Gamma(10)}{\\Gamma(2)\\Gamma(8)}\\left[\n3 \\theta (1 - \\theta)^7 + \\theta^7(1- \\theta)\n\\right]\n\\]\n\nMake a plot of this prior density and explain why it makes sense for the scientists. Based on the prior density, which do the scientists think is more likely - that their machine is fine, or bad?\nThe scientists run the machine \\(n\\) times. Let \\(y_i\\) be one if the machine fails on the \\(i\\)th run, and zero otherwise. Write out the posterior distribution of \\(\\theta\\) given \\(y_1, \\ldots, y_n\\) (up to a proportionality constant) and simplify as much as possible.\nFor the case that \\(n = 4\\), make a plot of the (unscaled) posterior of \\(\\theta\\) for the five cases \\(\\sum y_i \\in \\{ 0, 1, 2, 3, 4\\}\\).\nThe posterior is a mixture (weighted average) of two distributions that you know. Identify these two distributions, including their parameters."
  },
  {
    "objectID": "hw/hw02.html",
    "href": "hw/hw02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Let \\(Y_1, Y_2 | \\theta\\) be i.i.d. binary(\\(\\theta\\)), so that \\(p(y_1, y_2 | \\theta) = \\theta ^{y_1 + y_2} (1- \\theta) ^{2 - y_1 - y_2}\\) and let \\(\\theta \\sim \\text{beta}(\\eta, \\eta)\\)\n\nCompute \\(E~Y_i\\) and \\(Var~Y_i\\) (the mean and variance of \\(Y_i\\) unconditional on \\(\\theta\\)) as a function of \\(\\eta\\)\nCompute \\(E~Y_1 Y_2\\), which is the same as \\(p(Y_1 = 1, Y_2 = 1)\\) unconditional on \\(\\theta\\). You can do this with help from the formula on page 33 of the book.\nUsing the terms you have calculated above, make a graph of the correlation between \\(Y_1\\) and \\(Y_2\\) as a function of \\(\\eta\\).\nInterpreting \\(\\eta\\) as how confident you are that \\(\\theta\\) is near \\(\\frac{1}{2}\\), and interpreting \\(Cor(Y_1, Y_2)\\) as how much information \\(Y_1\\) and \\(Y_2\\) provide about each other, explain in words why the correlation changes as a function of \\(\\eta\\)."
  },
  {
    "objectID": "hw/hw02.html#exercise-2",
    "href": "hw/hw02.html#exercise-2",
    "title": "Homework 2",
    "section": "Exercise 2",
    "text": "Exercise 2\nSuppose \\(n\\) individuals volunteer to count birds in a forest. Let \\(Y_i\\) be the number of birds counted by individual \\(i\\), and let \\(x_i\\) be the number of hours spent in the forest by volunteer \\(i\\). We will model the data \\(Y_1, \\ldots Y_n\\) as being independent given \\(\\theta\\), but not identically distributed. Specifically, our model is that \\(Y_i | \\theta \\sim \\text{Pois}(\\theta x_i)\\), independently for \\(i = 1, \\ldots n\\).\n\nCompute \\(E~Y_i | \\theta\\) and explain what \\(\\theta\\) represents.\nWrite out a formula for the joint pdf \\(p(y_1, \\ldots y_n |\\theta)\\) and simplify as much as possible. Find the MLE, that is, the value of \\(\\theta\\) that maximizes \\(p(y_1, \\ldots y_n | \\theta)\\). Explain why it makes sense.\nLet \\(\\theta \\sim \\text{gamma}(a, b)\\). Find a formula for the posterior mode of \\(\\theta\\) and compare to the MLE."
  },
  {
    "objectID": "hw/hw02.html#exercise-3",
    "href": "hw/hw02.html#exercise-3",
    "title": "Homework 2",
    "section": "Exercise 3",
    "text": "Exercise 3\nLet \\(\\theta_1\\) be the prevalence of a rare allele among people with Alzheimer’s disease, and let \\(\\theta_2\\) be the prevalence among people without the disease. To estimate \\(\\theta_1\\) and \\(\\theta_2\\), a sample of \\(n_1 = 19\\) Alzheimer’s patients and \\(n_2 = 176\\) control subjects are genotyped for the presence of the allele. Let \\(Y_1\\) and \\(Y_2\\) be the number of people in the two samples who have the allele. We will model \\(Y_1\\) and \\(Y_2\\) as independent with \\(Y_1 | \\theta_1 \\sim \\text{binomial}(n_1, \\theta_1)\\) and \\(Y_2 | \\theta_2 \\sim \\text{binomial}(n_2, \\theta_2)\\). Prior studies suggest that \\(\\theta_2 \\sim \\text{beta}(2, 30)\\) is a reasonable prior distribution for \\(\\theta_2\\). For now, we will use the same prior distribution for \\(\\theta_1\\). The study is performed and the data are that \\(Y_1 = 1\\) and \\(Y_2 = 16\\).\n\nState the posterior distributions of \\(\\theta_1\\) and \\(\\theta_2\\). Plot the posterior densities together on a single graph with the prior density, and compare all three curves with words.\nCompute the posterior mean and a 95% posterior interval for each of \\(\\theta_1\\) and \\(\\theta_2\\).\nWith a picture, with words, or mathematically, try to describe different kind of joint prior distribution for \\(\\theta_1\\) and \\(\\theta_2\\) that represents the \\(\\theta_1\\) and \\(\\theta_2\\) are close to each other, but highly uncertain."
  },
  {
    "objectID": "hw/hw00.html",
    "href": "hw/hw00.html",
    "title": "Homework 0",
    "section": "",
    "text": "This math assessment is meant to help both you and the instructor identify gaps in background knowledge both at the class and individual level."
  },
  {
    "objectID": "hw/hw00.html#exercise-1",
    "href": "hw/hw00.html#exercise-1",
    "title": "Homework 0",
    "section": "Exercise 1",
    "text": "Exercise 1\nSimplify\n\\[\n\\log(e^{a_1} e^{a_2} e^{a_3} \\cdots e^{a_n})\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-2",
    "href": "hw/hw00.html#exercise-2",
    "title": "Homework 0",
    "section": "Exercise 2",
    "text": "Exercise 2\nFind the derivative.\n\\[\n\\frac{d}{dx} \\left( \\frac{x}{\\log x} \\right)\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-3",
    "href": "hw/hw00.html#exercise-3",
    "title": "Homework 0",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat is the ordinary least squares estimator of \\(\\beta\\) (1-dimensional) in the linear regression \\(y = x \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-4",
    "href": "hw/hw00.html#exercise-4",
    "title": "Homework 0",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat is the ordinary least squares estimator of \\(\\beta\\) (p-dimensional) in the linear regression \\(y = X \\beta + \\epsilon\\) with iid errors?"
  },
  {
    "objectID": "hw/hw00.html#exercise-5",
    "href": "hw/hw00.html#exercise-5",
    "title": "Homework 0",
    "section": "Exercise 5",
    "text": "Exercise 5\nIn linear regression with p-dimensional β, what is the interpretation of the estimate for the jth coefficient?"
  },
  {
    "objectID": "hw/hw00.html#exercise-6",
    "href": "hw/hw00.html#exercise-6",
    "title": "Homework 0",
    "section": "Exercise 6",
    "text": "Exercise 6\nCompute the integral,\n\\[\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx\n\\]"
  },
  {
    "objectID": "hw/hw00.html#exercise-7",
    "href": "hw/hw00.html#exercise-7",
    "title": "Homework 0",
    "section": "Exercise 7",
    "text": "Exercise 7\n\\(X \\sim N(\\mu, \\sigma^2)\\) reads “X is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nLet\n\\[\n\\begin{aligned}\nX &\\sim N(0, 1),\\\\\nY &\\sim N(3, 2),\\\\\nZ &= X + Y\n\\end{aligned}\n\\]\nWhat is the distribution of \\(Z\\)? What is \\(\\mathbb{E}[Z]\\) and \\(Var(Z)\\)?"
  },
  {
    "objectID": "hw/hw00.html#exercise-8",
    "href": "hw/hw00.html#exercise-8",
    "title": "Homework 0",
    "section": "Exercise 8",
    "text": "Exercise 8\nIn your own words, the “support” of random variable is…"
  },
  {
    "objectID": "hw/hw00.html#exercise-9",
    "href": "hw/hw00.html#exercise-9",
    "title": "Homework 0",
    "section": "Exercise 9",
    "text": "Exercise 9\nTRUE/FALSE: The product of two uniform[0, 1] random variables is uniform[0, 1]."
  },
  {
    "objectID": "hw/hw01.html",
    "href": "hw/hw01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Let \\(X_i \\in \\mathcal{X}\\) for all \\(i \\in \\{1, 2, \\ldots\\}\\) and suppose our belief model for \\(\\mathbf{X} = \\{ X_1, \\ldots X_n \\}\\) is exchangeable for all \\(n\\). Show, using de Finetti’s theorem, that for all \\(i \\neq j\\),\n\\[\nCov(X_i, X_j) \\geq 0 \\text{ and }\n\\]\n\\[\nCorr(X_i, X_j) \\geq 0.\n\\]"
  },
  {
    "objectID": "hw/hw01.html#exercise-2",
    "href": "hw/hw01.html#exercise-2",
    "title": "Homework 1",
    "section": "Exercise 2",
    "text": "Exercise 2\n\n2.2 from Hoff"
  },
  {
    "objectID": "hw/hw01.html#exercise-3",
    "href": "hw/hw01.html#exercise-3",
    "title": "Homework 1",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n2.3 from Hoff"
  },
  {
    "objectID": "hw/hw01.html#exercise-4",
    "href": "hw/hw01.html#exercise-4",
    "title": "Homework 1",
    "section": "Exercise 4",
    "text": "Exercise 4\n\n2.6 from Hoff"
  },
  {
    "objectID": "solutions/hw01s.html",
    "href": "solutions/hw01s.html",
    "title": "Homework 1 solutions",
    "section": "",
    "text": "By definition of covariance,\n\\[\nCov(X_i, X_j) = \\mathbb{E}~X_i X_j - \\mathbb{E}~X_i ~\\mathbb{E}~X_j\n\\]\nBy the law of total expectation,\n\\[\n= \\mathbb{E}~[\\mathbb{E}~X_i X_j| \\theta] -\n\\mathbb{E}~[\\mathbb{E}~X_i | \\theta]\n\\mathbb{E}~[\\mathbb{E}~X_j | \\theta]\n\\]\nBy de Finetti’s theorem, exchangeability of \\(X_i\\) and \\(X_j\\) implies the two variables are conditionally iid relative to \\(\\theta\\). Therefore,\n\\[\n\\begin{aligned}\n\\mathbb{E}~[\\mathbb{E} ~ X_i X_j| \\theta] &= \\mathbb{E}~\n\\left[\n\\int \\int x_i~x_j~p(x_i, x_j |\\theta) dx_i~dx_j\n\\right]\\\\\n&=\\mathbb{E}~\n\\left[\n\\int x_i~p(x_i |\\theta) dx_i \\cdot \\int x_j~p(x_j |\\theta) dx_j\n\\right]\\\\\n&=\n\\mathbb{E}\n\\left[\n\\mathbb{E}~ X_i | \\theta \\cdot\n\\mathbb{E}~ X_j | \\theta\n\\right]\n\\end{aligned}\n\\]\nSimilarly,\n\\[\n\\mathbb{E}~\nX_i | \\theta\n=\n\\mathbb{E}\nX_j | \\theta\n\\]\nso that in total,\n\\[\nCov(X_i, X_j) =\n\\mathbb{E}~\n\\left[\n\\left(\n\\mathbb{E}~X_i | \\theta\n\\right)^2\n\\right]\n-\n\\left(\n\\mathbb{E}~\n\\left[\n\\mathbb{E}~\nX_i | \\theta\n\\right]\n\\right)^2\n\\]\nNote that \\(\\mathbb{E}~X_i | \\theta\\) is some function of \\(\\theta\\), say \\(g(\\theta)\\). It is easy to see\n\\[\nCov(X_i, X_j) = Var(g(\\theta)) \\geq 0\n\\]\n\nExplicit detail:\nBy de Finetti’s theorem exchangeability of \\(X_i\\) and \\(X_j\\) implies\n\\[\np(x_i, x_j) = \\int p(x_i | \\theta) p(x_j | \\theta) p(\\theta) d\\theta\n\\]\nRecall \\(p(x_i, x_j) = \\int p(x_i, x_j, \\theta) d\\theta\\) and therefore \\(p(x_i, x_j) = \\int p(x_i, x_j | \\theta) p(\\theta) d\\theta\\). By comparison to the above, notice\n\\[\np(x_i, x_j | \\theta) = p(x_i | \\theta) p(x_j|\\theta).\n\\]\nIn words, \\(x_i\\) and \\(x_j\\) are conditionally independent given \\(\\theta\\)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian methods and modern statistics",
    "section": "",
    "text": "Week\nDate\nTopic\nReading\nNotes\nAssignment\n\n\n\n\n1\nMon Aug 28\nlab: welcome\n\n💻\nhello R\n\n\n\nTue Aug 29\nintro, history, notation\nCh. 2\n\nhw 0\n\n\n\nThu Aug 31\nprobability, exchangeability\nCh. 2\n💻\nhw 1\n\n\n2\nMon Sep 04\nNO LAB\n\n\n\n\n\n\nTue Sep 05\nsingle parameter estimation\nCh. 3\n💻\n\n\n\n\nThu Sep 07\nPoisson model and conjugacy\nCh. 3\n\nhw 2\n\n\n3\nMon Sep 11\nlab: MLE and MAP estimator\n\n💻\n\n\n\n\nTue Sep 12\nreliability, exp. families\nCh. 3\n💻, 📝\n\n\n\n\nThu Sep 14\nprediction, Monte Carlo intro\nCh. 4\n💻, 📝\nhw 3\n\n\n4\nMon Sep 18\nlab: prior sensitivity and change of variables\n\n💻\n\n\n\n\nTue Sep 19\nMonte Carlo integration\nCh. 4\n💻\n\n\n\n\nThu Sep 21\nthe normal model\nCh. 5\n💻\n\n\n\n5\nMon Sep 25\npractice and review\n\n💻\n\n\n\n\nTue Sep 26\ncatch up / review\n\n\n\n\n\n\nThu Sep 28\nExam I\n\n\n\n\n\n6\nMon Oct 02\nNO LAB\n\n\n\n\n\n\nTue Oct 03\nthe normal model II\nCh. 5\n\nhw 4\n\n\n\nThu Oct 05\nestimators\nCh. 5\n💻, 📝\n\n\n\n7\nMon Oct 09\nlab: predictive checks and bias\n\n💻\n\n\n\n\nTue Oct 10\nGibbs sampling\nCh. 6\n💻\nec\n\n\n\nThu Oct 12\nMCMC diagnostics\nCh. 6\n💻\nhw 5\n\n\n8\nMon Oct 16\nNO LAB\n\n\n\n\n\n\nTue Oct 17\nNO CLASS\n\n\n\n\n\n\nThu Oct 19\nmultivariate normal (mvn)\nCh. 7\n💻\n\n\n\n9\nMon Oct 23\nfull conditional review\n\n\n\n\n\n\nTue Oct 24\nmvn parameter estimation\nCh. 7\n💻, 📝\nhw 6\n\n\n\nThu Oct 26\nhierarchical modeling intro\nCh. 8\n💻\n\n\n\n10\nMon Oct 30\ntraceplots and MCMC diagnostics\n\n💻\n\n\n\n\nTue Oct 31\nintro to Bayesian regression\nCh. 9\n💻\nhw 7\n\n\n\nThu Nov 02\nBayesian regression II\nCh. 9\n💻\n\n\n\n11\nMon Nov 06\nHierarchical modeling and Gibbs sampling practice\n\n\n\n\n\n\nTue Nov 07\nBayesian regression III  Guest lecture: Prof. Peter Hoff\nCh. 9\n\nhw 8\n\n\n\nThu Nov 09\nNO CLASS: read chapter summaries\n\n\n\n\n\n12\nMon Nov 13\nexam practice\n\n💻\n\n\n\n\nTue Nov 14\nreview\n\n\n\n\n\n\nThu Nov 16\nExam II\n\n\n\n\n\n13\nMon Nov 20\nNO LAB\n\n\n\n\n\n\nTue Nov 21\nBayesian regression example + stan intro\n\n\n\n\n\n\nThu Nov 23\nNO CLASS\n\n\n\n\n\n14\nMon Nov 27\nrstanarm\n\n💻\n\n\n\n\nTue Nov 28\nintro to Metropolis algorithm\nCh. 10\n📝\nhw 9\n\n\n\nThu Nov 30\nMetropolis-Hastings\nCh. 10\n💻\n\n\n\n15\nMon Dec 04\nMCMC practice\n\n💻\n\n\n\n\nTue Dec 05\nMCMC and HMC\nCh. 10\n💻\n\n\n\n\nThu Dec 07\nfinal review"
  },
  {
    "objectID": "slides/lab1.html#example-normal-likelihood",
    "href": "slides/lab1.html#example-normal-likelihood",
    "title": "MLEs and MAPs",
    "section": "Example: normal likelihood",
    "text": "Example: normal likelihood\nLet \\(X\\) be the resting heart rate (RHR) in beats per minute of a student in this class.\nAssume RHR is normally distributed with some mean \\(\\mu\\) and standard deviation \\(8\\).\n\n\\[\n\\textbf{Data-generative model: } X_i \\overset{\\mathrm{iid}}{\\sim} N(\\mu, 64)\n\\]\n\n\nIf we observe three student heart rates, {75, 58, 68} then our likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\nThat is, the joint density function of the observed data, viewed as a function of the parameter.\n\n\n\n\n\n\n\n\nImportant\n\n\nThe likelihood itself is not a density function. The integral with respect to the parameter does not need to equal 1."
  },
  {
    "objectID": "slides/lab1.html#visualizing-the-likelihood",
    "href": "slides/lab1.html#visualizing-the-likelihood",
    "title": "MLEs and MAPs",
    "section": "Visualizing the likelihood",
    "text": "Visualizing the likelihood\n\\[L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).\\]\n\ndatalikelihood functionplotplot code\n\n\n\nx = c(75, 58, 68)\n\n\n\n\nL = function(mu, x) {\n  stopifnot(is.numeric(x))\n  n = length(x)\n  likelihood = 1\n  for(i in 1:n){\n    likelihood = likelihood * dnorm(x[i], mean = mu, sd = 8)\n  }\n  return(likelihood)\n}\n\n\n\n\n\n\n\n\n\n\n\nggplot() +\n  xlim(c(50, 83)) +\n  geom_function(fun = L, args = list(x = x)) +\n  theme_bw() +\n  labs(x = expression(mu), y = \"likelihood\") + \n  geom_vline(xintercept = 67, color = 'red')\n\n\n\n\n\nThe maximum likelihood estimate \\(\\hat{\\mu} = \\frac{75 + 58 + 68}{3} = 67\\).\nThe maximum likelihood estimate is the parameter value that maximizes the likelihood function."
  },
  {
    "objectID": "slides/lab1.html#the-log-likelihood",
    "href": "slides/lab1.html#the-log-likelihood",
    "title": "MLEs and MAPs",
    "section": "The log-likelihood",
    "text": "The log-likelihood\nNotice how small the y-axis is on the previous slide. What happens to the scale of the likelihood as we add additional data points?\n\\[\nL(\\mu) = \\prod_{i = 1}^{n} f_x(x_i |\\mu)\n\\]\n\nSince densities often evaluate between 0 and 1, multiplying many together (as we usually do in likelihoods) can quickly result in floating point underflow. That is, numbers smaller than the computer can actually represent in memory.\n\nNote: sometimes densities evaluate to greater than 1 (e.g. dnorm(0, 0, 0.001)) and multiplying several together can result in overflow.\n\n\n\nlog to the rescue!\n\nlog is a monotonic function, i.e. \\(x > y\\) implies \\(\\log(x) > \\log(y)\\), because of this the maximum of \\(f\\) is the same as the maximum of \\(\\log f\\).\nadditionally, log turns products into sums\n\nin practice, we always work with the log-likelihood,\n\\[\n\\log L(\\mu) = \\sum_{i = 1}^n \\log f_x(x_i | \\mu).\n\\]"
  },
  {
    "objectID": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "href": "slides/lab1.html#maximum-likelihood-estimation-mle",
    "title": "MLEs and MAPs",
    "section": "Maximum likelihood estimation (MLE)",
    "text": "Maximum likelihood estimation (MLE)\nHow did we know to take the average of the values to find the maximum likelihood estimator \\(\\hat{\\mu}\\)?\n\nFrom calculus, we know that to maximize a function, we need to find where the slope equals zero (technically, to ensure we find some maxima and not a minima we need to also check that the second derivative is negative).\nExample: normal likelihood\nFor the normal likelihood example on the previous slide, we can see visually that the function is concave.\nTo find the maximum,\n\\[\n\\begin{aligned}\n\\frac{d}{d\\mu} \\log L(\\mu) &= \\sum_{i}\\frac{d}{d\\mu} \\log f_x(x_i |\\mu)\\\\\n&= \\sum_{i}\\frac{d}{d\\mu} \\left[ -\\frac{1}{2} \\log (2 \\pi \\sigma^2) - \\frac{1}{2\\sigma^2} (x_i - \\mu)^2 \\right]\\\\\n&= \\sum_i \\frac{1}{\\sigma^2} (x_i - \\mu)\n\\end{aligned}\n\\]\nSetting the derivative equal to zero,\n\\[\n\\begin{aligned}\n\\sum_i \\left[ x_i - \\hat{\\mu} \\right] &= 0\\\\\nn \\hat{\\mu} &= \\sum_i x_i\\\\\n\\hat{\\mu} &= \\bar{x}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab1.html#maximum-a-posteriori-probability-map",
    "href": "slides/lab1.html#maximum-a-posteriori-probability-map",
    "title": "MLEs and MAPs",
    "section": "Maximum a posteriori probability (MAP)",
    "text": "Maximum a posteriori probability (MAP)\nIn Bayesian inference, we wish to find the mode of the posterior, not the likelihood.\nTo find the posterior mode, \\(\\hat{\\theta}\\), we instead take the derivative of the log-posterior,\n\\[\n\\frac{d}{d\\theta} \\log p(\\theta | y) = 0\n\\]\nPractice exercise\nAs in class, let\n\\[\nY | \\theta \\sim \\text{binomial}(n, \\theta)\\\\\n\\theta \\sim \\text{beta}(a, b)\n\\]\n\nFind the closed-form solution for the posterior mode \\(\\hat{\\theta}\\).\nRecreate Figure 1 from class using the same data flips provided below but change the prior to \\(\\theta \\sim \\text{beta}(2, 2)\\).\n\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\n\n\nAdd a red vertical line to each subplot that shows the MAP estimate under the prior \\(\\theta \\sim \\text{beta}(2, 2)\\).\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab0-welcome.html#introductions",
    "href": "slides/lab0-welcome.html#introductions",
    "title": "Welcome to Lab",
    "section": "Introductions",
    "text": "Introductions\n\n\n\n\nMeet the TA!\nIntroduce yourself (icebreaker)\nFollow along these slides on the course website (under slides): sta360-fa23.github.io\nBookmark this! It’s the course website."
  },
  {
    "objectID": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "href": "slides/lab0-welcome.html#what-to-expect-in-labs",
    "title": "Welcome to Lab",
    "section": "What to expect in labs",
    "text": "What to expect in labs\n\nDiscussion\nPractice problems\nAssistance on computing portion of homeworks"
  },
  {
    "objectID": "slides/lab0-welcome.html#tips",
    "href": "slides/lab0-welcome.html#tips",
    "title": "Welcome to Lab",
    "section": "Tips",
    "text": "Tips\n\nShow up.\nMake use of office hours. Before you need help!"
  },
  {
    "objectID": "slides/lab0-welcome.html#beginnings",
    "href": "slides/lab0-welcome.html#beginnings",
    "title": "Welcome to Lab",
    "section": "Beginnings",
    "text": "Beginnings\nWhile this is not a computing class, computers are the workhorse of Bayesian statistics and we will use R to both enhance understanding of fundamental course material as well as to implement models to learn about real data sets."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio",
    "href": "slides/lab0-welcome.html#set-up-rstudio",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 1 (easiest): RStudio container\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick RStudio to log into the Docker container. You should now see the RStudio environment.\n\nIf you haven’t previously done so, you will need to reserve a container for RStudio first."
  },
  {
    "objectID": "slides/lab0-welcome.html#set-up-rstudio-1",
    "href": "slides/lab0-welcome.html#set-up-rstudio-1",
    "title": "Welcome to Lab",
    "section": "Set up RStudio",
    "text": "Set up RStudio\nOption 2: RStudio on your computer\n\nDownload R from http://www.r-project.org/.\nDownload RStudio, the popular IDE for R, from https://posit.co/downloads/.\n(optionally) download Quarto from https://quarto.org/docs/get-started/"
  },
  {
    "objectID": "slides/lab0-welcome.html#demo",
    "href": "slides/lab0-welcome.html#demo",
    "title": "Welcome to Lab",
    "section": "Demo",
    "text": "Demo\nNext, check your familarity with R/RStudio fundamentals here. You can also find a link to this from the course schedule under “Assignment”.\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "RStudio containers\n\nResources\n\nSakai website\n\nlectures and solutions uploaded here under “Resources” tab on the left hand side\n\nGradescope\n\nTextbook\n\nA First Course in Bayesian Statistical Methods by Peter Hoff\nErrata to the textbook"
  },
  {
    "objectID": "notes/estimation1.html",
    "href": "notes/estimation1.html",
    "title": "Is this a fair coin?",
    "section": "",
    "text": "outputcode\n\n\n\n\n [1] 0 1 0 0 0 0 0 0 0 0\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(glue)\nlibrary(patchwork)\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\nflips %>% head(10)\nWe observe 10 flips from the same coin above, where 0 is “tails” and 1 is “heads”. In summary, we see Y = 1 heads in 10 coin flips. Is this a fair coin?\nTo articulate this mathematically, let \\(\\theta \\in [0, 1]\\) be the bias-weighting (the chance of heads) of the coin. Fundamentally, we want \\(p(\\theta | y)\\), which we can expand via Bayes’ rule,\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{\\int_{\\theta \\in \\Theta} p(y|\\theta) p(\\theta) d\\theta}\n\\]\nLikelihood: the data generative process. The joint probability (or density) of the data given the parameters of the model. Most often thought of as a function of the parameter. Note: not a density of the parameter.\nPrior: Our a priori (beforehand) beliefs about the true population characteristics.\nPosterior: Our a posteriori (afterwards) beliefs about the true population characteristics after having observed the data set \\(y\\).\nNormalizing constant: A number that enables a pmf or pdf to integrate to 1."
  },
  {
    "objectID": "notes/estimation1.html#uniform-prior",
    "href": "notes/estimation1.html#uniform-prior",
    "title": "Is this a fair coin?",
    "section": "Uniform prior",
    "text": "Uniform prior\nLet \\(y\\) be the number of heads in \\(n\\) coin flips.\n\\[\np(\\theta | y) \\propto \\theta^{y}(1-\\theta)^{n-y}\n\\]\nThis is the kernel of a ___ density, where \\(\\alpha = y + 1\\) and \\(\\beta = n - y + 1\\), hence\n\\[\np(\\theta | y) = \\frac{\\Gamma(n + 2)}{\\Gamma(y + 1)\\Gamma(n-y+1)} \\theta^{y}(1-\\theta)^{n-y}\n\\]\nand the posterior mean is \\(\\frac{y + 1}{n + 2}\\) and the posterior variance is \\(\\frac{(y+1)(n - y + 1)}{(n + 2)^2 (n + 1)}\\).\nLet’s examine how the posterior evolves with each successive coin flip.\n\nplotscode\n\n\n\n\n\n\n\n\n\n\nN = c(0, 1, 2, 3, 4, 10, 100, 1000, 5000)\n\nfor (i in seq_along(N)) {\nn = N[i]\nif(n == 0) {\n  y = 0\n}\nelse {\n  y = sum(flips[1:n])\n}\n\nx = 0:1 # range\ndf = data.frame(x)\nassign(paste0(\"p\", i),\n  df %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun=dbeta, \n                args = list(shape1 = y + 1, shape2 = n - y + 1)) +\n  labs(y = TeX(\"$p(\\\\theta | y)$\"), x = TeX(\"$\\\\theta$\"),\n       title = glue(\"n = {n}\")) +\n  theme_bw()\n)\n}\n\n(p1 + p2 + p3) / \n  (p4 + p5 + p6) / \n  (p7 + p8 + p9) +\n  plot_annotation(title = \"Figure 1\")"
  },
  {
    "objectID": "notes/estimation1.html#conjugacy",
    "href": "notes/estimation1.html#conjugacy",
    "title": "Is this a fair coin?",
    "section": "Conjugacy",
    "text": "Conjugacy\nIf \\(\\theta \\sim\\) Uniform(0, 1) then \\(p(\\theta)\\) = 1 for all \\(\\theta \\in [0, 1]\\).\nSimilarly, if \\(\\theta \\sim\\) beta(1, 1), then \\(p(\\theta) = 1\\).\nClaim:\nIf\n\\[\n\\begin{aligned}\n\\theta &\\sim \\text{beta}(a, b)\\\\\nY | \\theta &\\sim \\text{binomial}(n, \\theta)\n\\end{aligned}\n\\]\nthen\n\\[\np(\\theta | Y) = \\text{beta}(y + a, n - y + b)\n\\]\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\nWhile conjugate priors make calculation easy, they may not accurately reflect our prior beliefs.\n\n\n\n\n\n\nExercise\n\n\n\nProve the claim above."
  },
  {
    "objectID": "notes/estimation1.html#other-priors",
    "href": "notes/estimation1.html#other-priors",
    "title": "Is this a fair coin?",
    "section": "Other priors",
    "text": "Other priors\nIncidentally, people are often satisfied with the choice of likelihood but are worried about the choice of prior.\nLet’s examine the effect of another couple of priors.\nGiven the coin’s dubious origin, we might believe a priori that the coin is biased. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(.5, .5)\n\\]\nOr alternatively, we might be strongly believe a priori that the coin is fair. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(20, 20)\n\\]\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow would you update the code of the previous example to show posterior inference under the prior \\(\\theta \\sim\\) beta(2,3)?"
  },
  {
    "objectID": "notes/estimation1.html#prior-data",
    "href": "notes/estimation1.html#prior-data",
    "title": "Is this a fair coin?",
    "section": "Prior data",
    "text": "Prior data\nIn the example above, the parameters, a and b, of the conjugate prior are often thought of as prior data.\n\na: “prior number of 1s”\nb: “prior number of 0s”\na + b: “prior sample size”\n\n\n\n\n\n\n\nExercise\n\n\n\nWe saw above that when a = 20 and b = 20, we needed more data to move the posterior.\nShow that the posterior mean, \\(E(\\theta | y) = \\frac{a + y}{a + b + n}\\) converges to the sample average as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "notes/probability.html",
    "href": "notes/probability.html",
    "title": "Probability",
    "section": "",
    "text": "This is foundational material. Most of it is background you will have learned in STA230/240. While dry, we must soldier on to get to the exciting stuff."
  },
  {
    "objectID": "notes/probability.html#review-set-theory",
    "href": "notes/probability.html#review-set-theory",
    "title": "Probability",
    "section": "Review: set theory",
    "text": "Review: set theory\n\n\n\n\n\n\nDefinition\n\n\n\nset: a collection of elements, denoted by {}\nExamples\n\n\\(\\phi\\) = {} “the empty set”\nA = {1, 2, 3}\nB = {taken STA199, has not taken STA199}\nC = {{1,2,3}, {4, 5}}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsubset: denoted by \\(\\subset\\), \\(A \\subset B\\) iff \\(a \\in A \\implies a \\in B\\)\nExamples\nUsing the previously examples of A, B and C above,\n\n\\(A \\subset C\\)\n\\(A \\not\\subset B\\)\n\n\n\nRecall:\n\n\\(\\cup\\) means “union”, “or”\n\\(\\cap\\) means “intersection”, “and”\n\n\n\n\n\n\n\nDefinition\n\n\n\npartition: {\\(H_1, H_2, ... H_n\\)} = \\(\\{H_i\\}_{i = 1}^n\\) is a partition of \\(\\mathcal{H}\\) if\n\nthe union of sets is \\(\\mathcal{H}\\) i.e. \\(\\cup_{i = 1}^n H_i = \\mathcal{H}\\)\nthe sets are disjoint i.e. \\(H_i \\cap H_j = \\phi\\) for all \\(i \\neq j\\)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsample space: \\(\\mathcal{H}\\), the set of all possible data sets (outcomes)\nevent: a set of one or more outcomes\nNote: p(\\(\\mathcal{H}\\)) = 1\nExamples\n\nRoll a six-sided die once. The sample space \\(\\mathcal{H} = \\{1, 2, 3, 4, 5, 6\\}\\).\nLet \\(A\\) be the event that the die lands on an even number. \\(A = \\{2, 4, 6 \\}\\)"
  },
  {
    "objectID": "notes/probability.html#axioms-of-probability-in-words",
    "href": "notes/probability.html#axioms-of-probability-in-words",
    "title": "Probability",
    "section": "Axioms of probability (in words)",
    "text": "Axioms of probability (in words)\nP1. Probabilities are between 0 and 1, importantly p(\\(\\neg\\)H|H) = 0 and p(H|H) = 1.\nP2. If two events A and B are disjoint, then p(A or B) = p(A) + p(B)\nP3. The joint probability of two events may be broken down stepwise: p(A,B) = p(A|B)p(B)\n–\nIt follows that\n\nfor any partition \\(\\{H_i\\}_{i = 1}^n\\), \\(\\sum_{i=1}^n p(H_i) = 1\\) (rule of total probability)\n\nnote: simplest partition \\(p(A) + p(\\neg A) = 1\\)\n\n\\(p(A) = \\sum_{i=1}^n p(A, H_i)\\) (rule of marginal probability)\n\nnote: P3 implies that equivalently, \\(p(A) = \\sum_{i=1}^n p(A | H_i) p(H_i)\\)\n\np(A|B) = p(A,B) / p(B) when p(B) \\(\\neq 0\\)\n\nnote: these statements can also be made where each term is additionally conditioned on another event C\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDerive Bayes’ rule:\n\\(p(H_i|X) = \\frac{p(X|H_i)p(H_i)}{\\sum_k p(X|H_k)p(H_k)}\\)\nusing the axioms of probability.\n\n\nBayes’ rule tells us how to update beliefs about \\(\\{H_i \\}_{i = 1}^n\\) given data \\(X\\)."
  },
  {
    "objectID": "notes/probability.html#independence",
    "href": "notes/probability.html#independence",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(p(F, G | H) = p(F | H) p(G | H)\\)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nShow conditional independence implies\n\\(p(F | H, G) = p(F | H)\\)\n\n\nThis means that if we know H, then G does not supply any additional information about F."
  },
  {
    "objectID": "notes/probability.html#random-variables",
    "href": "notes/probability.html#random-variables",
    "title": "Probability",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nDefinition\n\n\n\nIn Bayesian inference, a random variable is an unknown numerical quantity about which we make probability statements.\nExamples\n\nData. E.g. the amount of a wheat a field will yield later this year. Since this data has not yet been generated, the quantity is unknown.\nA population parameter. E.g. the true mean resting heart rate of Duke students. Note: this is a fixed (non-random) quantity, but it is also unknown. We use probability to describe our uncertainty in this quantity.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ndiscrete random variable: a random variable that takes countably many values. Y is discrete if its possible outcomes can be enumerated \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots \\}\\).\nNote: discrete does not mean finite. There may be infinitely many outcomes!\nExamples\n\nY = the number of children of a randomly sampled person\nY = the number of visible stars in the sky on a randomly sampled night of the year\n\nFor each \\(y \\in \\mathcal{Y}\\), let p(Y) = probability(Y = y). Then p is the probability mass function (pmf) of the random variable Y.\nExamples\n\nBinomial pmf: the probability of \\(y\\) successes in \\(n\\) trials, where each trial has an individual probability of success \\(\\theta\\).\n\\[p(y | \\theta) = {n \\choose y} \\theta ^y (1-\\theta)^y \\text{ for } y \\in \\{0, 1, \\ldots n \\}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots n\\}\\)\nsuccess probability \\(\\theta \\in [0, 1]\\)\ndbinom(y, n, theta) computes this pmf in R\n\nPoisson pmf: probability of \\(y\\) events occurring during a fixed interval at a mean rate \\(\\theta\\)\n\\[p(y | \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots \\}\\)\nrate \\(\\theta \\in \\mathbb{R}^+\\)\ndpois(y, theta) computes this pmf in R\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ncontinuous random variable: a random variable that takes uncountably many values.\nThe probability density function (pdf) of a continuous random variable, X is defined\n\\(pdf(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{p(x < X < x + \\Delta x)}{\\Delta x}\\)\nand the probability X is in some interval,\n\\(p(x_1 < X < x_2) = \\int_{x_1}^{x_2} pdf(x) dx\\)\nExamples\n\nNormal pdf \\[\np(x | \\mu, \\sigma) = (2\\pi \\sigma^2)^{-\\frac{1}{2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n\\]\nUniform pdf \\[p(x|a,b) =\n\\begin{cases}\n\\frac{1}{b - a} \\hspace{.6cm}\\text{ for } x \\in [a, b]\\\\\n0 \\hspace{1cm}\\text{ otherwise }\n\\end{cases}\\]\n\n\n\nNote: we will often abuse notation and use \\(p(x)\\) in place of \\(pmf(x)\\) and \\(pdf(x)\\) and prob(event), where only the context makes meaning clear.\nFor pmfs\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\leq 1\\\\\n\\sum_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nSimilarly, for pdfs,\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\ \\text{and} \\\\\n\\int_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nNote: For a continuous random variable Y, p(y) can be larger than 1 and p(y) is not p(Y = y), which equals 0.\n\n\n\n\n\n\nDefinition\n\n\n\nThe part of the density/mass function that depends on the variable is called the kernel.\nExample\n\nthe kernel of the normal pdf is \\(e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat’s the kernel of a gamma random variable X?\nRecall: the pdf of a gamma distribution:\n\\[\np(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\n\\]"
  },
  {
    "objectID": "notes/probability.html#moments",
    "href": "notes/probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nFor a random variable X, the \\(n\\)th moment is defined as E(\\(X^n\\)).\nRecall, the expected value is defined for discrete random variable X,\n\\[\nE(X) = \\sum_{x \\in \\mathcal{X}} x p(x)\n\\]\nand for continuous random variable Y,\n\\[\nE(Y) = \\int_{-\\infty}^{\\infty} y p(y) dy\n\\]\nThe variance of a random variable, is also known as the second central moment and is defined\n\\[\nE(X - E(X))^2\n\\] or equivalently,\n\\[\nE(X^2) - E(X)^2\n\\]\nMore generally, the covariance between two random variables X and Y is defined\n\\[\nE[(X - E[X])(Y - E[Y])]\n\\]"
  },
  {
    "objectID": "notes/probability.html#exchangeability",
    "href": "notes/probability.html#exchangeability",
    "title": "Probability",
    "section": "Exchangeability",
    "text": "Exchangeability\n\noffline notes"
  },
  {
    "objectID": "notes/reliability.html",
    "href": "notes/reliability.html",
    "title": "Posterior summaries and reliability",
    "section": "",
    "text": "Posterior mode: sometimes called “MAP” or “maximum a posteriori” estimate, this quantity is given by \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y)\\).\n\nNotice this unwinds to be \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(y | \\theta) p(\\theta)\\).\n\n\n\n\n\n\n\nExercise\n\n\n\n\nShow that, for the uniform prior, \\(\\hat{\\theta} = y / n\\)\nCompare to maximum likelihood estimate (MLE); see notes on likelihoods\n\n\n\nOne way to report the reliability of the posterior mode is to look at the width of the posterior near the mode, which we can sometimes approximate with a Gaussian distribution:\n\\[\np(\\theta | y) \\approx C e^{\\frac{1}{2} \\frac{d^2L}{d\\theta^2}|_{\\hat{\\theta}} (\\theta - \\hat{\\theta})^2}\n\\]\nwhere \\(C\\) is a normalization constant and \\(L\\) is the log-posterior, \\(\\log p(\\theta | y)\\).\nTaken together, the fitted Gaussian with a mean equal to the posterior mode is called the Laplace approximation.\n\nLet’s derive the Laplace approximation offline"
  },
  {
    "objectID": "notes/reliability.html#confidence-regions",
    "href": "notes/reliability.html#confidence-regions",
    "title": "Posterior summaries and reliability",
    "section": "Confidence regions",
    "text": "Confidence regions\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\nContrast posterior coverage to frequentist coverage:\n\n\n\n\n\n\nDefinition\n\n\n\nA random interval \\((l(Y), u(Y)\\)) has 95% frequentist coverage for \\(\\theta\\) if before data are observed,\n\\[\np(l(Y) < \\theta < u(Y) | \\theta) = 0.95\n\\]\nInterpretation: if \\(Y \\sim P_\\theta\\) then the probability that \\((l(Y), u(Y)\\) will cover \\(\\theta\\) is 0.95.\n\n\nIn practice, for many applied problems\n\\[\np(l(y) < \\theta < u(y) | y ) \\approx p(l(Y) < \\theta < u(Y) | \\theta)\n\\]\nsee section 3.1.2. in the book."
  },
  {
    "objectID": "notes/reliability.html#high-posterior-density",
    "href": "notes/reliability.html#high-posterior-density",
    "title": "Posterior summaries and reliability",
    "section": "High posterior density",
    "text": "High posterior density\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nNote: all points inside an HPD region have higher posterior density than points outside the region.\n\n\n\n\n\n\n\nExercise\n\n\n\nIs the HPD region always an interval?"
  },
  {
    "objectID": "notes/prediction1.html",
    "href": "notes/prediction1.html",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:"
  },
  {
    "objectID": "notes/prediction1.html#prediction-example",
    "href": "notes/prediction1.html#prediction-example",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Prediction example",
    "text": "Prediction example\nGeneral social survey (1998)\nSetup:\n\nSuppose \\(X_i = 1\\) if the ith person is happy. \\(X_i = 0\\) otherwise.\nLet \\(Y = \\sum_{i = 1}^{n} X_i\\), where \\(n\\) is the number of people sampled.\n\\(Y_i | \\theta \\sim \\text{binomial}(\\theta)\\) for some fixed \\(n\\).\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\n\nScenario: We sample \\(n = 10\\) people. \\(y = 6\\) are happy. If we sample another \\(n = 10\\), what is the probability that \\(\\tilde{y}\\) are happy?\nWe fundamentally want the posterior predictive distribution, \\(p(\\tilde{y} | y)\\).\nFollowing the offline notes, and given conditional independence, we want\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\int p(\\tilde{y} | \\theta) p(\\theta | y) d\\theta\n&=\n\\int {n \\choose \\tilde{y}}\n(\\theta)^\\tilde{y} (1-\\theta)^{n-\\tilde{y}}\n\\cdot\n\\frac{1}{\\text{B(y + 1, n - y + 1)}}\\theta^{y}(1-\\theta)^{n-y}\nd\\theta\\\\\n&= {n \\choose \\tilde{y}} \\frac{1}{\\text{B(y + 1, n - y + 1)}} \\int \\theta^{\\tilde{y}+y} \\cdot\n(1-\\theta)^{(n-\\tilde{y}) + (n - y)} d\\theta\\\\\n&= {n \\choose \\tilde{y}}\n\\frac{\\text{B}(\\tilde{y} + y + 1, 2n - y - \\tilde{y} + 1)}{\\text{B(y + 1, n - y + 1)}}\n\\end{aligned}\n\\]\nwhere \\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). We can of course simplify, since this is really a bunch of factorials, but we can also naively use the beta() function in R and push forward.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\ny = 6\nn = 10\n\n# posterior predictive probability of ytilde\nprobYT = function(ytilde) {\n  choose(n, ytilde) * \n    beta(ytilde + y + 1, (2*n) - y - ytilde + 1) / \n    beta(y + 1, n - y + 1)\n}\n\n# construct data frame\ndf = data.frame(ytilde = 0:10) %>%\n  mutate(postPredict = probYT(ytilde))\n\n# plot data frame\ndf %>%\n  ggplot(aes(x = ytilde, y = postPredict)) +\n  geom_bar(stat = 'identity') +\n  labs(x = TeX(\"$\\\\tilde{y}$\"), y = TeX(\"$p(\\\\tilde{y}|y)$\"),\n       title = \"Posterior predictive probability\") +\n  theme_bw()"
  },
  {
    "objectID": "notes/prediction1.html#monte-carlo-motivation",
    "href": "notes/prediction1.html#monte-carlo-motivation",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about…\n\n\\(p(\\theta \\in \\mathcal{A} | y)\\),\n\\(E~g(\\theta) | y\\),\n\\(Var~g(\\theta) | y\\)?\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?"
  },
  {
    "objectID": "notes/prediction1.html#monte-carlo-integration",
    "href": "notes/prediction1.html#monte-carlo-integration",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(X\\), the sample mean \\(\\bar{x}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\]\nthen the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) f_\\theta(\\theta | y)dx \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\n\\]\nwhere \\(f_x(x)\\) is the probability density function for a random variable \\(X\\).\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) to \\(E~\\theta|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/prediction1.html#examples",
    "href": "notes/prediction1.html#examples",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %>%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(\\theta_1 - \\theta_2\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = theta1 - theta2)\n\ndf %>%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1 - \\\\theta_2$\"),\n       y = TeX(\"$p(\\\\theta_1 - \\\\theta_2 | {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n(3) \\(p(\\theta_1 - \\theta_2> .5)\\)\n\nmean(df$diff > .5)\n\n[1] 0.4106\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\nLet \\(\\gamma = \\log \\theta\\)\nVisualize \\(p(\\gamma)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000)\n\n# define transform function\nf = function(x) {\n  return(exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(gamma = -7:0)\ndf2 = data.frame(gammaSamples = log(theta))\n\n# make plots\ndf %>%\n  ggplot(aes(x = gamma)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = gammaSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000)\ngamma = log(theta)\nhist(gamma)"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 360: Bayesian methods and modern statistics",
    "section": "",
    "text": "This course introduces Bayesian modeling and inference, motivated by real world examples. Course topics include Bayes’ theorem, exchangeability, conjugate priors, Markov chain Monte Carlo (MCMC) approximation, Gibbs sampling, hierarchical modeling, Bayesian regression and generalized linear models. We compare and contrast Bayesian methods to the frequentist paradigm. By the end of this course students should feel comfortable (1) writing Bayesian models and, when appropriate, (2) sampling from the posterior using MCMC to make inference.\n\n\n\n\n\n\n\n\n\nContact\nOffice hours\nLocation\n\n\n\n\nDr. Alexander Fisher\naaf29@duke.edu\nTu: 11:30am-1:30pm\nOld Chem 207\n\n\nCarol Wang\nzhuoqun.wang@duke.edu\nMo: 6:00pm-8:00pm\nZoom\n\n\nManny Mokel\nemmanuel.mokel@duke.edu\nTh: 3:00pm-5:00pm\nOld Chem 203B\n\n\nCaitrin Murphy\ncaitrin.murphy@duke.edu\nWe: 4:30pm-6:30pm\nOld Chem 025\n\n\n\n\n\n\n\n\n\nLecture\nTu/Th 10:05 - 11:20am\nOld Chemistry 116\n\n\nLab 01\nM 3:05pm - 4:20pm\nPerkins LINK 087 (Classroom 3)\n\n\nLab 02\nM 4:40pm - 5:55pm\nSocial Sciences 124\n\n\n\nCourse website: sta360-fa23.github.io\n\n\n\n\n\n\n\n\n\n\n\nA First Course in Bayesian Statistical Methods. As a Duke student, an electronic version of the book is freely available to you on Springer link. Check the errata at the link above.\nChapter summaries. I compile major take-away points from each section. Review these to help prepare for exams.\nWe will use the statistical software package R on homework asignments in this course. R is freely available at http://www.r-project.org/. RStudio, the popular IDE for R, is freely available at https://posit.co/downloads/.\n\n\n\n\nPart I: The Bayesian modeling toolkit\n\nReview of probability\nConjugate statistical models\nSemi-conjugate models and Gibbs sampling\n\nPart II: Statistical model building and analysis\n\nMultilevel models\nLinear regression\nGeneralized linear models\nDensity estimation and classification\n\n\n\n\n\n\n\n\n\n\n\nAssignment\nDescription\n\n\n\n\nHomework (40%)\nIndividual take-home assignments, submitted to Gradescope.\n\n\nMidterms (30%)\nTwo in-class exams.\n\n\nFinal exam (25%)\nCumulative final during final’s week.\n\n\nQuizzes (5%)\nIn-class pop quizzes.\n\n\n\nA \\(>= 93\\), A- \\(< 93\\), B+ \\(< 90\\), B \\(< 87\\), B- \\(< 83\\), C+ \\(<80\\), C \\(< 77\\), C- \\(< 73\\), D+ \\(< 70\\), D \\(< 67\\), D- \\(< 63\\), F \\(< 60\\)\n\n\n\n\n\n\nA note on quizzes\n\n\n\nOn random class days, there will be a brief quiz on the previous lectures. If you score \\(>60\\%\\) cumulatively on your final quiz grade, you will receive full participation credit. Your lowest two quizzes will also be dropped.\n\n\n\n\n\n\n\n\nA note on exams\n\n\n\nIf you miss either midterm 1 or midterm 2, and have an excused absence, your missing midterm grade will be replaced by your final exam grade. You must take at least 1 midterm and the final exam to pass the course.\n\n\n\n\n\n\n\n\n\nAcademic integrity\nBy enrolling in this course, you commit to upholding Duke’s community standard reproduced as follows:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\nAny violations of academic integrity will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action. For the Exams and Quizzes, students are required to work alone. For the Homework assignments, students may work with a study group but each student must write up and submit their own answers.\nLate work\nLate homework may be submitted within 48 hours of the assignment deadline. Late homework submitted within 24 hours (even 1 minute late) will receive a 5% late penalty. Late work submitted between 24 to 48 hours of the deadline will receive a 10% late penalty. Work submitted after 48 hours will not be accepted. Exams cannot be turned in late and can only be excused under exceptional circumstances. The Duke policy for illness requires a short-term illness report or a letter from the Dean; except in emergencies, all other absenteeism must be approved in advance (e.g., an athlete who must miss class may be excused by prior arrangement for specific days). For emergencies, email notification is needed at the first reasonable time.\nErrors in grading\nErrors in grading must be brought to the attention of the TA or instructor during office hours within 1 week of receiving the grade."
  },
  {
    "objectID": "quizzes/quiz01.html",
    "href": "quizzes/quiz01.html",
    "title": "Quiz 1",
    "section": "",
    "text": "Exercise 1\nTRUE or FALSE: The beta prior is conjugate to a binomial likelihood.\n\n\nExercise 2\nTRUE or FALSE: \\(p(y|\\theta)\\) is the marginal likelihood.\n\n\nExercise 3\nIn Bayes’ theorem (written below), which term is the “normalizing constant”?\n\\[\np(\\theta | y) = \\frac{p(y |\\theta) p(\\theta)}{\\int p(y, \\theta) d\\theta}\n\\]\n\n\nExercise 4\n\\[\n\\begin{aligned}\nX &\\sim gamma(k, \\theta)\\\\\np(x) &= \\frac{1}{\\Gamma(k) \\theta^k}x^{k-1}e^{-x/\\theta}\n\\end{aligned}\n\\]\nThe kernel of the distribution is ___.\n\n\n\n04:00"
  },
  {
    "objectID": "quizzes/quiz02.html",
    "href": "quizzes/quiz02.html",
    "title": "Quiz 2",
    "section": "",
    "text": "Exercise 1\nTRUE or FALSE: this is a 95% Bayesian confidence interval:\n\\[\np(l(y) < \\theta < u(y) | y) = 0.95\n\\]\n\n\nExercise 2\nWrite “equals” or “does not equal” in the blank below:\nIf\n\\[\nY | \\theta \\sim \\text{binomial}(n, \\theta),\n\\]\nthen \\(\\hat{\\theta}_{MLE}\\) ___ \\(\\hat{\\theta}_{MAP}\\) when \\(\\theta \\sim \\text{beta}(1, 1)\\).\n\n\nExercise 3\nTRUE or FALSE: high posterior density regions are always intervals.\n\n\n\n03:00"
  },
  {
    "objectID": "notes/MonteCarlo.html",
    "href": "notes/MonteCarlo.html",
    "title": "Monte Carlo Integration",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "slides/lab2.html#practice-exercise",
    "href": "slides/lab2.html#practice-exercise",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\nA cancer laboratory is estimating the rate of tumorigenesis in two strains of mice, \\(A\\) and \\(B\\). They have tumor count data for 10 mice in strain \\(A\\) and 13 mice in strain \\(B\\),\n\nyA = c(12, 9, 12, 14, 13, 13, 15, 8, 15, 6)\nyB = c(11, 11, 10, 9, 9, 8, 7, 10, 6, 8, 8, 9, 7)\n\nAssume\n\\[\n\\begin{aligned}\nY_A &\\sim \\text{Poisson}(\\theta_A)\\\\\nY_B &\\sim \\text{Poisson}(\\theta_B).\n\\end{aligned}\n\\]\n\nExercise 1Exercise 2\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12, 1).\n\\end{aligned}\n\\]\n\nCompute \\(p(\\theta_B < \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\) via Monte Carlo sampling.\n\n\n\nLet\n\\[\n\\begin{aligned}\n\\theta_A &\\sim \\text{gamma}(120, 10)\\\\\n\\theta_B &\\sim \\text{gamma}(12\\cdot n_0, n_0).\n\\end{aligned}\n\\]\n\nFor a range of values of \\(n_0\\), obtain \\(p(\\theta_B < \\theta_A ~|~ \\vec{y}_A, \\vec{y}_B)\\).\nDescribe how sensitive conclusions about the event \\(\\{ \\theta_B < \\theta_A\\}\\) are to the prior distribution on \\(\\theta_B\\)."
  },
  {
    "objectID": "slides/lab2.html#practice-exercise-1",
    "href": "slides/lab2.html#practice-exercise-1",
    "title": "Sensitivity to the prior and change of variables",
    "section": "Practice exercise",
    "text": "Practice exercise\n\nLet \\(X \\sim \\text{Unif}(5, 10)\\)\nLet \\(Y = X^2\\)\n\nNotice that even though \\(X^2\\) is not a monotonic function everywhere, it is a monotonic function over the support of X.\nExercise: use the change of variables formula to derive \\(p(y)\\). Confirm with Monte Carlo simulation.\n\n\nShow solution\nlibrary(tidyverse)\n\nx = runif(100000, 5, 10)\ny = x^2\n\ndf = data.frame(y)\n\nf = function(y) {\n  return(.1/sqrt(y))\n}\n\ndf %>%\n  ggplot(aes(x = y)) + \n  stat_function(fun = f) +\n  geom_histogram(aes(x = y, y = ..density..),\n                 fill = 'steelblue', alpha = 0.5)\n\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/MonteCarlo.html#monte-carlo-prediction",
    "href": "notes/MonteCarlo.html#monte-carlo-prediction",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo prediction",
    "text": "Monte Carlo prediction\n\nPrior predictive distribution\nWe can use Monte Carlo to sample new observation, \\(\\tilde{y}\\), from the prior predictive distribution\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta)p(\\theta) d\\theta,\n\\]\nwhere we proceed by following the iterative procedure below\n1. sample theta_i from the prior p(theta)\n2. sample ytilde from p(ytilde | theta_i)\n3. repeat steps 1 and 2\n\nthis can be useful to see if a prior for \\(p(\\theta)\\) actually translate to reasonable prior beliefs about the data.\n\n\n\n\n\n\n\nExercise\n\n\n\nFor \\(p(\\theta) = \\text{gamma}(8,2)\\), plot \\(p(\\tilde{y})\\) assuming \\(\\tilde{y} | \\theta \\sim \\text{Poisson}(\\theta)\\).\n\n\n\n\n\n\n\nPosterior predictive distribution\nWe can also sample \\(\\tilde{y}\\) from the posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta,\n\\]\nwhere the procedure is the same as before, except step 1 is replace with sampling \\(\\theta\\) from the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\).\nThe resulting sequence \\((\\theta^{(1)}, \\tilde{y}^{(1)}), \\ldots, (\\theta^{(N)}, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the joint posterior of \\((\\theta, \\tilde{Y})\\). The sequence \\(\\tilde{y}^{(1)}, \\ldots, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the marginal posterior distribution of \\(\\tilde{Y}\\), aka the posterior predictive distribution."
  },
  {
    "objectID": "notes/MonteCarlo.html#posterior-predictive-model-checking",
    "href": "notes/MonteCarlo.html#posterior-predictive-model-checking",
    "title": "Monte Carlo Integration",
    "section": "Posterior predictive model checking",
    "text": "Posterior predictive model checking\nWe can assess the fit of a model by comparing the posterior predictive distribution to the empirical distribution.\n\nExample: is our Poisson model flawed?\n\n# load general social survey data\ngss = read_csv(\"https://sta360-fa23.github.io/data/gss.csv\")\n\n\ny1 = gss$CHILDS[gss$FEMALE == 1 &  gss$YEAR >= 1990  & gss$AGE == 40 & \n                   gss$DEGREE < 3 ]\ny1 = y1[!is.na(y1)]\nn = length(y1)\n\nWe are examining the number of children \\(Y_i\\) belonging to \\(n=\\) 111 40 year old women surveyed 1990 or later without a bachelor’s. These data come from the general social survey.\nSuppose\n\\[\n\\begin{aligned}\nY_i & \\sim \\text{Poisson}(\\theta)\\\\\n\\theta & \\sim \\text{gamma}(2, 1).\n\\end{aligned}\n\\]\nThe empirical and predictive distributions of the data are both plotted below.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\n# posterior predictive distribution\nytotal = sum(y1)\na = 2 ; b = 1\nN = 10000\ntheta.post.mc = rgamma(N, ytotal + a, b + n)\ny1.mc = rpois(N, theta.post.mc)\n\n# data\ndf = data.frame(y1) # empirical\ndf2 = data.frame(y1.mc) # post predictive\n  \n# make plot\ndf %>%\n  ggplot(aes(x = y1)) +\n  geom_bar(aes(x = y1 + .15, y = (..count..)/sum(..count..),\n               fill = \"empirical\"), alpha = 0.6, width = 0.3) +\n  geom_bar(data = df2, \n                 aes(x = y1.mc -.15, y = (..count..) / sum(..count..),\n                     fill = \"predictive\"), alpha = 0.4, width = 0.3) +\n  labs(x = \"number of children\", \n       y = TeX(\"$p(Y_i = y_i)$\"),\n       fill = \"\") +\n  scale_x_continuous(breaks = c(0:7), labels = c(0:7),\n                     limits = c(-.5,7.5)) +\n  \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nLet \\(\\mathbf{y}\\) be a vector of length 111. Let \\(t(\\mathbf{y})\\) be the ratio of \\(2\\)s to \\(1\\)s in \\(\\mathbf{y}\\). For our observed data, this test statistic \\(t(\\mathbf{y}_{obs}) = 38 / 19 = 2\\). What is the tail probability \\(p(t(\\tilde{\\mathbf{Y}}) \\geq t(\\mathbf{y}_{obs}))\\) under the posterior predictive distribution?"
  },
  {
    "objectID": "quizzes/quiz03.html",
    "href": "quizzes/quiz03.html",
    "title": "Quiz 3",
    "section": "",
    "text": "Exercise 1\nWrite “posterior” or “prior” in the blank below:\n\\(\\int p(\\tilde{y}|\\theta) p(\\theta | y_1,\\ldots y_n)d\\theta\\) is a ___ predictive distribution.\n\n\nExercise 2\nExpand \\(p(\\theta | y)\\) using Bayes’ rule (include the normalization constant).\n\n\nExercise 3\nTRUE or FALSE\nMonte Carlo integration error scales \\(\\mathcal{O}(\\frac{1}{\\sqrt{N}})\\) where \\(N\\) is the number of independent samples from the posterior.\n\n\n\n03:00"
  },
  {
    "objectID": "quizzes/quiz03.html#exercise-3",
    "href": "quizzes/quiz03.html#exercise-3",
    "title": "Quiz 3",
    "section": "Exercise 3",
    "text": "Exercise 3\nTRUE or FALSE\nMonte Carlo integration error scales \\(\\mathcal{O}(\\frac{1}{\\sqrt{N}})\\) where \\(N\\) is the number of independent samples from the posterior.\n\n\n\n03:00"
  },
  {
    "objectID": "notes/normalModel1.html",
    "href": "notes/normalModel1.html",
    "title": "The normal model",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/MonteCarlo.html#monte-carlo-error",
    "href": "notes/MonteCarlo.html#monte-carlo-error",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo error",
    "text": "Monte Carlo error\n\nHow many values should we simulate?\nRecall: expected values are integrals, and integrals are expected values. Since central limit theorem (CLT) deals with expected values…\nRecall: CLT states that if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\n\nHow to remember this/show this? Offline notes.\n\nSo to estimate \\(\\theta\\), we can generate \\(\\bar{\\theta}\\) by Monte Carlo simulation and report a confidence interval using quantiles of the normal given above in conjunction with the Monte Carlo standard error \\(\\frac{\\hat{\\sigma}}{\\sqrt{N}}\\)\nThis means we get convergence at the rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\nRecall:\n\nsd1 = pnorm(1) - pnorm(-1)\nsd2 = pnorm(2) - pnorm(-2)\nsd3 = pnorm(3) - pnorm(-3)\n\n\na 0.6826895% confidence interval can be obtained using \\(\\pm 1\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9544997% confidence interval can be obtained using \\(\\pm 2\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9973002% confidence interval can be obtained using \\(\\pm 3\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\n\n\n\nExample\n\n# Let theta be \"x\" in the code below\nset.seed(123)\n\n# binomial(n, p)\nn = 20\np = 0.4\n\n# mean, variance, sd of a binomial(n, p)\nEX = n*p # 20*.4 = 8\nVarX = n*p*(1-p) # 20*.4*.6 = 4.8\nsdX = sqrt(VarX) # 2.19089\n\n# Monte Carlo sample of size N\nN = 100\nxSamples = rbinom(N, size = n, prob = p) \n\n# sample mean, var, sd\nxbar = mean(xSamples)\nxvar = var(xSamples)\nxsigma = sd(xSamples) # = sqrt(sum((xSamples - xbar)^2) / (N -1))\n\nse = xsigma / sqrt(N)\n\nlb = round(xbar - (2*se), 3)\nub = round(xbar + (2*se), 3)\n\nFor N = 100 Monte Carlo samples, The posterior mean of \\(\\theta\\) is \\(\\bar{\\theta} =\\) 8.01 with 95% confidence interval (7.57 8.45).\n\n\n\n\n\n\nExercise\n\n\n\nAbove we estimate \\(Var(\\theta)\\) to be 4.838 and the standard error for \\(N = 100\\) was 0.22.\nIf you wanted to state \\(p(\\theta \\in (\\hat{\\theta} \\pm 0.01)) = 0.95\\), how large would \\(N\\) have to be?\nCheck your answer by adjusting \\(N\\) above."
  },
  {
    "objectID": "notes/normalModel1.html#components-of-the-normal",
    "href": "notes/normalModel1.html#components-of-the-normal",
    "title": "The normal model",
    "section": "Components of the normal",
    "text": "Components of the normal\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nVocabulary\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance has a special name, precision. Mathematically we will call precision \\(\\lambda^2 = \\frac{1}{\\sigma^2}\\). Intuitively, precision tells us how close \\(y_i\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#one-parmaeter-inference",
    "href": "notes/normalModel1.html#one-parmaeter-inference",
    "title": "The normal model",
    "section": "One parmaeter inference",
    "text": "One parmaeter inference"
  },
  {
    "objectID": "notes/normalModel1.html#normal-definition",
    "href": "notes/normalModel1.html#normal-definition",
    "title": "The normal model",
    "section": "Normal definition",
    "text": "Normal definition\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nVocabulary\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance has a special name, precision. Mathematically we will call precision \\(\\lambda^2 = \\frac{1}{\\sigma^2}\\). Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#background",
    "href": "notes/normalModel1.html#background",
    "title": "The normal model",
    "section": "Background",
    "text": "Background\n\nDefinition and vocabulary\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2  \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (x-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance \\((\\frac{1}{\\sigma^2})\\) has a special name, precision. Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/normalModel1.html#bayesian-inference",
    "href": "notes/normalModel1.html#bayesian-inference",
    "title": "The normal model",
    "section": "Bayesian inference",
    "text": "Bayesian inference\nIn general, we wish to make inference about \\(\\theta\\) and \\(\\sigma^2\\) after observing some data \\(y_1, \\ldots y_n\\) and thus are interested in the posterior \\(p(\\theta, \\sigma^2 | y_1, \\ldots y_n)\\). This is the standard task we have seen thus far, and requires us to specify a joint prior \\(p(\\theta, \\sigma^2)\\). Below, we will work to find a class of conjugate priors over \\(\\theta\\) and \\(\\sigma^2\\).\nWe can break up the joint posterior into two pieces from the axioms of probability:\n\\[\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\n\\]\nThis suggests that we calculate the joint posterior by:\n\nfirst finding the full conditional of \\(\\theta\\): \\(p(\\theta| \\sigma^2, \\vec{y})\\)\nand then finding the marginal posterior of \\(\\sigma^2\\): \\(p(\\sigma^2 | \\vec{y})\\),\n\nwhere \\(\\vec{y} = \\{y_1, \\ldots y_n\\}\\).\n\nThe full conditional of \\(\\theta\\)\nBy Bayes’ theorem,\n\\[\np(\\theta| \\sigma^2, \\vec{y}) \\propto \\underbrace{p(\\vec{y} |\\theta, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\theta|\\sigma^2)}_{\\text{prior}}.\n\\]\nTo arrive at the full conditional posterior of \\(\\theta\\), we must first specify a prior on \\(\\theta\\).\nConsidering we have a normal likelihood, what is a conjugate class of densities for \\(\\theta\\)?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\\(\\theta | \\sigma^2 \\sim N(\\mu_0, \\tau_0^2)\\) for some \\(\\mu_0 \\in \\mathbb{R}\\) and \\(\\tau_0^2 \\in \\mathbb{R}^+\\) is conjugate.\n\n\n\nWith the conjugate prior, our full conditional posterior \\(\\{ \\theta| \\sigma^2, \\vec{y} \\} \\sim N(\\mu_n, \\tau_n^2)\\) where\n\\[\n\\begin{aligned}\n\\mu_n &=\n\\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\n\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n}\n\\\\\n\\\\\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\end{aligned}\n\\]\n\nLet’s sketch out ‘completing the square’ to derive the parameters offline.\n\n\n\nIntuitive posterior parameters\nIf we consider the posterior precision, \\(\\frac{1}{\\tau_n^2}\\), we can re-arrange the terms above to illuminate how posterior information = prior information + data information;.\n\\[\n\\frac{1}{\\tau_n^2}= \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\\]\nIn words, posterior precision is equivalent to prior precision plus sampling precision. If we name each precision term, \\(\\lambda_0 = \\frac{1}{\\tau_0}\\), \\(\\lambda_n = \\frac{1}{\\tau_n}\\) and \\(\\lambda = \\frac{1}{\\sigma}\\) then\n\\[\n\\mu_n = \\frac{\\lambda_0^2}{\\lambda_0^2 + n\\lambda^2} \\mu_0 +\n\\frac{n\\lambda^2}{\\lambda_0^2 + n\\lambda^2} \\bar{y}\n\\]\ni.e. the posterior mean is the weighted average of prior and sample mean, where the weights are the relative contribution of each precision!\nWe can re-define \\(\\lambda_0^2 = \\kappa_0 \\lambda^2\\) (or equivalently \\(\\tau_0^2 = \\frac{\\sigma^2}{\\kappa_0}\\)) and obtain\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y},\\\\\n\\frac{1}{\\tau_n^2} &= \\frac{\\kappa_0 + n}{\\sigma^2}\n\\end{aligned}\n\\]\nwhere we can interpret \\(\\kappa_0\\) as the prior sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that \\(\\tau_n^2\\) is the posterior variance of the full conditional posterior of \\(\\theta\\). This is distinct from \\(\\sigma_n^2\\), defined below.\n\n\n\n\nPrior on \\(\\sigma^2\\)\nRemember, we want \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\). We have the first component of the right hand side, what about the second component?\nNotice that\n\\[\np(\\sigma^2 | \\vec{y}) \\propto p(\\sigma^2)\\int p(\\vec{y} | \\theta, \\sigma^2) p(\\theta|\\sigma^2) d\\theta\n\\]\nBut how do we choose \\(p(\\sigma^2)\\) to be conjugate? We can proceed in multiple ways: one is noting that the integral is really a convolution of normals, (thereby a sum of normals) and is therefore a normal density.\nUpon inspection, we can see a suitable choice is \\(\\frac{1}{\\sigma^2} \\sim \\text{gamma}(a, b)\\).\n\n\nThe inverse-gamma\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if \\(\\frac{1}{X}\\) has a gamma(a,b) distribution.\nIf X has an inverse-gamma distribution, the density of X is\n\\[\np(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1}e^{-b/x} \\ \\text{for } \\ x > 0\n\\]\nand\n\\[\n\\begin{aligned}\nEX &= \\frac{b}{(a-1)} \\text{ if } a \\geq 1; \\ \\infty \\text{ if } 0<a<1,\\\\\nVar(X) &= \\frac{b^2}{(a-1)^2(a-2)} \\ \\text{if } a \\geq 2; \\ \\infty \\text{ if } 0 < a < 2,\\\\\nMode(X) &= \\frac{b}{a +1}.\n\\end{aligned}\n\\]\n\n\nThe marginal posterior of \\(\\sigma^2\\)\nTaken all together, if we let our sampling model and prior distributions be such that\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\]\nthen the posterior\n\\[\n\\frac{1}{\\sigma^2} | \\vec{y} \\sim \\text{gamma}(\\frac{\\nu_n}{2}, \\frac{\\nu_n \\sigma^2_n}{2}),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\nu_n &= \\nu_0 + n,\\\\\n\\sigma^2_n &= \\frac{1}{\\nu_n} \\left[\n\\nu_0 \\sigma^2_0 +(n-1)s^2 + \\frac{\\kappa_0 n}{\\kappa_0 + n}(\\bar{y} - \\mu_0)^2\n\\right],\n\\end{aligned}\n\\]\nand \\(s^2\\) is the sample variance, \\(\\frac{1}{n-1} \\sum_i (y_i - \\bar{y})^2\\)."
  },
  {
    "objectID": "notes/normalModel1.html#the-marginal-posterior-of-sigma2",
    "href": "notes/normalModel1.html#the-marginal-posterior-of-sigma2",
    "title": "The normal model",
    "section": "The marginal posterior of \\(\\sigma^2\\)",
    "text": "The marginal posterior of \\(\\sigma^2\\)"
  },
  {
    "objectID": "notes/normalModel1.html#posterior-estimates-via-monte-carlo-sampling",
    "href": "notes/normalModel1.html#posterior-estimates-via-monte-carlo-sampling",
    "title": "The normal model",
    "section": "Posterior estimates via Monte Carlo sampling",
    "text": "Posterior estimates via Monte Carlo sampling\n\n# setting hyperparameters\nnu0 = 3; s20 = 1\nk0 = 1; mu0 = 2\n\n# data\ny = c(1.64, 1.70, 1.72, 1.82, 1.82, 1.82, 1.90, 2.08)\nn = length(y)\nybar = mean(y)\ns2 = var(y)\n\n# posterior via Monte Carlo sampling\n\nN = 10000\ns2.mc = 1 / rgamma(N, nu0 + n, )"
  },
  {
    "objectID": "notes/normalModel1.html#computing-the-joint-posterior",
    "href": "notes/normalModel1.html#computing-the-joint-posterior",
    "title": "The normal model",
    "section": "Computing the joint posterior",
    "text": "Computing the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can compute the joint posterior by sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\) to draw samples from the joint posterior.\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "slides/lab3-review.html#exercise",
    "href": "slides/lab3-review.html#exercise",
    "title": "Exam practice",
    "section": "Exercise",
    "text": "Exercise\nPhysicists studying a radioactive substance measure the times at which the substance emits a particle. They will record \\(n+1\\) emissions and set \\(Y_1\\) to be the time elapsed between the first and second emission, \\(Y_2\\) to be the time elapsed between the second and third emission and so on. They will model the data as \\(Y_1, \\ldots Y_n | \\theta \\sim \\text{exponential}(\\theta)\\). The pdf of the exponential(\\(\\theta\\)) distribution is\n\\[\np(y |\\theta) = \\theta e^{-\\theta y} \\ \\text{ for } \\ y>0, \\ \\theta>0.\n\\]\nFor this distribution, \\(E[Y|\\theta] = \\frac{1}{\\theta}\\).\n(a). Write out the corresponding joint density \\(p(y_1, \\ldots, y_n | \\theta)\\) and simplify as much as possible. Justify each step of your calculation.\n(b). For fixed values of \\(y_1, \\ldots y_n\\), find the value of \\(\\theta\\) that maximizes \\(p(y_1, \\ldots, y_n | \\theta)\\) as a function of \\(\\theta\\), and call this maximizing value \\(\\hat{\\theta}\\). Hint: \\(\\hat{\\theta}\\) can also be found by maximizing \\(\\log p(y_1, \\ldots, y_n | \\theta)\\), which is easier to work with.\n(c). Suppose your information about \\(\\theta\\) can be described with a gamma(\\(a, b\\)) prior distribution for some values of \\(a\\) and \\(b\\). Write out the formula for \\(p(\\theta | y_1, \\ldots y_n)\\), up to a proportionality in \\(\\theta\\), and simplify as much as possible. From this, identify explicitly the posterior distribution of \\(\\theta\\) (i.e., write “the posterior is a blank distribution with parameter(s) blank)”.\n(d). Obtain the formula for \\(E[\\theta, y_1, \\ldots y_n]\\) as a function of \\(a, b n\\) and \\(y_1, \\ldots y_n\\), and try to write this as a function of the estimator \\(\\hat{\\theta}\\) you found in part (b). What does \\(E[\\theta | y_1,\\ldots,y_n]\\) get close to as \\(n\\) increases?\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "solutions/workshop.html",
    "href": "solutions/workshop.html",
    "title": "Workshopping",
    "section": "",
    "text": "Proof of concept\nWe have some data:\n\n# generating 10 samples from the population\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "notes/exam-notes.html",
    "href": "notes/exam-notes.html",
    "title": "Exam notes",
    "section": "",
    "text": "A random variable \\(X \\in \\mathbb{R}\\) has a \\(N(\\theta, \\sigma^2)\\) distribution if \\(\\sigma^2 > 0\\) and\n\\(p(x | \\theta, \\sigma^2) = (2 \\pi \\sigma^2)^{-\\frac{1}{2}} e^{-\\frac{1}{2\\sigma^2}(x - \\theta)^2} \\ \\ \\ \\text{ for } -\\infty < x < \\infty.\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has a gamma(a,b) distribution if \\(a > 0, b > 0\\) and\n\\(p(x |a,b) = \\frac{b^a}{\\Gamma(a)} x^{a - 1} e^{-bx} \\ \\ \\ \\text{ for } x > 0.\\)\n\\(E[X | a, b] = a/b\\), \\(Var[X | a,b] = a / b^2\\)\n\n\n\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if 1/X has a gamma(a,b) distribution. If \\(X\\) is inverse-gamma(a,b) then the density of X is\n\\(p(x|a,b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1} e^{-b/x} \\ \\ \\ \\text{ for } x > 0.\\)\n\\(E[X|a,b] = \\frac{b}{a-1}\\) if \\(a>=1\\), \\(\\infty\\) if \\(0<a<1\\)\n\\(Var[X|a,b] = \\frac{b^2}{(a-1)^2(a-2)}\\) if \\(a\\geq2\\), \\(\\infty\\) if \\(0<a<2\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, \\ldots, n\\}\\) has a binomial\\((n, \\theta)\\) distribution if \\(\\theta \\in [0, 1]\\) and\n\\(p(X = x| \\theta, n) = {n \\choose x} \\theta^x (1- \\theta)^{n-x} \\ \\ \\ \\text{ for } x\\in \\{0, 1, \\ldots, n \\}\\)\n\\(E[X|\\theta] = n\\theta\\), \\(Var[X|\\theta] = n\\theta(1-\\theta)\\)\n\n\n\nA random variable \\(X \\in [0, 1]\\) has a beta(a,b) distribution if \\(a > 0, b > 0\\) and\n\\(p(x|a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} x^{a-1} (1-x)^{b-1} \\ \\ \\ \\text{ for } 0 \\leq x \\leq 1.\\)\n\\(E[X|a,b] = \\frac{a}{a + b}\\), \\(Var[X|a,b] = \\frac{ab}{(a + b + 1)(a + b)^2}\\)\n\n\n\nA random variable \\(X \\in \\{0, 1, 2, \\ldots \\}\\) has a Poisson(\\(\\theta\\)) distribution if \\(\\theta > 0\\) and\n\\(p(X = x | \\theta) = \\theta^x \\frac{e^{-\\theta}}{x!} \\ \\ \\ \\text{ for } x \\in \\{0, 1, 2, \\ldots\\}\\)\n\\(E[X|\\theta] = \\theta\\), \\(Var[X|\\theta] = \\theta\\)\n\n\n\nA random variable \\(X \\in [0, \\infty)\\) has a exponential(\\(\\theta\\)) distribution if \\(\\theta >0\\) and\n\\(p(x | \\theta) = \\theta e^{-\\theta x}\\)\n\\(E[X|\\theta] = \\frac{1}{\\theta}\\), \\(Var[X|\\theta] = \\frac{1}{\\theta^2}\\)"
  },
  {
    "objectID": "chapterSummaries.html#definitions-and-conjugacy",
    "href": "chapterSummaries.html#definitions-and-conjugacy",
    "title": "Chapter summaries",
    "section": "Definitions and conjugacy",
    "text": "Definitions and conjugacy\n\nBe able to define likelihood, prior, poserior, normalizing constant\n\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\n\nExamples of conjugate models: beta-binomial, gamma-Poisson."
  },
  {
    "objectID": "chapterSummaries.html#reliability",
    "href": "chapterSummaries.html#reliability",
    "title": "Chapter summaries",
    "section": "Reliability",
    "text": "Reliability\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nExponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi | n_0, t_0) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\)."
  },
  {
    "objectID": "chapterSummaries.html#exponential-families",
    "href": "chapterSummaries.html#exponential-families",
    "title": "Chapter summaries",
    "section": "Exponential families",
    "text": "Exponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\)."
  },
  {
    "objectID": "chapterSummaries.html#chapter-3",
    "href": "chapterSummaries.html#chapter-3",
    "title": "Chapter summaries",
    "section": "Chapter 3",
    "text": "Chapter 3\n\nDefinitions and conjugacy\n\nBe able to define likelihood, prior, posterior, normalizing constant\n\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\n\nExamples of conjugate models: beta-binomial, gamma-Poisson.\n\n\n\nReliability\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\n\nExponential families\nIf density \\(p(y|\\theta)\\) can be written \\(h(y) c(\\phi) e^{\\phi t(y)}\\) for some transform \\(\\phi = f(\\theta)\\) we can say \\(p(y|\\theta)\\) belongs in the exponential family, and the conjugate prior is \\(p(\\phi | n_0, t_0) =c(\\phi)^{n_0} e^{n_0 t_0 \\phi}\\). Note: the conjugate prior is given over \\(\\phi\\) and we’d have to transform back if we care about \\(p(\\theta)\\)."
  },
  {
    "objectID": "chapterSummaries.html#chapter-4",
    "href": "chapterSummaries.html#chapter-4",
    "title": "Chapter summaries",
    "section": "Chapter 4",
    "text": "Chapter 4\n\nPredictive distributions\nThe posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta\n\\]\nwhen \\(Y | \\theta\\) conditionally iid.\nThe prior predictive distribution,\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta) p(\\theta)d\\theta.\n\\]\nNotice both the posterior and prior predictive distributions are represented as integrals. Integrals are expectations. This means we can use Monte Carlo integration to approximate.\nTo approximate the posterior predictive distribution:\n\nsample from the posterior of theta, \\(p(\\theta|y_1,\\ldots y_n)\\)\nsample from data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\nTo approximate the prior predictive distribution:\n\nsample from the prior of theta, \\(p(\\theta)\\)\nsample from the data generative model \\(p(\\tilde{y}|\\theta)\\) for the values of theta sampled in (1).\n\n\n\nMonte Carlo error\nSince Monte Carlo approximation can be viewed as a sample mean approximating an expected value, CLT applies.\nMore specifically, if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\nand Monte Carlo estimates converge at a rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\n\n\nThe sampling view\nIf we have a posterior \\(p(\\theta | y_1, \\ldots y_n)\\) that we can sample from and we want some summary of the posterior… e.g. we want\n\n\\(p(\\theta < a)\\)\nquantiles of the posterior , or\nthe posterior of some transform \\(f(\\theta)\\),\n\nthen we can simply sample from the posterior to obtain an empirical approximation of the posterior and then report the empirical quantity of interest. This is also called Monte Carlo approximation.\nThe procedure can be written:\n\nsample from the posterior \\(p(\\theta |y_1, \\ldots y_n)\\) some large number of times and then\ncompute the quantity of interest"
  },
  {
    "objectID": "hw/hw04.html",
    "href": "hw/hw04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Let\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, 1/\\gamma)\\\\\n\\theta | \\sigma^2 &\\sim N(\\mu_0, 1/\\gamma \\kappa_0)\\\\\n\\gamma &\\sim \\text{gamma}(a, b)\n\\end{aligned}\n\\]\nso \\(\\gamma\\) is the precision (inverse-variance) of the normal distribution.\n\nDerive and simplify the joint pdf \\(p(y_1, \\ldots y_n | \\theta, \\gamma)\\)\nDerive the posterior of the precision, \\(p(\\gamma| y_1, \\ldots y_n)\\).\nDerive the posterior of \\(\\theta\\), \\(p(\\theta | y_1, \\ldots y_n)\\)"
  },
  {
    "objectID": "hw/hw04.html#exercise-2",
    "href": "hw/hw04.html#exercise-2",
    "title": "Homework 4",
    "section": "Exercise 2",
    "text": "Exercise 2\nExercise 5.1 from Hoff. You can read in the data from the three schools with the R code below. Hint: the problem specification is the same as exercise 1, except \\(a = \\nu_0/2\\) and \\(b = \\nu_0 \\sigma_0^2/2\\).\n\nlibrary(tidyverse)\nschool1 = read_csv(\"https://sta360-fa23.github.io/data/school1.csv\")\nschool2 = read_csv(\"https://sta360-fa23.github.io/data/school2.csv\")\nschool3 = read_csv(\"https://sta360-fa23.github.io/data/school3.csv\")"
  },
  {
    "objectID": "notes/normalModel1.html#sampling-from-the-joint-posterior",
    "href": "notes/normalModel1.html#sampling-from-the-joint-posterior",
    "title": "The normal model",
    "section": "Sampling from the joint posterior",
    "text": "Sampling from the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can sample from the joint posterior by first sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\).\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(1000, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "hw/hw04.html#exercise-3",
    "href": "hw/hw04.html#exercise-3",
    "title": "Homework 4",
    "section": "Exercise 3",
    "text": "Exercise 3\n3.12 from Hoff."
  },
  {
    "objectID": "notes/lec01-probability.html",
    "href": "notes/lec01-probability.html",
    "title": "Probability",
    "section": "",
    "text": "This is foundational material. Most of it is background you will have learned in STA230/240. While dry, we must soldier on to get to the exciting stuff."
  },
  {
    "objectID": "notes/lec01-probability.html#review-set-theory",
    "href": "notes/lec01-probability.html#review-set-theory",
    "title": "Probability",
    "section": "Review: set theory",
    "text": "Review: set theory\n\n\n\n\n\n\nDefinition\n\n\n\nset: a collection of elements, denoted by {}\nExamples\n\n\\(\\phi\\) = {} “the empty set”\nA = {1, 2, 3}\nB = {taken STA199, has not taken STA199}\nC = {{1,2,3}, {4, 5}}\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsubset: denoted by \\(\\subset\\), \\(A \\subset B\\) iff \\(a \\in A \\implies a \\in B\\)\nExamples\nUsing the previously examples of A, B and C above,\n\n\\(A \\subset C\\)\n\\(A \\not\\subset B\\)\n\n\n\nRecall:\n\n\\(\\cup\\) means “union”, “or”\n\\(\\cap\\) means “intersection”, “and”\n\n\n\n\n\n\n\nDefinition\n\n\n\npartition: {\\(H_1, H_2, ... H_n\\)} = \\(\\{H_i\\}_{i = 1}^n\\) is a partition of \\(\\mathcal{H}\\) if\n\nthe union of sets is \\(\\mathcal{H}\\) i.e. \\(\\cup_{i = 1}^n H_i = \\mathcal{H}\\)\nthe sets are disjoint i.e. \\(H_i \\cap H_j = \\phi\\) for all \\(i \\neq j\\)\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nsample space: \\(\\mathcal{H}\\), the set of all possible data sets (outcomes)\nevent: a set of one or more outcomes\nNote: p(\\(\\mathcal{H}\\)) = 1\nExamples\n\nRoll a six-sided die once. The sample space \\(\\mathcal{H} = \\{1, 2, 3, 4, 5, 6\\}\\).\nLet \\(A\\) be the event that the die lands on an even number. \\(A = \\{2, 4, 6 \\}\\)"
  },
  {
    "objectID": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "href": "notes/lec01-probability.html#axioms-of-probability-in-words",
    "title": "Probability",
    "section": "Axioms of probability (in words)",
    "text": "Axioms of probability (in words)\nP1. Probabilities are between 0 and 1, importantly p(\\(\\neg\\)H|H) = 0 and p(H|H) = 1.\nP2. If two events A and B are disjoint, then p(A or B) = p(A) + p(B)\nP3. The joint probability of two events may be broken down stepwise: p(A,B) = p(A|B)p(B)\n–\nIt follows that\n\nfor any partition \\(\\{H_i\\}_{i = 1}^n\\), \\(\\sum_{i=1}^n p(H_i) = 1\\) (rule of total probability)\n\nnote: simplest partition \\(p(A) + p(\\neg A) = 1\\)\n\n\\(p(A) = \\sum_{i=1}^n p(A, H_i)\\) (rule of marginal probability)\n\nnote: P3 implies that equivalently, \\(p(A) = \\sum_{i=1}^n p(A | H_i) p(H_i)\\)\n\np(A|B) = p(A,B) / p(B) when p(B) \\(\\neq 0\\)\n\nnote: these statements can also be made where each term is additionally conditioned on another event C\n\n\n\n\n\n\n\n\nExercise\n\n\n\nDerive Bayes’ rule:\n\\(p(H_i|X) = \\frac{p(X|H_i)p(H_i)}{\\sum_k p(X|H_k)p(H_k)}\\)\nusing the axioms of probability.\n\n\nBayes’ rule tells us how to update beliefs about \\(\\{H_i \\}_{i = 1}^n\\) given data \\(X\\)."
  },
  {
    "objectID": "notes/lec01-probability.html#independence",
    "href": "notes/lec01-probability.html#independence",
    "title": "Probability",
    "section": "Independence",
    "text": "Independence\n\n\n\n\n\n\nDefinition\n\n\n\nTwo events \\(F\\) and \\(G\\) are conditionally independent given \\(H\\) if \\(p(F, G | H) = p(F | H) p(G | H)\\)\n\n\n\n\n\n\n\n\nExercise\n\n\n\nShow conditional independence implies\n\\(p(F | H, G) = p(F | H)\\)\n\n\nThis means that if we know H, then G does not supply any additional information about F."
  },
  {
    "objectID": "notes/lec01-probability.html#random-variables",
    "href": "notes/lec01-probability.html#random-variables",
    "title": "Probability",
    "section": "Random variables",
    "text": "Random variables\n\n\n\n\n\n\nDefinition\n\n\n\nIn Bayesian inference, a random variable is an unknown numerical quantity about which we make probability statements.\nExamples\n\nData. E.g. the amount of a wheat a field will yield later this year. Since this data has not yet been generated, the quantity is unknown.\nA population parameter. E.g. the true mean resting heart rate of Duke students. Note: this is a fixed (non-random) quantity, but it is also unknown. We use probability to describe our uncertainty in this quantity.\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ndiscrete random variable: a random variable that takes countably many values. Y is discrete if its possible outcomes can be enumerated \\(\\mathcal{Y} = \\{y_1, y_2, \\ldots \\}\\).\nNote: discrete does not mean finite. There may be infinitely many outcomes!\nExamples\n\nY = the number of children of a randomly sampled person\nY = the number of visible stars in the sky on a randomly sampled night of the year\n\nFor each \\(y \\in \\mathcal{Y}\\), let p(Y) = probability(Y = y). Then p is the probability mass function (pmf) of the random variable Y.\nExamples\n\nBinomial pmf: the probability of \\(y\\) successes in \\(n\\) trials, where each trial has an individual probability of success \\(\\theta\\).\n\\[p(y | \\theta) = {n \\choose y} \\theta ^y (1-\\theta)^y \\text{ for } y \\in \\{0, 1, \\ldots n \\}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots n\\}\\)\nsuccess probability \\(\\theta \\in [0, 1]\\)\ndbinom(y, n, theta) computes this pmf in R\n\nPoisson pmf: probability of \\(y\\) events occurring during a fixed interval at a mean rate \\(\\theta\\)\n\\[p(y | \\theta) = \\frac{\\theta^y e^{-\\theta}}{y!}\\]\n\nsupport: \\(y \\in \\{0, 1, 2, \\ldots \\}\\)\nrate \\(\\theta \\in \\mathbb{R}^+\\)\ndpois(y, theta) computes this pmf in R\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\ncontinuous random variable: a random variable that takes uncountably many values.\nThe probability density function (pdf) of a continuous random variable, X is defined\n\\(pdf(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{p(x < X < x + \\Delta x)}{\\Delta x}\\)\nand the probability X is in some interval,\n\\(p(x_1 < X < x_2) = \\int_{x_1}^{x_2} pdf(x) dx\\)\nExamples\n\nNormal pdf \\[\np(x | \\mu, \\sigma) = (2\\pi \\sigma^2)^{-\\frac{1}{2}}e^{-\\frac{1}{2\\sigma^2}(x-\\mu)^2}\n\\]\nUniform pdf \\[p(x|a,b) =\n\\begin{cases}\n\\frac{1}{b - a} \\hspace{.6cm}\\text{ for } x \\in [a, b]\\\\\n0 \\hspace{1cm}\\text{ otherwise }\n\\end{cases}\\]\n\n\n\nNote: we will often abuse notation and use \\(p(x)\\) in place of \\(pmf(x)\\) and \\(pdf(x)\\) and prob(event), where only the context makes meaning clear.\nFor pmfs\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\leq 1\\\\\n\\sum_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nSimilarly, for pdfs,\n\\[\n\\begin{aligned}\n0 \\leq p(y) \\ \\text{and} \\\\\n\\int_{y \\in \\mathcal{Y}} p(y) = 1\n\\end{aligned}\n\\]\nNote: For a continuous random variable Y, p(y) can be larger than 1 and p(y) is not p(Y = y), which equals 0.\n\n\n\n\n\n\nDefinition\n\n\n\nThe part of the density/mass function that depends on the variable is called the kernel.\nExample\n\nthe kernel of the normal pdf is \\(e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nWhat’s the kernel of a gamma random variable X?\nRecall: the pdf of a gamma distribution:\n\\[\np(x | \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha - 1} e^{-\\beta x}\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#moments",
    "href": "notes/lec01-probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nFor a random variable X, the \\(n\\)th moment is defined as E(\\(X^n\\)).\nRecall, the expected value is defined for discrete random variable X,\n\\[\nE(X) = \\sum_{x \\in \\mathcal{X}} x p(x)\n\\]\nand for continuous random variable Y,\n\\[\nE(Y) = \\int_{-\\infty}^{\\infty} y p(y) dy\n\\]\nThe variance of a random variable, is also known as the second central moment and is defined\n\\[\nE(X - E(X))^2\n\\] or equivalently,\n\\[\nE(X^2) - E(X)^2\n\\]\nMore generally, the covariance between two random variables X and Y is defined\n\\[\nE[(X - E[X])(Y - E[Y])]\n\\]"
  },
  {
    "objectID": "notes/lec01-probability.html#exchangeability",
    "href": "notes/lec01-probability.html#exchangeability",
    "title": "Probability",
    "section": "Exchangeability",
    "text": "Exchangeability\n\noffline notes"
  },
  {
    "objectID": "notes/lec02-estimation.html",
    "href": "notes/lec02-estimation.html",
    "title": "Is this a fair coin?",
    "section": "",
    "text": "outputcode\n\n\n\n\n [1] 0 1 0 0 0 0 0 0 0 0\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(glue)\nlibrary(patchwork)\n\nset.seed(3)\nflips = rbinom(5000, size = 1, prob = 0.25)\nflips %>% head(10)\nWe observe 10 flips from the same coin above, where 0 is “tails” and 1 is “heads”. In summary, we see Y = 1 heads in 10 coin flips. Is this a fair coin?\nTo articulate this mathematically, let \\(\\theta \\in [0, 1]\\) be the bias-weighting (the chance of heads) of the coin. Fundamentally, we want \\(p(\\theta | y)\\), which we can expand via Bayes’ rule,\n\\[\np(\\theta | y) = \\frac{p(y|\\theta) p(\\theta)}{\\int_{\\theta \\in \\Theta} p(y|\\theta) p(\\theta) d\\theta}\n\\]\nLikelihood: the data generative process. The joint probability (or density) of the data given the parameters of the model. Most often thought of as a function of the parameter. Note: not a density of the parameter.\nPrior: Our a priori (beforehand) beliefs about the true population characteristics.\nPosterior: Our a posteriori (afterwards) beliefs about the true population characteristics after having observed the data set \\(y\\).\nNormalizing constant: A number that enables a pmf or pdf to integrate to 1."
  },
  {
    "objectID": "notes/lec02-estimation.html#uniform-prior",
    "href": "notes/lec02-estimation.html#uniform-prior",
    "title": "Is this a fair coin?",
    "section": "Uniform prior",
    "text": "Uniform prior\nLet \\(y\\) be the number of heads in \\(n\\) coin flips.\n\\[\np(\\theta | y) \\propto \\theta^{y}(1-\\theta)^{n-y}\n\\]\nThis is the kernel of a ___ density, where \\(\\alpha = y + 1\\) and \\(\\beta = n - y + 1\\), hence\n\\[\np(\\theta | y) = \\frac{\\Gamma(n + 2)}{\\Gamma(y + 1)\\Gamma(n-y+1)} \\theta^{y}(1-\\theta)^{n-y}\n\\]\nand the posterior mean is \\(\\frac{y + 1}{n + 2}\\) and the posterior variance is \\(\\frac{(y+1)(n - y + 1)}{(n + 2)^2 (n + 1)}\\).\nLet’s examine how the posterior evolves with each successive coin flip.\n\nplotscode\n\n\n\n\n\n\n\n\n\n\nN = c(0, 1, 2, 3, 4, 10, 100, 1000, 5000)\n\nfor (i in seq_along(N)) {\nn = N[i]\nif(n == 0) {\n  y = 0\n}\nelse {\n  y = sum(flips[1:n])\n}\n\nx = 0:1 # range\ndf = data.frame(x)\nassign(paste0(\"p\", i),\n  df %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun=dbeta, \n                args = list(shape1 = y + 1, shape2 = n - y + 1)) +\n  labs(y = TeX(\"$p(\\\\theta | y)$\"), x = TeX(\"$\\\\theta$\"),\n       title = glue(\"n = {n}\")) +\n  theme_bw()\n)\n}\n\n(p1 + p2 + p3) / \n  (p4 + p5 + p6) / \n  (p7 + p8 + p9) +\n  plot_annotation(title = \"Figure 1\")"
  },
  {
    "objectID": "notes/lec02-estimation.html#conjugacy",
    "href": "notes/lec02-estimation.html#conjugacy",
    "title": "Is this a fair coin?",
    "section": "Conjugacy",
    "text": "Conjugacy\nIf \\(\\theta \\sim\\) Uniform(0, 1) then \\(p(\\theta)\\) = 1 for all \\(\\theta \\in [0, 1]\\).\nSimilarly, if \\(\\theta \\sim\\) beta(1, 1), then \\(p(\\theta) = 1\\).\nClaim:\nIf\n\\[\n\\begin{aligned}\n\\theta &\\sim \\text{beta}(a, b)\\\\\nY | \\theta &\\sim \\text{binomial}(n, \\theta)\n\\end{aligned}\n\\]\nthen\n\\[\np(\\theta | Y) = \\text{beta}(y + a, n - y + b)\n\\]\n\n\n\n\n\n\nDefinition\n\n\n\nA prior \\(p(\\theta)\\) is said to be conjugate to the data generative model \\(p(y|\\theta)\\) if the family of the posterior is necessarily in the same family as the prior. In math, \\(p(\\theta)\\) is conjugate to \\(p(y|\\theta)\\) if\n\\[\np(\\theta) \\in \\mathcal{P} \\implies p(\\theta | y) \\in \\mathcal{P}\n\\]\n\n\nWhile conjugate priors make calculation easy, they may not accurately reflect our prior beliefs.\n\n\n\n\n\n\nExercise\n\n\n\nProve the claim above."
  },
  {
    "objectID": "notes/lec02-estimation.html#other-priors",
    "href": "notes/lec02-estimation.html#other-priors",
    "title": "Is this a fair coin?",
    "section": "Other priors",
    "text": "Other priors\nIncidentally, people are often satisfied with the choice of likelihood but are worried about the choice of prior.\nLet’s examine the effect of another couple of priors.\nGiven the coin’s dubious origin, we might believe a priori that the coin is biased. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(.5, .5)\n\\]\nOr alternatively, we might be strongly believe a priori that the coin is fair. How could we represent this belief?\n\\[\n\\theta \\sim \\text{beta}(20, 20)\n\\]\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nHow would you update the code of the previous example to show posterior inference under the prior \\(\\theta \\sim\\) beta(2,3)?"
  },
  {
    "objectID": "notes/lec02-estimation.html#prior-data",
    "href": "notes/lec02-estimation.html#prior-data",
    "title": "Is this a fair coin?",
    "section": "Prior data",
    "text": "Prior data\nIn the example above, the parameters, a and b, of the conjugate prior are often thought of as prior data.\n\na: “prior number of 1s”\nb: “prior number of 0s”\na + b: “prior sample size”\n\n\n\n\n\n\n\nExercise\n\n\n\nWe saw above that when a = 20 and b = 20, we needed more data to move the posterior.\nShow that the posterior mean, \\(E(\\theta | y) = \\frac{a + y}{a + b + n}\\) converges to the sample average as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "notes/lec03-reliability.html",
    "href": "notes/lec03-reliability.html",
    "title": "Posterior summaries and reliability",
    "section": "",
    "text": "Posterior mode: sometimes called “MAP” or “maximum a posteriori” estimate, this quantity is given by \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(\\theta | y)\\).\n\nNotice this unwinds to be \\(\\hat{\\theta} = \\arg \\max_{\\theta} p(y | \\theta) p(\\theta)\\).\n\n\n\n\n\n\n\nExercise\n\n\n\n\nShow that, for the uniform prior, \\(\\hat{\\theta} = y / n\\)\nCompare to maximum likelihood estimate (MLE); see notes on likelihoods\n\n\n\nOne way to report the reliability of the posterior mode is to look at the width of the posterior near the mode, which we can sometimes approximate with a Gaussian distribution:\n\\[\np(\\theta | y) \\approx C e^{\\frac{1}{2} \\frac{d^2L}{d\\theta^2}|_{\\hat{\\theta}} (\\theta - \\hat{\\theta})^2}\n\\]\nwhere \\(C\\) is a normalization constant and \\(L\\) is the log-posterior, \\(\\log p(\\theta | y)\\).\nTaken together, the fitted Gaussian with a mean equal to the posterior mode is called the Laplace approximation.\n\nLet’s derive the Laplace approximation offline"
  },
  {
    "objectID": "notes/lec03-reliability.html#confidence-regions",
    "href": "notes/lec03-reliability.html#confidence-regions",
    "title": "Posterior summaries and reliability",
    "section": "Confidence regions",
    "text": "Confidence regions\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(\\Phi\\) be the support of \\(\\theta\\). An interval \\((l(y), u(y)) \\subset \\Phi\\) has 95% posterior coverage if\n\\[\np(l(y) < \\theta < u(y) | y ) = 0.95\n\\]\nInterpretation: after observing \\(Y = y\\), our probability that \\(\\theta \\in (l(y), u(y))\\) is 95%.\nSuch an interval is called 95% posterior confidence interval (CI). It may also sometimes be referred to as a 95% “credible interval” to distinguish it from a frequentist CI.\n\n\nContrast posterior coverage to frequentist coverage:\n\n\n\n\n\n\nDefinition\n\n\n\nA random interval \\((l(Y), u(Y)\\)) has 95% frequentist coverage for \\(\\theta\\) if before data are observed,\n\\[\np(l(Y) < \\theta < u(Y) | \\theta) = 0.95\n\\]\nInterpretation: if \\(Y \\sim P_\\theta\\) then the probability that \\((l(Y), u(Y)\\) will cover \\(\\theta\\) is 0.95.\n\n\nIn practice, for many applied problems\n\\[\np(l(y) < \\theta < u(y) | y ) \\approx p(l(Y) < \\theta < u(Y) | \\theta)\n\\]\nsee section 3.1.2. in the book."
  },
  {
    "objectID": "notes/lec03-reliability.html#high-posterior-density",
    "href": "notes/lec03-reliability.html#high-posterior-density",
    "title": "Posterior summaries and reliability",
    "section": "High posterior density",
    "text": "High posterior density\n\n\n\n\n\n\nDefinition\n\n\n\nA \\(100 \\times (1-\\alpha)\\)% high posterior density (HPD) region is a set \\(s(y) \\subset \\Theta\\) such that\n\n\\(p(\\theta \\in s(y) | Y = y) = 1 - \\alpha\\)\nIf \\(\\theta_a \\in s(y)\\) and \\(\\theta_b \\not\\in s(y)\\), then \\(p(\\theta_a | Y = y) > p(\\theta_b | Y = y)\\)\n\n\n\n\nNote: all points inside an HPD region have higher posterior density than points outside the region.\n\n\n\n\n\n\n\nExercise\n\n\n\nIs the HPD region always an interval?"
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html",
    "href": "notes/lec05-MonteCarlo.html",
    "title": "Monte Carlo Integration",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#monte-carlo-error",
    "href": "notes/lec05-MonteCarlo.html#monte-carlo-error",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo error",
    "text": "Monte Carlo error\n\nHow many values should we simulate?\nRecall: expected values are integrals, and integrals are expected values. Since central limit theorem (CLT) deals with expected values…\nRecall: CLT states that if \\(\\theta_i |\\vec{y}\\) iid with mean \\(\\theta\\) and finite variance \\(\\sigma^2\\), for \\(i \\in \\{1, \\ldots, N\\}\\), then the sample mean\n\\[\n\\bar{\\theta} \\sim N(\\theta, \\frac{\\sigma^2}{N} ).\n\\]\n\nHow to remember this/show this? Offline notes.\n\nSo to estimate \\(\\theta\\), we can generate \\(\\bar{\\theta}\\) by Monte Carlo simulation and report a confidence interval using quantiles of the normal given above in conjunction with the Monte Carlo standard error \\(\\frac{\\hat{\\sigma}}{\\sqrt{N}}\\)\nThis means we get convergence at the rate \\(\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)\\) regardless of the dimension of the integral!\nRecall:\n\nsd1 = pnorm(1) - pnorm(-1)\nsd2 = pnorm(2) - pnorm(-2)\nsd3 = pnorm(3) - pnorm(-3)\n\n\na 0.6826895% confidence interval can be obtained using \\(\\pm 1\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9544997% confidence interval can be obtained using \\(\\pm 2\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\na 0.9973002% confidence interval can be obtained using \\(\\pm 3\\cdot \\hat{\\sigma}/\\sqrt{N}\\)\n\n\n\nExample\n\n# Let theta be \"x\" in the code below\nset.seed(123)\n\n# binomial(n, p)\nn = 20\np = 0.4\n\n# mean, variance, sd of a binomial(n, p)\nEX = n*p # 20*.4 = 8\nVarX = n*p*(1-p) # 20*.4*.6 = 4.8\nsdX = sqrt(VarX) # 2.19089\n\n# Monte Carlo sample of size N\nN = 100\nxSamples = rbinom(N, size = n, prob = p) \n\n# sample mean, var, sd\nxbar = mean(xSamples)\nxvar = var(xSamples)\nxsigma = sd(xSamples) # = sqrt(sum((xSamples - xbar)^2) / (N -1))\n\nse = xsigma / sqrt(N)\n\nlb = round(xbar - (2*se), 3)\nub = round(xbar + (2*se), 3)\n\nFor N = 100 Monte Carlo samples, The posterior mean of \\(\\theta\\) is \\(\\bar{\\theta} =\\) 8.01 with 95% confidence interval (7.57 8.45).\n\n\n\n\n\n\nExercise\n\n\n\nAbove we estimate \\(Var(\\theta)\\) to be 4.838 and the standard error for \\(N = 100\\) was 0.22.\nIf you wanted to state \\(p(\\theta \\in (\\hat{\\theta} \\pm 0.01)) = 0.95\\), how large would \\(N\\) have to be?\nCheck your answer by adjusting \\(N\\) above."
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#monte-carlo-prediction",
    "href": "notes/lec05-MonteCarlo.html#monte-carlo-prediction",
    "title": "Monte Carlo Integration",
    "section": "Monte Carlo prediction",
    "text": "Monte Carlo prediction\n\nPrior predictive distribution\nWe can use Monte Carlo to sample new observation, \\(\\tilde{y}\\), from the prior predictive distribution\n\\[\np(\\tilde{y}) = \\int p(\\tilde{y}|\\theta)p(\\theta) d\\theta,\n\\]\nwhere we proceed by following the iterative procedure below\n1. sample theta_i from the prior p(theta)\n2. sample ytilde from p(ytilde | theta_i)\n3. repeat steps 1 and 2\n\nthis can be useful to see if a prior for \\(p(\\theta)\\) actually translate to reasonable prior beliefs about the data.\n\n\n\n\n\n\n\nExercise\n\n\n\nFor \\(p(\\theta) = \\text{gamma}(8,2)\\), plot \\(p(\\tilde{y})\\) assuming \\(\\tilde{y} | \\theta \\sim \\text{Poisson}(\\theta)\\).\n\n\n\n\n\n\n\nPosterior predictive distribution\nWe can also sample \\(\\tilde{y}\\) from the posterior predictive distribution,\n\\[\np(\\tilde{y} | y_1, \\ldots y_n) = \\int p(\\tilde{y}|\\theta) p(\\theta|y_1, \\ldots, y_n)d\\theta,\n\\]\nwhere the procedure is the same as before, except step 1 is replace with sampling \\(\\theta\\) from the posterior \\(p(\\theta | y_1,\\ldots, y_n)\\).\nThe resulting sequence \\((\\theta^{(1)}, \\tilde{y}^{(1)}), \\ldots, (\\theta^{(N)}, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the joint posterior of \\((\\theta, \\tilde{Y})\\). The sequence \\(\\tilde{y}^{(1)}, \\ldots, \\tilde{y}^{(N)})\\) constitutes \\(N\\) independent samples from the marginal posterior distribution of \\(\\tilde{Y}\\), aka the posterior predictive distribution."
  },
  {
    "objectID": "notes/lec05-MonteCarlo.html#posterior-predictive-model-checking",
    "href": "notes/lec05-MonteCarlo.html#posterior-predictive-model-checking",
    "title": "Monte Carlo Integration",
    "section": "Posterior predictive model checking",
    "text": "Posterior predictive model checking\nWe can assess the fit of a model by comparing the posterior predictive distribution to the empirical distribution.\n\nExample: is our Poisson model flawed?\n\n# load general social survey data\ngss = read_csv(\"https://sta360-fa23.github.io/data/gss.csv\")\n\n\ny1 = gss$CHILDS[gss$FEMALE == 1 &  gss$YEAR >= 1990  & gss$AGE == 40 & \n                   gss$DEGREE < 3 ]\ny1 = y1[!is.na(y1)]\nn = length(y1)\n\nWe are examining the number of children \\(Y_i\\) belonging to \\(n=\\) 111 40 year old women surveyed 1990 or later without a bachelor’s. These data come from the general social survey.\nSuppose\n\\[\n\\begin{aligned}\nY_i & \\sim \\text{Poisson}(\\theta)\\\\\n\\theta & \\sim \\text{gamma}(2, 1).\n\\end{aligned}\n\\]\nThe empirical and predictive distributions of the data are both plotted below.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n\n# posterior predictive distribution\nytotal = sum(y1)\na = 2 ; b = 1\nN = 10000\ntheta.post.mc = rgamma(N, ytotal + a, b + n)\ny1.mc = rpois(N, theta.post.mc)\n\n# data\ndf = data.frame(y1) # empirical\ndf2 = data.frame(y1.mc) # post predictive\n  \n# make plot\ndf %>%\n  ggplot(aes(x = y1)) +\n  geom_bar(aes(x = y1 + .15, y = (..count..)/sum(..count..),\n               fill = \"empirical\"), alpha = 0.6, width = 0.3) +\n  geom_bar(data = df2, \n                 aes(x = y1.mc -.15, y = (..count..) / sum(..count..),\n                     fill = \"predictive\"), alpha = 0.4, width = 0.3) +\n  labs(x = \"number of children\", \n       y = TeX(\"$p(Y_i = y_i)$\"),\n       fill = \"\") +\n  scale_x_continuous(breaks = c(0:7), labels = c(0:7),\n                     limits = c(-.5,7.5)) +\n  \n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nLet \\(\\mathbf{y}\\) be a vector of length 111. Let \\(t(\\mathbf{y})\\) be the ratio of \\(2\\)s to \\(1\\)s in \\(\\mathbf{y}\\). For our observed data, this test statistic \\(t(\\mathbf{y}_{obs}) = 38 / 19 = 2\\). What is the tail probability \\(p(t(\\tilde{\\mathbf{Y}}) \\geq t(\\mathbf{y}_{obs}))\\) under the posterior predictive distribution?"
  },
  {
    "objectID": "notes/lec04-prediction.html",
    "href": "notes/lec04-prediction.html",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "",
    "text": "Load packages:"
  },
  {
    "objectID": "notes/lec04-prediction.html#prediction-example",
    "href": "notes/lec04-prediction.html#prediction-example",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Prediction example",
    "text": "Prediction example\nGeneral social survey (1998)\nSetup:\n\nSuppose \\(X_i = 1\\) if the ith person is happy. \\(X_i = 0\\) otherwise.\nLet \\(Y = \\sum_{i = 1}^{n} X_i\\), where \\(n\\) is the number of people sampled.\n\\(Y_i | \\theta \\sim \\text{binomial}(\\theta)\\) for some fixed \\(n\\).\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\n\nScenario: We sample \\(n = 10\\) people. \\(y = 6\\) are happy. If we sample another \\(n = 10\\), what is the probability that \\(\\tilde{y}\\) are happy?\nWe fundamentally want the posterior predictive distribution, \\(p(\\tilde{y} | y)\\).\nFollowing the offline notes, and given conditional independence, we want\n\n\n\n\n\n\\[\n\\begin{aligned}\n\\int p(\\tilde{y} | \\theta) p(\\theta | y) d\\theta\n&=\n\\int {n \\choose \\tilde{y}}\n(\\theta)^\\tilde{y} (1-\\theta)^{n-\\tilde{y}}\n\\cdot\n\\frac{1}{\\text{B(y + 1, n - y + 1)}}\\theta^{y}(1-\\theta)^{n-y}\nd\\theta\\\\\n&= {n \\choose \\tilde{y}} \\frac{1}{\\text{B(y + 1, n - y + 1)}} \\int \\theta^{\\tilde{y}+y} \\cdot\n(1-\\theta)^{(n-\\tilde{y}) + (n - y)} d\\theta\\\\\n&= {n \\choose \\tilde{y}}\n\\frac{\\text{B}(\\tilde{y} + y + 1, 2n - y - \\tilde{y} + 1)}{\\text{B(y + 1, n - y + 1)}}\n\\end{aligned}\n\\]\nwhere \\(B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\). We can of course simplify, since this is really a bunch of factorials, but we can also naively use the beta() function in R and push forward.\n\nplotcode\n\n\n\n\n\n\n\n\n\n\ny = 6\nn = 10\n\n# posterior predictive probability of ytilde\nprobYT = function(ytilde) {\n  choose(n, ytilde) * \n    beta(ytilde + y + 1, (2*n) - y - ytilde + 1) / \n    beta(y + 1, n - y + 1)\n}\n\n# construct data frame\ndf = data.frame(ytilde = 0:10) %>%\n  mutate(postPredict = probYT(ytilde))\n\n# plot data frame\ndf %>%\n  ggplot(aes(x = ytilde, y = postPredict)) +\n  geom_bar(stat = 'identity') +\n  labs(x = TeX(\"$\\\\tilde{y}$\"), y = TeX(\"$p(\\\\tilde{y}|y)$\"),\n       title = \"Posterior predictive probability\") +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-motivation",
    "href": "notes/lec04-prediction.html#monte-carlo-motivation",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo motivation",
    "text": "Monte Carlo motivation\nGeneral social survey from the 90s gathered data on the number of children to women of two categories: those with and without a bachelor’s degree.\nSetup:\n\n\\(Y_{i1}\\): number of children of \\(i\\)th woman in group 1 (no bachelor’s)\n\\(Y_{i2}\\): number of children of \\(i\\)th woman in group 2 (bachelor’s)\n\nModel:\n\n\\(Y_{11}, \\ldots, Y_{n_1 1} | \\theta_1 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_1)\\)\n\\(Y_{12} \\ldots, Y_{n_2 2} | \\theta_2 \\overset{\\mathrm{iid}}{\\sim} \\text{Poisson}(\\theta_2)\\)\n\nPrior:\n\n\\(\\theta_1 \\sim \\text{gamma}(2, 1)\\)\n\\(\\theta_2 \\sim \\text{gamma}(2, 1)\\)\n\nData:\n\n\\(n_1 = 111\\), \\(\\bar{y_1} = 1.95\\), \\(\\sum y_{i 1} = 217\\)\n\\(n_2 = 44\\), \\(\\bar{y_1} = 1.5\\), \\(\\sum y_{i 1} = 66\\)\n\nPosterior:\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\nWe already know how to compute\n\nposterior mean: \\(E~\\theta | y = \\alpha / \\beta\\) (shape, rate parameterization)\nposterior density (dgamma)\nposterior quantiles and confidence intervals (qgamma)\n\nWhat about…\n\n\\(p(\\theta \\in \\mathcal{A} | y)\\),\n\\(E~g(\\theta) | y\\),\n\\(Var~g(\\theta) | y\\)?\n\nWhat about posterior distribution of \\(|\\theta_1 - \\theta_2\\), \\(\\theta_1 / \\theta_2\\), \\(\\text{max} \\{\\theta_1, \\theta_2 \\}\\)?"
  },
  {
    "objectID": "notes/lec04-prediction.html#monte-carlo-integration",
    "href": "notes/lec04-prediction.html#monte-carlo-integration",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Monte Carlo integration",
    "text": "Monte Carlo integration\n\napproximates an integral by a stochastic average\nshines when other methods of integration are impossible (e.g. high dimensional integration)\nworks because of law of large numbers: for a random variable \\(X\\), the sample mean \\(\\bar{x}_N\\) converges to the true mean \\(\\mu\\) as the number of samples \\(N\\) tends to infinity.\n\nThe key idea is: we obtain independent samples from the posterior,\n\\[\n\\theta^{(1)}, \\ldots \\theta^{(N)} \\overset{\\mathrm{iid}}{\\sim} p(\\theta |\\vec{y})\n\\]\nthen the empirical distribution of the samples approximates the posterior (approximation improves as \\(N\\) increases).\nRecall\n\\[\nE~g(\\theta)|y = \\int_\\mathcal{\\theta} g(\\theta) f_\\theta(\\theta | y)dx \\approx \\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\n\\]\nwhere \\(f_x(x)\\) is the probability density function for a random variable \\(X\\).\nThe law of large numbers says that if our samples \\(\\theta^{(i)}\\) are independent, \\(\\frac{1}{N} \\sum_{i = 1}^N g(\\theta^{(i)})\\) to \\(E~\\theta|y\\).\n\n\n\n\n\n\nNote\n\n\n\nIntegrals are expectations, and expectations are integrals."
  },
  {
    "objectID": "notes/lec04-prediction.html#examples",
    "href": "notes/lec04-prediction.html#examples",
    "title": "Prediction & Intro to Monte Carlo",
    "section": "Examples",
    "text": "Examples\n\n\\(\\theta_1 | \\vec{y_1} \\sim \\text{gamma}(219, 112)\\)\n\\(\\theta_2 | \\vec{y_2} \\sim \\text{gamma}(68, 45)\\)\n\n\n(1) proof of concept: the mean\n\nset.seed(123)\nN = 5000\nrgamma(N, shape = 219, rate = 112) %>%\n  mean()\n\n[1] 1.95294\n\n\nPretty close to the true mean, 1.9553571.\n\n\n(2) posterior of \\(\\theta_1 - \\theta_2\\)\n\nset.seed(123)\ntheta1 = rgamma(N, shape = 219, rate = 112)\ntheta2 = rgamma(N, shape = 68, rate = 45)\n\ndf = data.frame(diff = theta1 - theta2)\n\ndf %>%\n  ggplot(aes(x = diff)) + \n  geom_density() +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1 - \\\\theta_2$\"),\n       y = TeX(\"$p(\\\\theta_1 - \\\\theta_2 | {y}_1, {y}_2)$\"))\n\n\n\n\n\n\n(3) \\(p(\\theta_1 - \\theta_2> .5)\\)\n\nmean(df$diff > .5)\n\n[1] 0.4106\n\n\n\nExerciseFull solutionQuick Monte Carlo\n\n\n\n\n\n\n\n\nExercise\n\n\n\n\n\\(\\theta \\sim \\text{uniform}(0, 1)\\)\nLet \\(\\gamma = \\log \\theta\\)\nVisualize \\(p(\\gamma)\\) using Monte Carlo simulation, then show using the change of variables formula and plotting the closed form of the density.\n\n\n\n\n\n\n# sample from p(theta)\ntheta = runif(10000)\n\n# define transform function\nf = function(x) {\n  return(exp(x))\n}\n\n# create a df for each plot\ndf = data.frame(gamma = -7:0)\ndf2 = data.frame(gammaSamples = log(theta))\n\n# make plots\ndf %>%\n  ggplot(aes(x = gamma)) +\n  stat_function(fun = f, col = 'red', alpha = 0.5) +\n  geom_histogram(data = df2, aes(x = gammaSamples,\n                                 y = ..density..),\n               fill = 'steelblue', alpha = 0.5)\n\n\n\n\n\n\n\n# Just making the Monte Carlo part of the plot \n# in 3 lines\ntheta = runif(10000)\ngamma = log(theta)\nhist(gamma)"
  },
  {
    "objectID": "notes/lec06-normalModel.html",
    "href": "notes/lec06-normalModel.html",
    "title": "The normal model",
    "section": "",
    "text": "# load packages\nlibrary(tidyverse)\nlibrary(latex2exp)"
  },
  {
    "objectID": "notes/lec06-normalModel.html#background",
    "href": "notes/lec06-normalModel.html#background",
    "title": "The normal model",
    "section": "Background",
    "text": "Background\n\nDefinition and vocabulary\nLet \\(Y\\) be normally distributed with mean \\(\\theta\\) and variance \\(\\sigma^2\\). Mathematically,\n\\[\nY | \\theta, \\sigma^2  \\sim N(\\theta, \\sigma^2).\n\\]\nThe density\n\\[\n\\begin{aligned}\np(y ~|~ \\theta, \\sigma^2 ) &= (2\\pi\\sigma^2)^{-1/2} e^{-\\frac{1}{2\\sigma^2} (y-\\theta)^2},\\\\\ny &\\in \\mathbb{R},\\\\\n\\theta &\\in \\mathbb{R},\\\\\n\\sigma &\\in \\mathbb{R}^+.\n\\end{aligned}\n\\]\n\nlocation, scale\n\n\\(\\theta\\) is called the ‘location’ parameter\n\\(\\sigma\\) is called the ‘scale’ parameter\n\n\n\nprecision\nNotice that every time \\(\\sigma^2\\) appears in the density, it is inverted. For this reason, the inverse variance \\((\\frac{1}{\\sigma^2})\\) has a special name, precision. Intuitively, precision tells us how close \\(y\\) is to the mean \\(\\theta\\). (Large precision = small variance = closer).\n\n\n\nplots of normal densities\n\n\n\n\n\n\nWarning\n\n\n\nIn R, the arguments of pnorm, dnorm, rnorm are the mean and standard deviation (not the variance!)\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\nN = 10000\ny.mc = rnorm(N, mean = 3, sd = 2)\n\ndf = data.frame(y.mc)\n\ndf %>%\n  ggplot(aes(x = y.mc)) +\n  geom_histogram(aes(y = ..density..), alpha = 0.6, fill = 'steelblue') +\n  stat_function(fun = dnorm, args = list(mean = 3, sd = 2), aes(color = \"N(3, 4)\")) +\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), aes(color = \"N(0, 1)\")) +\n  theme_bw() +\n  labs(x = \"y\", y = \"density\", title = \"Normal densities\",\n       color = \"\")"
  },
  {
    "objectID": "notes/lec06-normalModel.html#bayesian-inference",
    "href": "notes/lec06-normalModel.html#bayesian-inference",
    "title": "The normal model",
    "section": "Bayesian inference",
    "text": "Bayesian inference\nIn general, we wish to make inference about \\(\\theta\\) and \\(\\sigma^2\\) after observing some data \\(y_1, \\ldots y_n\\) and thus are interested in the posterior \\(p(\\theta, \\sigma^2 | y_1, \\ldots y_n)\\). This is the standard task we have seen thus far, and requires us to specify a joint prior \\(p(\\theta, \\sigma^2)\\). Below, we will work to find a class of conjugate priors over \\(\\theta\\) and \\(\\sigma^2\\).\nWe can break up the joint posterior into two pieces from the axioms of probability:\n\\[\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\n\\]\nThis suggests that we calculate the joint posterior by:\n\nfirst finding the full conditional of \\(\\theta\\): \\(p(\\theta| \\sigma^2, \\vec{y})\\)\nand then finding the marginal posterior of \\(\\sigma^2\\): \\(p(\\sigma^2 | \\vec{y})\\),\n\nwhere \\(\\vec{y} = \\{y_1, \\ldots y_n\\}\\).\n\nThe full conditional of \\(\\theta\\)\nBy Bayes’ theorem,\n\\[\np(\\theta| \\sigma^2, \\vec{y}) \\propto \\underbrace{p(\\vec{y} |\\theta, \\sigma^2)}_{\\text{likelihood}} \\underbrace{p(\\theta|\\sigma^2)}_{\\text{prior}}.\n\\]\nTo arrive at the full conditional posterior of \\(\\theta\\), we must first specify a prior on \\(\\theta\\).\nConsidering we have a normal likelihood, what is a conjugate class of densities for \\(\\theta\\)?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\\(\\theta | \\sigma^2 \\sim N(\\mu_0, \\tau_0^2)\\) for some \\(\\mu_0 \\in \\mathbb{R}\\) and \\(\\tau_0^2 \\in \\mathbb{R}^+\\) is conjugate.\n\n\n\nWith the conjugate prior, our full conditional posterior \\(\\{ \\theta| \\sigma^2, \\vec{y} \\} \\sim N(\\mu_n, \\tau_n^2)\\) where\n\\[\n\\begin{aligned}\n\\mu_n &=\n\\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2} \\bar{y}}{\n\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n}\n\\\\\n\\\\\n\\tau_n^2 &= \\frac{1}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\end{aligned}\n\\]\n\nLet’s sketch out ‘completing the square’ to derive the parameters offline.\n\n\n\nIntuitive posterior parameters\nIf we consider the posterior precision, \\(\\frac{1}{\\tau_n^2}\\), we can re-arrange the terms above to illuminate how posterior information = prior information + data information;.\n\\[\n\\frac{1}{\\tau_n^2}= \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\\]\nIn words, posterior precision is equivalent to prior precision plus sampling precision. If we name each precision term, \\(\\lambda_0 = \\frac{1}{\\tau_0}\\), \\(\\lambda_n = \\frac{1}{\\tau_n}\\) and \\(\\lambda = \\frac{1}{\\sigma}\\) then\n\\[\n\\mu_n = \\frac{\\lambda_0^2}{\\lambda_0^2 + n\\lambda^2} \\mu_0 +\n\\frac{n\\lambda^2}{\\lambda_0^2 + n\\lambda^2} \\bar{y}\n\\]\ni.e. the posterior mean is the weighted average of prior and sample mean, where the weights are the relative contribution of each precision!\nWe can re-define \\(\\lambda_0^2 = \\kappa_0 \\lambda^2\\) (or equivalently \\(\\tau_0^2 = \\frac{\\sigma^2}{\\kappa_0}\\)) and obtain\n\\[\n\\begin{aligned}\n\\mu_n &= \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y},\\\\\n\\frac{1}{\\tau_n^2} &= \\frac{\\kappa_0 + n}{\\sigma^2}\n\\end{aligned}\n\\]\nwhere we can interpret \\(\\kappa_0\\) as the prior sample size.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that \\(\\tau_n^2\\) is the posterior variance of the full conditional posterior of \\(\\theta\\). This is distinct from \\(\\sigma_n^2\\), defined below.\n\n\n\n\nPrior on \\(\\sigma^2\\)\nRemember, we want \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\). We have the first component of the right hand side, what about the second component?\nNotice that\n\\[\np(\\sigma^2 | \\vec{y}) \\propto p(\\sigma^2)\\int p(\\vec{y} | \\theta, \\sigma^2) p(\\theta|\\sigma^2) d\\theta\n\\]\nBut how do we choose \\(p(\\sigma^2)\\) to be conjugate? We can proceed in multiple ways: one is noting that the integral is really a convolution of normals, (thereby a sum of normals) and is therefore a normal density.\nUpon inspection, we can see a suitable choice is \\(\\frac{1}{\\sigma^2} \\sim \\text{gamma}(a, b)\\).\n\n\nThe inverse-gamma\nA random variable \\(X \\in (0, \\infty)\\) has an inverse-gamma(a,b) distribution if \\(\\frac{1}{X}\\) has a gamma(a,b) distribution.\nIf X has an inverse-gamma distribution, the density of X is\n\\[\np(x | a, b) = \\frac{b^a}{\\Gamma(a)} x^{-a-1}e^{-b/x} \\ \\text{for } \\ x > 0\n\\]\nand\n\\[\n\\begin{aligned}\nEX &= \\frac{b}{(a-1)} \\text{ if } a \\geq 1; \\ \\infty \\text{ if } 0<a<1,\\\\\nVar(X) &= \\frac{b^2}{(a-1)^2(a-2)} \\ \\text{if } a \\geq 2; \\ \\infty \\text{ if } 0 < a < 2,\\\\\nMode(X) &= \\frac{b}{a +1}.\n\\end{aligned}\n\\]\n\n\nThe marginal posterior of \\(\\sigma^2\\)\nTaken all together, if we let our sampling model and prior distributions be such that\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\]\nthen the posterior\n\\[\n\\frac{1}{\\sigma^2} | \\vec{y} \\sim \\text{gamma}(\\frac{\\nu_n}{2}, \\frac{\\nu_n \\sigma^2_n}{2}),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\nu_n &= \\nu_0 + n,\\\\\n\\sigma^2_n &= \\frac{1}{\\nu_n} \\left[\n\\nu_0 \\sigma^2_0 +(n-1)s^2 + \\frac{\\kappa_0 n}{\\kappa_0 + n}(\\bar{y} - \\mu_0)^2\n\\right],\n\\end{aligned}\n\\]\nand \\(s^2\\) is the sample variance, \\(\\frac{1}{n-1} \\sum_i (y_i - \\bar{y})^2\\)."
  },
  {
    "objectID": "notes/lec06-normalModel.html#sampling-from-the-joint-posterior",
    "href": "notes/lec06-normalModel.html#sampling-from-the-joint-posterior",
    "title": "The normal model",
    "section": "Sampling from the joint posterior",
    "text": "Sampling from the joint posterior\nSince \\(p(\\theta, \\sigma^2 | \\vec{y}) = p(\\theta | \\sigma^2, y_1, \\ldots, y_n)p(\\sigma^2|y_1, \\ldots y_n)\\), we can sample from the joint posterior by first sampling from \\(p(\\sigma^2|y_1, \\ldots y_n)\\) and then sampling from \\(p(\\theta | \\sigma^2, y_1, \\ldots, y_n)\\).\n\nExample\nProof of concept\nWe have some data:\n\n# generating 10 samples from the population\nset.seed(123)\ntrue.theta = 4\ntrue.sigma = 1\ny = rnorm(10, true.theta, true.sigma)\n\nybar = mean(y) # sample mean\nn = length(y) # sample size\ns2 = var(y) # sample variance\n\nWe make inference about \\(\\theta\\) and \\(\\sigma^2\\):\n\n# priors\n# theta prior\nmu_0 = 2; k_0 = 1\n# sigma2 prior\nnu_0 = 1; s2_0 = 0.010\n\n# posterior parameters\nkn = k_0 + n\nnun = nu_0 + n\nmun = (k_0 * mu_0 + n * ybar) /kn\ns2n = (nu_0 * s2_0 + (n - 1) * s2 + k_0 * n * (ybar - mu_0)^2 / (kn)) / (nun)\n\ns2.postsample = 1 / rgamma(10000, nun / 2, s2n * nun / 2)\ntheta.postsample = rnorm(10000, mun, sqrt(s2.postsample / kn))\n\ndf = data.frame(theta.postsample, s2.postsample)\n\ndf %>%\n  ggplot(aes(x = theta.postsample, y = s2.postsample)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, \\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()"
  },
  {
    "objectID": "notes/lec07-estimators.html",
    "href": "notes/lec07-estimators.html",
    "title": "Estimators",
    "section": "",
    "text": "Definition\n\n\n\nA point estimator of an unknown parameter \\(\\theta\\) is a function that converts data into a single element of parameter space \\(\\Theta\\).\n\n\nExample: imagine \\(\\theta\\) is the population mean. The following are each point estimators of \\(\\theta\\):\n\n\\(\\bar{y}\\)\n\\(y_1\\)\n\\(\\frac{y_1 + y_2}{2}\\)\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is convention to write the population parameter as a Greek character and the estimator as the same Greek character, but with a “hat”. For example, \\(\\theta\\) is the parameter and \\(\\hat{\\theta}\\) is the estimator.\n\n\nSampling properties of a point estimator refer to the estimator’s behavior under hypothetical repeatable surveys or experiments.\nThree common sampling properties of estimators we will see again and again are:\n\nbias\nvariance\nmean squared error (MSE)\n\n\n\nBefore we discuss bias, variance and mean squared error of an estimator, it’s important to understand that an estimator is a statistic (function of the data) and therefore a random variable. Because of this, estimator’s have a sampling distribution.\nExercise: What does the example below show? What is x?\n\nset.seed(360)\n\nx = vector()\nfor (i in 1:100) {\n  y = rnorm(10)\n  x = append(min(y), x)\n}\nhist(x, freq = FALSE)\nabline(v = mean(x), col= \"steelblue\", lwd = 4)\n\n\n\ncat(\"The variance of x is \", round(var(x), 3))\n\nThe variance of x is  0.291\n\n\n\n\n\nIn the rest of these notes, let \\(\\theta_0\\) be the true value of the population parameter \\(\\theta\\).\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\nExercise: Imagine \\(\\hat{\\theta}_a\\) and \\(\\hat{\\theta}_b\\) are two different estimators of \\(\\theta\\). The true value of \\(\\theta\\) is \\(\\theta_0 = 0\\). The sampling distributions of the two estimators are given below. Which estimator do you prefer?\n\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\]\nwhere \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\nWhile it may seem desirable to have an estimator with zero bias, the estimator may still be far away from the true parameter value if the variance is too large. The mean squared error quantifies how close an estimator is to the true parameter value.\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]\n\n\n\nLet’s show this offline."
  },
  {
    "objectID": "notes/lec07-estimators.html#practice",
    "href": "notes/lec07-estimators.html#practice",
    "title": "Estimators",
    "section": "Practice",
    "text": "Practice\nSuppose you wish to make inference about the average bill length of Chinstrap penguins.\nYou make the modeling assumption that \\(Y\\), the bill length of a penguin is normally distributed, i.e. \\(Y \\sim N(\\theta, \\sigma^2)\\) and you set up a conjugate prior as we’ve done before.\nOne can then show that the posterior mean estimator of \\(\\theta\\) is\n\\[\n\\hat{\\theta}_b = E[\\theta | y_1,\\ldots y_n] = \\frac{n}{\\kappa_0 + n} \\bar{y} + \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 = w\\bar{y} + (1-w) \\mu_0\n\\]\nExercise: compare \\(\\hat{\\theta}_b\\) to the estimator \\(\\hat{\\theta}_e = \\bar{y}\\). Compute the expected value of each estimator, which one is biased? Compute the variance of each estimator. Which has lower variance?\n\nLet’s compute the MSE and discuss when the Bayesian estimator \\(\\hat{\\theta}_b\\) has lower MSE than the sample mean offline."
  },
  {
    "objectID": "notes/lec07-estimators.html#extra-practice",
    "href": "notes/lec07-estimators.html#extra-practice",
    "title": "Estimators",
    "section": "Extra practice",
    "text": "Extra practice\n\n\n\n\n\nSuppose you know that you know Gentoo penguins are closely related to Chinstrap penguins. Previously, you’ve measured the bill length of three Gentoo penguins and found their mean bill length to be 46.2. Accordingly, you set \\(\\mu_0 = 46.2\\).\n\n\n\n\n\n\n\n\nSuppose (for illustrative purposes) that you know the true population mean and variance for Chinstrap penguin bill length,\n\\[\n\\begin{aligned}\n\\theta_0 &= 48.8\\\\\n\\sigma^2 &= 3.3.\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nCompute \\(MSE[\\hat{\\theta}_e|\\theta_0]\\) and \\(MSE[\\hat{\\theta_b}|\\theta_0]\\) and plot the ratio \\(MSE[\\hat{\\theta}_b]/MSE[\\hat{\\theta}_e|\\theta_0]\\) as a function of \\(n\\) for \\(\\kappa_0 = 0, 1, 2, 3\\)."
  },
  {
    "objectID": "quizzes/quiz04.html",
    "href": "quizzes/quiz04.html",
    "title": "Quiz 4",
    "section": "",
    "text": "Exercise 1\n\\[\nY | \\theta, \\sigma^2 \\sim N(\\theta, \\sigma^2)\n\\]\nWhat is a conjugate class of priors for \\(\\theta | \\sigma^2\\)?\n\n\nExercise 2\nTRUE or FALSE\nAn estimator is a random variable.\n\n\nExercise 3\nLet \\(\\theta_0\\) be the true value of \\(\\theta\\).\nIf \\(E[\\hat{\\theta}| \\theta = \\theta_0] = \\theta_0\\), we say \\(\\hat{\\theta}\\) is a ____ estimator of \\(\\theta\\).\n\n\n\n03:00"
  },
  {
    "objectID": "slides/lab4.html#exercise",
    "href": "slides/lab4.html#exercise",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nA data scientist at a small subscriber-based tech company models the number of new subscribers in a day as \\(Y|\\theta \\sim \\text{Poisson}(\\theta)\\) with prior \\(\\theta \\sim \\text{gamma}(a,b)\\). A priori, the data scientist believes that there are on average 20 signups per day and 90% of the time there are between approximately 3 and 50 signups on a given day.\na\nFind suitable \\(a\\) and \\(b\\) that satisfy the data scientist’s prior beliefs.\nVerify how well your prior aligns with this belief using Monte Carlo sampling to generate the prior predictive distribution, \\(p(\\tilde{y}) = \\int p(\\tilde{y}, \\theta)d\\theta\\).\n\n\n\nb\nAfter one month the data scientist observes the following daily subscriber counts:\n\ny = c(10, 21, 19, 16, 20, 18, 35, 16, 23, 26, 20, 21, 23, 19, 18, 20, 23, 18, 21, 16, 15, 15, 20, 22, 19, 25)\n\nThe data scientist is fundamentally interested in the variance of subscriber counts per day. Is the Poisson model appropriate for this data?\nReport \\(p(\\tilde{S}^2 > s^2_{obs} | y_1,\\ldots y_n)\\) where \\(\\tilde{S}^2\\) is the posterior predictive sample variance and \\(s^2_{obs}\\) is the observed sample variance (\\(s^2_{obs} = 21.3\\)). To generate samples under the posterior predictive distribution, use the prior from part (a)."
  },
  {
    "objectID": "slides/lab4.html#bias",
    "href": "slides/lab4.html#bias",
    "title": "Extra practice",
    "section": "Bias",
    "text": "Bias\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab4.html#exercise-1",
    "href": "slides/lab4.html#exercise-1",
    "title": "Extra practice",
    "section": "Exercise",
    "text": "Exercise\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/lec08-gibbs.html",
    "href": "notes/lec08-gibbs.html",
    "title": "Gibbs sampling",
    "section": "",
    "text": "Definition\n\n\n\nA semiconjugate or conditionally conjugate prior is a prior that is conjugate to the full conditional posterior.\n\n\nNote: the idea of a semiconjugate prior only makes sense when making inferences about two or more parameters.\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta & \\sim N(\\mu_0, \\tau_0^2)\\\\\n\\frac{1}{\\sigma^2} &\\sim gamma(\\nu_0/2, \\nu_0\\sigma_0^2/2)\n\\end{aligned}\n\\]\nIn this case, \\(\\tau_0^2\\) is not a function of \\(\\sigma^2\\) and thus \\(p(\\theta, \\sigma^2) = p(\\theta) p(\\sigma^2)\\).\nEach prior is “semiconjugate” since \\(p(\\theta| \\sigma^2, y_1,\\ldots y_n)\\) is normal and \\(p(\\frac{1}{\\sigma^2} | \\theta, y_1,\\ldots y_n)\\) is gamma but \\(p(\\theta, \\sigma^2)\\) is not conjugate to \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA proper prior is a density function that does not depend on data and integrates to 1. If a prior integrates to a positive finite value, it is an unnormalized density that can be renormalized by being multiplied by a constant to integrate to 1. If a prior is not proper, we call the prior improper.\n\n\nExample:\n\\[\n\\begin{aligned}\nY | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\np(\\theta, \\sigma^2) &= \\frac{1}{\\sigma^2}\n\\end{aligned}\n\\]\n\\(p(\\theta, \\sigma^2)\\) is an improper prior. \\(p(\\theta, \\sigma^2)\\) does not integrate to a finite value and thus cannot be renormalized. It is not a probability density. However, it yields a tractable posterior for \\(\\theta\\) and \\(\\sigma^2\\) (see p 79 of Hoff).\n\n\n\nPriors are meant to describe our state of knowledge before examining data. In some cases we may wish to describe our ignorance a priori using a vague prior that plays a minimal role in the posterior distribution.\nA common trap is to imagine that a flat, or uniform prior is uninformative. Previously, on homework 3 you showed a uniform prior on binary probability of success \\(\\theta\\) is informative on the log-odds. Additionally, an improper flat prior may carry a lot of information, since most of the mass is infinitely far away.\n\n\n\n\n\n\nDefinition\n\n\n\nThe Jeffreys prior\n\\[\nJ(\\theta) \\propto \\sqrt{I(\\theta)}\n\\]\nwhere \\(I(\\theta) = -E[\\frac{\\partial}{\\partial\\theta^2} \\log p(Y|\\theta) | \\theta]\\).\n\n\nThe defining feature of Jeffreys prior is that it will yield an equivalent result if applied to a transformed parameter. This principle of invariance is one approach to non-informative priors that works well for single parameter priors. Multiparameter extensions are often less useful."
  },
  {
    "objectID": "notes/lec08-gibbs.html#inference-under-non-conjugate-priors",
    "href": "notes/lec08-gibbs.html#inference-under-non-conjugate-priors",
    "title": "Gibbs sampling",
    "section": "Inference under non-conjugate priors",
    "text": "Inference under non-conjugate priors\nSuppose we don’t know\n\\[\np(\\theta, \\sigma^2 | y_1,\\ldots y_n)\n\\]\nbut we do know the full conditional posteriors\n\\[\n\\begin{aligned}\np(\\theta | \\sigma^2, y_1, \\ldots y_n)\\\\\np(\\sigma^2 | \\theta, y_1,\\ldots y_n)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/lec08-gibbs.html#gibbs-sampler",
    "href": "notes/lec08-gibbs.html#gibbs-sampler",
    "title": "Gibbs sampling",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\nWhat if we have a non-conjugate prior? How can we can we look at \\(p(\\theta, \\sigma^2 | y_1,\\ldots y_n)\\)?\nIn general, suppose we don’t know\n\\[\np(\\theta, \\sigma^2 | y_1,\\ldots y_n)\n\\]\nbut we do know the full conditional posteriors\n\\[\n\\begin{aligned}\np(\\theta | \\sigma^2, y_1, \\ldots y_n)\\\\\np(\\sigma^2 | \\theta, y_1,\\ldots y_n)\n\\end{aligned}\n\\]\nwe can generate sample \\(\\theta^{(s)}, \\sigma^{2(s)}\\) from the joint posterior by the following algorithm:\n\nsample \\(\\theta^{(s+1)}\\) from \\(p(\\theta | \\sigma^{2(s)}, y_1,\\ldots y_n)\\)\nsample \\(\\sigma^{2(s+1)}\\) from \\(p(\\sigma^2|\\theta^{(s+1)}, y_1,\\ldots, y_n)\\)\nlet \\(\\phi^{(s+1)} = \\{ \\theta^{(s+1)}, \\sigma^{2(s+1)} \\}\\)\n\niterate steps 1-3 \\(S\\) times.\nThis algorithm is called the Gibbs sampler,\n\nit creates a dependent set of values \\(\\phi^{(1)} \\ldots \\phi^{(S)}\\),\nthe sequence is called a Markov chain,\nthe samples let us approximate the posterior i.e. the histogram of \\((\\phi^{(1)},\\ldots \\phi^{(S)})\\) is a Markov chain Monte Carlo approximation to \\(p(\\phi | y_1,\\ldots y_n)\\).\n\nExample: in the semiconjugate normal model described above, the resulting posteriors are:\n\\[\n\\theta | \\sigma^2, y_1,\\ldots y_n \\sim N(\\mu_n, \\tau_n^2),\n\\]\nwhere \\(\\mu_n = \\frac{\\mu_0/\\tau_0^2 + n\\bar{y} /\\sigma^2}{1/{\\tau_0^2} + n/\\sigma^2}\\) and \\(\\tau_n^2 = \\left( \\frac{1}{\\tau_0^2 }+ \\frac{n}{\\sigma^2} \\right)^{-1}\\) and\n\\[\n\\sigma^2 | \\theta, y_1, \\ldots y_n \\sim invgamma(\\nu_n/2, \\nu_n \\sigma^2_n / 2)\n\\]\nwhere \\(\\nu_n = \\nu_0 + n\\), \\(\\sigma_n^2 = \\frac{1}{\\nu_n} [\\nu_0 \\sigma_0^2 + n s^2_n(\\theta)]\\) and \\(s^2_n(\\theta) = \\frac{1}{n}\\sum (y_i - \\theta)^2\\).\n\n##########################\n# example from Hoff ch6 #\n##########################\n\n# data\ny = c(1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08)\nmean.y = mean(y) ; var.y = var(y) ; n = length(y)\n\n# priors\nmu0 = 0\nt20 = 100\nnu0 = 1\ns20 = 2\n\n# starting point\nS = 1000\nPHI = matrix(nrow = S, ncol = 2)\nphi = c(mean.y, var(y))\nPHI[1, ] = phi\n\n# Gibbs sampling\nset.seed(360)\nfor(s in 2:S) { \n\n## generate theta from sigma2\nmun = (mu0 / t20 + n * mean.y * phi[2]) / (1 / t20 + n * phi[2])\nt2n = 1 / (1 / t20 + n * phi[2])\nphi[1] = rnorm(1, mun, sqrt(t2n))\n\n## generate 1/sigma2 from theta\nnun = nu0 + n\ns2n = (nu0 * s20 + (n - 1) * var.y + n * (mean.y - phi[1])^2 ) / nun\nphi[2] = rgamma(1, nun/2, nun * s2n / 2)\n\n## update chain\nPHI[s,] = phi\n}\n\nNote: in this code we use the identity \\(n s_n^2(\\theta) = (n-1)s^2 + n (\\bar{y} - \\theta)^2\\).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\n# plotting the joint posterior\ndf = as.data.frame(PHI)\nnames(df) = c(\"theta\", \"prec\")\ndf %>%\n  ggplot(aes(x = theta, y = prec)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  labs(x = TeX(\"$\\\\theta$\"),\n       y = TeX(\"$1/\\\\sigma^2$\"),\n       fill = TeX(\"$p(\\\\theta, 1/\\\\sigma^2 | y_1, \\\\ldots y_n)$\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nSince the sequence \\(\\{\\phi^{(s)} \\}\\) depends on \\(\\phi^{(0)}, \\ldots \\phi^{(s-1)}\\) only through \\(\\phi^{(s-1)}\\) we say the sequence is memoryless. This is called the Markov property, and so the sequence is a Markov chain.\n“What happens next depends only on the state of affairs now”\n\n\nUnder some conditions,\n\\[\np(\\phi^{(s)} \\in A) \\rightarrow \\int_A p(\\phi) d\\phi \\ \\ \\text{ as } s \\rightarrow \\infty\n\\]\ni.e. the sampling distribution of \\(\\phi^{(s)}\\) approaches the target distribution as \\(s \\rightarrow \\infty\\) regardless of \\(\\phi^{(0)}\\).\nFurthermore,\n\\[\n\\frac{1}{S} \\sum_{s=1}^S g(\\phi^{(s)})  \\rightarrow E[g(\\phi)]\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nBig take-away: if we can sample from the full conditional posteriors, we can construct a Markov chain with samples from the joint posterior! We can then use Monte Carlo approximation to use the samples to summarize aspects of the posterior."
  },
  {
    "objectID": "hw/extra-credit.html",
    "href": "hw/extra-credit.html",
    "title": "Extra credit",
    "section": "",
    "text": "Because this is extra credit, the teaching team will not assist solving this problem during office hours. Additionally, extra credit may not be turned in late."
  },
  {
    "objectID": "hw/extra-credit.html#exercise",
    "href": "hw/extra-credit.html#exercise",
    "title": "Extra credit",
    "section": "Exercise",
    "text": "Exercise\n3.14 from Hoff.\nAdditionally, complete part (e): discuss the resulting posterior based on your findings from parts (a) through (d) in a couple of sentences."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html",
    "href": "notes/lec09-mcmc-diagnostics.html",
    "title": "MCMC diagnostics",
    "section": "",
    "text": "We setup a data generative model, \\(p(y | \\boldsymbol{\\theta})\\) and a prior on the model parameters \\(p(\\boldsymbol{\\theta})\\) where \\(\\boldsymbol{\\theta} = \\{ \\theta_1, \\theta_2, \\ldots \\theta_n\\}\\).\nNext, we wish to make inferences using the data we collect \\(\\boldsymbol{y} = \\{y_1,\\ldots y_n\\}\\). All inferences we make require the posterior \\(p(\\boldsymbol{\\theta}| \\boldsymbol{y})\\), which we obtain via Bayes’ rule.\nIn general, the inferences we wish to make, e.g. \\(p(g(\\boldsymbol{\\theta}) \\in A)\\), are complicated or impossible to compute analytically. Here, Monte Carlo approximation helps. The key idea is that we use independent samples from the posterior as an empirical approximation to make inference.\nFor non-conjugate models, obtaining samples from the posterior can be hard. We saw last time that Gibbs sampling lets us generate a series of dependent samples from the posterior as an empirical approximation to make inference. The key idea is that if we sample a large number of samples \\(S\\), we should have some number \\(S_{eff}<S\\) effectively independent samples.\n\n\nGibbs sampling is one of many methods (but not the only method) to construct a Markov chain comprised of dependent samples from the target distribution.\nConstructing a Markov chain of dependent samples and using these samples to approximate the target distribution is called Markov chain Monte Carlo (MCMC).\n\nImportantly, MCMC sampling algorithms are not models. They do not generate more information than is in \\(\\boldsymbol{y}\\) and \\(p(\\boldsymbol{\\theta})\\). They are simply ways of “looking at” \\(p(\\boldsymbol{\\theta}|\\boldsymbol{y})\\).\n\n\n\n\n\n\nDefinition\n\n\n\nA target distribution is a distribution we are interested in sampling. In Bayesian statistics, this is typically the posterior distribution."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#definitions",
    "href": "notes/lec09-mcmc-diagnostics.html#definitions",
    "title": "MCMC diagnostics",
    "section": "Definitions",
    "text": "Definitions\n\n\n\n\n\n\nDefinition\n\n\n\nTypical set\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nStationarity\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nEffective sample size\n\n\n\n\n\n\n\n\nDefinition"
  },
  {
    "objectID": "notes/lec00-hmc.html",
    "href": "notes/lec00-hmc.html",
    "title": "Hamiltonian Monte Carlo",
    "section": "",
    "text": "Often we are interested in some summary (usually an integral) of the target distribution. To evaluate the quantity of interest, we need samples from the typical set."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#properties-of-mcmc",
    "title": "MCMC diagnostics",
    "section": "Properties of MCMC",
    "text": "Properties of MCMC\n\ntoy example\nImagine the following target distribution (the joint probability distribution of two variables, \\(\\theta\\) and \\(\\delta\\)).\n\nplotcode\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(latex2exp)\nset.seed(360)\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\nsd = rep(sqrt(1 / 3), 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # number of samples\n\ndelta = sample(d, size = N, prob = c(.45, .1, .4), replace = TRUE)\ntheta = rnorm(N, mean = mu[delta], sd = sd[delta])\n\ndf = data.frame(delta, theta)\ndf %>%\n  ggplot(aes(x = theta, y = delta)) + \n  geom_bin2d(bins = 25) +\n  theme_bw() + \n  labs(y = TeX(\"\\\\delta\"), \n       x = TeX(\"\\\\theta\"))\n\n\n\n\nIn this example,\n\\[\n\\begin{aligned}\np(\\delta = d) = \\begin{cases}\n&.45 &\\text{ if } d = 1\\\\\n&.10 &\\text{ if } d = 2\\\\\n&.45 &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\{\\theta | \\delta = d\\} \\sim\n\\begin{cases}\n&N(-3, 1/3) &\\text{ if } d = 1\\\\\n&N(0, 1/3) &\\text{ if } d = 2\\\\\n&N(3, 1/3) &\\text{ if } d = 3\n\\end{cases}\n\\end{aligned}\n\\]\nExercise: Construct a Gibbs sampler of the joint density.\nNote: this is a toy example. We can sample from the target distribution directly as seen above. However, we will construct a Gibbs sampler for pedagogical purposes that will become apparent momentarily.\n\n\n\n\n\n\nsolution\n\n\n\n\n\nTo construct a Gibbs sampler, we need the full conditional distributions.\n\n\\(p(\\theta | \\delta)\\) is given.\n\\(p(\\delta| \\theta) = \\frac{p(\\theta | \\delta = d) p(\\delta = d)}{ \\sum_{d=1}^3p(\\theta | \\delta = d)p(\\delta = d)}\\), for \\(d \\in \\{1, 2, 3\\}\\).\n\n\n\n\n\nplotcode\n\n\n\n\n\n\n\n\n\n\n## fixed values ## \nmu = c(-3, 0, 3) # conditional means\ns2 = rep(1 / 3, 3) # conditional sds\nd = c(1, 2, 3) # sample space of delta\nN = 1000 # chain length\nw = c(.45, .1, .4) # delta probabilities\n\n## Gibbs sampler ##\nset.seed(360)\nN = 1000 # number of Gibbs samples\n\ntheta = 0 # initial theta value\nthd.mcmc = NULL\nfor(i in 1:N) {\nd = sample(1:3 , 1, prob = w * dnorm(theta, mu, sqrt(s2))) \ntheta = rnorm(1, mu[d], sqrt(s2[d]))\nthd.mcmc = rbind(thd.mcmc, c(theta,d))\n}\n# note we take advantage that sample() in R does not require the probability\n# to add up to 1\n\ndf = data.frame(theta = thd.mcmc[,1],\n                delta = thd.mcmc[,2])\n\ndf %>%\n  ggplot(aes(x = seq(1, nrow(df)), y = theta)) +\n  geom_line() +\n  theme_bw() +\n  labs(y = TeX(\"\\\\theta\"),\n       x = \"iteration\",\n       title = \"Traceplot of 1000 Gibbs samples\")\n\n\n\n\nExercise:\n\ndescribe how we implement the conditional update for delta in the code above\nwhat do you notice from the traceplot above? Hint: you can imagine hopping from delta islands in the first figure of the joint target over parameter space.\n\n\n\n\n\n\n\nImportant\n\n\n\nThe picture to visualize is that of a particle moving through parameter space.\n\n\n\n\n\nLet’s see how well our samples of \\(\\theta\\) approximate the true marginal \\(p(\\theta)\\)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-what-we-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-what-we-mcmc",
    "title": "MCMC diagnostics",
    "section": "Terms to describe what we MCMC",
    "text": "Terms to describe what we MCMC\n\nautocorrelation: how correlated consecutive values in the chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\]\nwhere \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. In practice we use acf function in R. Example:\n\nacf(thd.mcmc[,1])\n\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nTypical set\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nStationarity\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nEffective sample size\n\n\n\n\n\n\n\n\nDefinition"
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "href": "notes/lec09-mcmc-diagnostics.html#terms-to-describe-mcmc",
    "title": "MCMC diagnostics",
    "section": "Terms to describe MCMC",
    "text": "Terms to describe MCMC\n\nautocorrelation: how correlated consecutive values in the chain are. Mathematically, we compute the sample autocorrelation between elements in the sequence that are \\(t\\) steps apart using\n\n\\[\n\\text{acf}_t(\\boldsymbol{\\phi}) =\n\\frac{\\frac{1}{S - t} \\sum_{s = 1}^{S-t} (\\phi_s - \\bar{\\phi})(\\phi_{s+t} - \\bar{\\phi})}\n{\\frac{1}{S-1} \\sum_{s = 1}^S (\\phi_s - \\bar{\\phi})^2}\n\\]\nwhere \\(\\boldsymbol{\\phi}\\) is a sequence of length \\(S\\) and \\(\\bar{\\phi}\\) is the mean of the sequence. In practice we use acf function in R. Example:\n\nacf(thd.mcmc[,1], plot = FALSE)\n\n\nAutocorrelations of series 'thd.mcmc[, 1]', by lag\n\n    0     1     2     3     4     5     6     7     8     9    10    11    12 \n1.000 0.962 0.959 0.954 0.951 0.948 0.948 0.943 0.941 0.936 0.933 0.931 0.928 \n   13    14    15    16    17    18    19    20    21    22    23    24    25 \n0.927 0.923 0.920 0.915 0.911 0.907 0.906 0.908 0.905 0.902 0.899 0.898 0.897 \n   26    27    28    29    30 \n0.895 0.891 0.891 0.887 0.887 \n\n\nThe higher the autocorrelation, the more samples we need to obtain a given level of precision for our approximation. One way to state how precise our approximation is, is with effective sample size.\n\neffective sample size (ESS): intuitively this is the effective number of exact samples “contained” in the Markov chain (see Betancourt 2018). For further reading on ESS, see the stan manual. In practice we use coda::effectiveSize() function to compute. Example:\n\n\nlibrary(coda)\neffectiveSize(thd.mcmc[,1])[[1]]\n\n[1] 2.065509\n\n\nMore precisely, the effective sample size (ESS) is the value \\(S_{eff}\\) such that\n\\[\nVar_{MCMC}[\\bar{\\phi}] = \\frac{Var[\\phi]}{S_{eff}}.\n\\]\nIn words, it’s the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. For comparison, recall \\(Var_{MC}[\\bar{\\phi}] = Var[\\phi]/S\\)\n\nStationarity is when samples taken in one part of the chain have a similar distribution to samples taken from other parts of the chain. Intuitively, we want the particle to move from our arbitrary starting point to regions of higher probability\\(^*\\), then we will say it has achieved stationarity.\n\nTraceplots are a great way to visually inspect whether a chain has converged, or achieved stationarity. In the traceplot above we can see that samples from the beginning of the chain look very different than samples at the end.\n\\(^*\\) recall that probability is really a volume in high dimensions of parameter space, and so it is not enough for a pdf to evaluate to a high value, there must also be sufficient volume.\n\nMixing: how well the particle moves between sets of high probability. Some might refer to this as how well the particle sojourns across the “typical set” (regions of high probability)."
  },
  {
    "objectID": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "href": "notes/lec09-mcmc-diagnostics.html#extra-practice",
    "title": "MCMC diagnostics",
    "section": "Extra practice",
    "text": "Extra practice\nGibbs sample the target above 10 thousand times. Report and discuss both the autocorrelation and ESS."
  },
  {
    "objectID": "hw/hw05.html",
    "href": "hw/hw05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Risk calculation: Let \\(Y_1, \\ldots, Y_n | \\theta \\sim \\text{ i.i.d. Poission}(\\theta)\\).\n\nFor the case that \\(\\theta \\sim \\text{gamma}(a, b)\\), show that the posterior mean of \\(\\theta\\) given \\(Y_1, \\ldots, Y_n\\) can be written as \\(\\hat{\\theta}_w = w \\bar{y} + (1-w)\\mu\\) for values \\(w\\) and \\(\\mu\\) that depend on \\(n\\), \\(a\\) and \\(b\\).\nNow consider how good this estimator is for a specific value of \\(\\theta\\). Compute \\(E[\\hat{\\theta}_w|\\theta]\\), \\(V[\\hat{\\theta}_w|\\theta]\\), and \\(E[\\bar{y}|\\theta]\\) and \\(V[\\bar{y}|\\theta]\\).\nFind some nice conditions on \\(w\\) and \\(\\mu\\) so that \\(MSE[\\hat{\\theta}_w] < MSE[\\bar{y}]\\)\n[Optional] Now suppose \\(n = 10\\) and \\(\\theta = 5\\). Pick a value of \\(w\\) and \\(\\mu\\) so that your condition in c. is met. Now verify the condition numerically with a Monte Carlo simulation, by simulating 1000 samples of size \\(n=10\\) from the Poisson(5) distribution, computing \\(\\bar{y}\\) and \\(\\hat{\\theta}_w\\) for each simulated sample, and then approximating the MSE of each estimator using the 1000 simulated values of each. Also make histograms or density plots of the simulated estimators, to confirm that one has low(er) variance but positive bias, and the other has zero bias but high(er) variance."
  },
  {
    "objectID": "hw/hw05.html#exercise-2",
    "href": "hw/hw05.html#exercise-2",
    "title": "Homework 5",
    "section": "Exercise 2",
    "text": "Exercise 2\n6.1 from Hoff. Let \\(\\theta\\) and \\(\\gamma\\) be independent. Use the code below to load the data.\n\nbach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/bach30.csv\")\n\nnobach30 = readr::read_csv(\"https://sta360-fa23.github.io/data/nobach30.csv\")"
  },
  {
    "objectID": "hw/hw05.html#exercise-3",
    "href": "hw/hw05.html#exercise-3",
    "title": "Homework 5",
    "section": "Exercise 3",
    "text": "Exercise 3\n6.2 from Hoff. Note the typo: \\(1/\\sigma_j^2\\) is gamma, not \\(1/\\sigma_j\\). Use the code below to load the data.\n\nglucose = readr::read_csv(\"https://sta360-fa23.github.io/data/glucose.csv\")"
  },
  {
    "objectID": "hw/hw06.html",
    "href": "hw/hw06.html",
    "title": "Homework 6",
    "section": "",
    "text": "6.3 from Hoff. You can simulate from a constrained normal distribution with mean mean and standard deviation sd, constrained to lie in the interval \\((a,b)\\) using the following function:\n\nrcnorm<-function(n, mean=0, sd=1, a=-Inf, b=Inf){\n  u = runif(n, pnorm((a - mean) / sd), pnorm((b - mean) / sd))\n  mean + (sd * qnorm(u))\n}\n\nNote that you can use this function to simulate a vector of constrained normal random variables, each with a potentially different mean, standard deviation, and constraints.\nTo load the data for this exercise, run the code below\n\ndivorce = readr::read_csv(\"https://sta360-fa23.github.io/data/divorce.csv\")"
  },
  {
    "objectID": "hw/hw06.html#exercise-2",
    "href": "hw/hw06.html#exercise-2",
    "title": "Homework 6",
    "section": "Exercise 2",
    "text": "Exercise 2\nShow that if \\(W \\sim \\text{Wishart}(m, S)\\) then \\(E[W] = mS\\)."
  },
  {
    "objectID": "hw/hw06.html#exercise-3",
    "href": "hw/hw06.html#exercise-3",
    "title": "Homework 6",
    "section": "Exercise 3",
    "text": "Exercise 3\nSuppose \\(Y\\) is a random normal vector \\(Y \\sim N_p(\\theta, \\Sigma)\\). Let \\(Y_A\\) be the first \\(p_1\\) elements of \\(Y\\) and \\(Y_B\\) be the last \\(p_2 = p - p_1\\) elements, so that \\(Y = (Y_A, Y_B)\\). Similarly, write \\(\\theta = (\\theta_A, \\theta_B)\\). Finally, let\n\\[\n\\Sigma^{-} \\equiv \\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand note that \\(\\Psi_{AB} = \\Psi_{BA}^T\\). Find the conditional distribution of \\(Y_B\\) given \\(Y_A\\) in terms of \\(\\theta_A\\), \\(\\theta_B\\) and components of \\(\\Psi\\). Try to interpret how \\(E[Y_B|Y_A]\\) differs from \\(E[Y_B]\\) and how \\(V[Y_B|Y_A]\\) differs from \\(V[Y_B]\\).\n\nIdentities for exercise 3\nSome of the following identities will be helpful for interpretation.\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "hw/hw06.html#useful-identities-for-exercise-3",
    "href": "hw/hw06.html#useful-identities-for-exercise-3",
    "title": "Homework 6",
    "section": "Useful identities for exercise 3",
    "text": "Useful identities for exercise 3\nLet\n\\[\n\\Sigma = \\left[ {\\begin{array}{cc}\n   \\Sigma_{AA} & \\Sigma_{AB} \\\\\n   \\Sigma_{BA} & \\Sigma_{BB} \\\\\n  \\end{array} } \\right]\n\\]\nand\n\\[\n\\Psi = \\left[ {\\begin{array}{cc}\n   \\Psi_{AA} & \\Psi_{AB} \\\\\n   \\Psi_{BA} & \\Psi_{BB} \\\\\n  \\end{array} } \\right].\n\\]\nThen\n\\[\n\\begin{aligned}\n\\Psi_{AA}^- &= \\Sigma_{AA} - \\Sigma_{AB} \\Sigma_{BB}^- \\Sigma_{BA}\\\\\n\\Psi_{BB}^- &= \\Sigma_{BB} - \\Sigma_{BA} \\Sigma_{AA}^- \\Sigma_{AB}\\\\\n\\Psi_{AB} &= -\\Psi_{AA} \\Sigma_{AB} \\Sigma_{BB}^-\\\\\n\\Psi_{BA} &= -\\Psi_{BB} \\Sigma_{BA} \\Sigma_{AA}^-,\n\\end{aligned}\n\\]\nand note that \\(\\Sigma_{AB} = \\Sigma_{BA}^T\\) and \\(\\Psi_{AB} = \\Psi_{BA}^T\\)."
  },
  {
    "objectID": "notes/lec10-mvn.html",
    "href": "notes/lec10-mvn.html",
    "title": "Multivariate normal",
    "section": "",
    "text": "Example 1: Twenty two students take a reading comprehension test before and after receiving an instructional method. The result for each student is a bivariate vector \\(Y_i\\) that includes a pre- and post- instructional score.\n\n\n\n\n\nExample 2: We measure three features of Gentoo penguins: bill length, bill depth and body mass. For each penguin we record \\(Y_i\\), a three-dimensional vector of trait measurements.\n\n\n\n\n\n\n\n\n\nWe say a \\(p\\) dimensional vector \\(\\boldsymbol{Y}\\) has a multivariate normal distribution if its sampling density is given by\n\\[\np(\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{\n-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}- \\boldsymbol{\\theta})\n\\}\n\\]\nwhere\n\\[\n\\boldsymbol{y}=  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\\\\\n   \\vdots\\\\\n   y_p\n  \\end{array} } \\right]\n  ~~~\n   \\boldsymbol{\\theta}= \\left[ {\\begin{array}{cc}\n   \\theta_1 \\\\\n   \\theta_2\\\\\n   \\vdots\\\\\n   \\theta_p\n  \\end{array} } \\right]\n  ~~~\n  \\Sigma =\n  \\left[ {\\begin{array}{cc}\n   \\sigma_1^2 & \\sigma_{12}& \\ldots & \\sigma_{1p}\\\\\n   \\sigma_{12} & \\sigma_2^2 &\\ldots & \\sigma_{2p}\\\\\n   \\vdots & \\vdots & & \\vdots\\\\\n   \\sigma_{1p} & \\ldots & \\ldots & \\sigma_p^2\n  \\end{array} } \\right].\n\\]\n\n\n\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma > 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] = \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\n\nlibrary(mvtnorm) contains functions we need.\n\nrmvnorm() to sample from a multivariate normal\ndmvnorm() to compute the density\npmvnorm() to compute the distribution function\nqmvnorm() to compute quantiles of the multivariate normal"
  },
  {
    "objectID": "notes/lec10-mvn.html#matrix-algebra-fundamentals",
    "href": "notes/lec10-mvn.html#matrix-algebra-fundamentals",
    "title": "Multivariate normal",
    "section": "Matrix algebra fundamentals",
    "text": "Matrix algebra fundamentals\n\nmatrix facts\n\nmatrix multiplication proceeds row \\(\\times\\) column, so if we have the product \\(AB\\), \\(A\\) must have the same number of ___ as B has ___.\nthe determinant of a matrix, \\(|A|\\), measures the size of the matrix\nthe identity matrix is the matrix multiplicative identity. It is represented by \\(\\boldsymbol{I}\\), in general \\(\\boldsymbol{I}_p\\) is a \\(p \\times p\\) matrix with 1 on each diagonal and 0 on every off-diagonal. \\(\\boldsymbol{I}A = A \\boldsymbol{I}= A\\).\nthe inverse of a matrix \\(A^{-1}\\) works as follows: \\(A A^{-1} = A^{-1}A = \\boldsymbol{I}\\).\nthe trace of a matrix, tr(A), is the sum of its diagonal elements\norder matters: \\(AB \\neq BA\\) in general.\n\\(\\Sigma > 0\\) is shorthand for saying the matrix is positive definite. This means that for all vectors \\(\\boldsymbol{x}\\), the quadratic form \\(\\boldsymbol{x}^T \\Sigma \\boldsymbol{x} > 0\\). \\(Sigma > 0 \\iff\\) all eigenvalues of \\(\\Sigma\\) are positive.\n\nExercise:\n\n\\(\\boldsymbol{\\theta}\\) and \\(\\boldsymbol{b}\\) are \\(p \\times 1\\) vectors, \\(A\\) is a symmetric matrix. Simplify \\(\\boldsymbol{b}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T A \\boldsymbol{b}\\) what is the dimension of the result?\nwhat’s the dimension of \\(V[\\boldsymbol{y}]\\)?\n\n\n\nmatrix operations in R\n\n# make a matrix A\nA = matrix(c(1,.2, .2, 2), ncol = 2)\nA\n\n     [,1] [,2]\n[1,]  1.0  0.2\n[2,]  0.2  2.0\n\n# invert A (expensive for large matrices)\nAinv = solve(A)\n\n# matrix multiplication\nAinv %*% A\n\n     [,1] [,2]\n[1,]    1    0\n[2,]    0    1\n\n# determinant of A\ndet(A)\n\n[1] 1.96\n\n# trace of A\nsum(diag(A))\n\n[1] 3\n\n# create a vector b\nb = matrix(c(1, 2), ncol = 1)\nb\n\n     [,1]\n[1,]    1\n[2,]    2\n\n# transpose the vector b\nt(b)\n\n     [,1] [,2]\n[1,]    1    2\n\n\n\nb %*% A\n\nError in b %*% A: non-conformable arguments\n\n\n\nWhat went wrong in the code above?"
  },
  {
    "objectID": "notes/lec10-mvn.html#semi-conjugate-priors",
    "href": "notes/lec10-mvn.html#semi-conjugate-priors",
    "title": "Multivariate normal",
    "section": "Semi-conjugate priors",
    "text": "Semi-conjugate priors\n\nprior on \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\Lambda_n &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1},\\\\\n\\boldsymbol{\\mu_n} &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1}(\\Lambda_0^{-1} \\boldsymbol{\\mu}_0 + n \\Sigma^{-1} \\bar{\\boldsymbol{y}}).\n\\end{aligned}\n\\]\nExercise: interprt \\(E[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\) and \\(Cov[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\)."
  },
  {
    "objectID": "notes/lec10-mvn.html#semiconjugate-priors",
    "href": "notes/lec10-mvn.html#semiconjugate-priors",
    "title": "Multivariate normal",
    "section": "Semiconjugate priors",
    "text": "Semiconjugate priors\n\nsemiconjugate prior for \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN(\\boldsymbol{\\mu_n}, \\Lambda_n),\n\\]\nwhere\n\\[\n\\begin{aligned}\n\\Lambda_n &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1},\\\\\n\\boldsymbol{\\mu_n} &= (\\Lambda_0^{-1} + n \\Sigma^{-1} )^{-1}(\\Lambda_0^{-1} \\boldsymbol{\\mu}_0 + n \\Sigma^{-1} \\bar{\\boldsymbol{y}}).\n\\end{aligned}\n\\]\nExercise: interpret \\(E[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\) and \\(Cov[\\boldsymbol{\\theta}| \\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n, \\Sigma]\\).\n\n\nsemiconjugate prior for \\(\\Sigma\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\Sigma &\\sim \\text{inverse-Wishart}(\\nu_0, S_0^{-1}),\n\\end{aligned}\n\\]\nthen\n\\[\n\\Sigma | \\boldsymbol{y}, \\boldsymbol{\\theta}\\sim \\text{inverse-Wishart} (\\nu_0 + n, (S_0 + S_{\\theta})^{-1}),\n\\]\nwhere \\(S_\\theta = \\sum_{i=1}^n (\\boldsymbol{y}_i - \\boldsymbol{\\theta})(\\boldsymbol{y}_i - \\boldsymbol{\\theta})^T\\) is the residual sum of squares matrix for the vectors \\(\\boldsymbol{y}_1, \\ldots \\boldsymbol{y}_n\\) if the population mean is \\(\\boldsymbol{\\theta}\\).\n\n\n\nthe inverse-Wishart\nthe inverse-Wishart\\((\\nu_0, S_0^{-1})\\) density is given by\n\\[\n\\begin{aligned}\np(\\Sigma | \\nu_0, S_0^{-1}) = \\left[\n2^{\\nu_0 p / 2} \\pi^{{p \\choose 2}/2} |S_0|^{-\\nu_0/2} \\prod_{j = 1}^p \\Gamma([\\nu_0 + 1 - j]/2)\n\\right]^{-1} \\times\\\\\n|\\Sigma|^{-(\\nu_0 + p + 1)/2} \\times \\exp \\{ -\\frac{1}{2}tr(S_0 \\Sigma^{-1})\\}.\n\\end{aligned}\n\\]\n\nKey facts\n\nnotice that the first line is the normalizing constant of the density\nthe support is \\(\\Sigma > 0\\) and \\(\\Sigma\\) symmetric \\(p \\times p\\) matrix. \\(\\nu_0 \\in \\mathbb{N}^+\\) and \\(\\nu_0 \\geq p\\). \\(S_0\\) is a \\(p \\times p\\) symmetric positive definite matrix.\nif \\(\\Sigma\\) is inv-Wishart\\((\\nu_0, S_0^{-1})\\) then \\(\\Sigma^{-1}\\) is Wishart\\((\\nu_0, S_0^{-1})\\).\n\\(E[\\Sigma^{-1}] = \\nu_0 S_0^{-1}\\) and \\(E[\\Sigma] = \\frac{1}{\\nu_0 - p - 1} S_0\\).\nintuition: \\(\\nu_0\\) is prior sample size. \\(S_0\\) is a prior guess of the covariance matrix.\n\n\n\nsampling from the inverse-Wishart\n\npick \\(\\nu_0 > p\\), pick \\(S_0\\)\nsample \\(\\boldsymbol{z}_1, \\ldots \\boldsymbol{z}_{\\nu_0} \\sim \\text{ i.i.d. } MVN(\\boldsymbol{0}, S_0^{-1})\\)\ncalculate \\(\\boldsymbol{Z}^T \\boldsymbol{Z} = \\sum_{i = 1}^{\\nu_0} \\boldsymbol{z}_i \\boldsymbol{z}^T\\)\nset \\(\\Sigma = (\\boldsymbol{Z}^T \\boldsymbol{Z})^{-1}\\)\n\n\nlibrary(mvtnorm) # contains function rmvnorm\n\n# 2x2 example: generating 1 sample from an inv-Wishart\nset.seed(360)\np = 2\nnu0 = 3\nS0 = matrix(c(1, .1, .1, 1), ncol = 2)\nS0inv = solve(S0)\nZ = rmvnorm(n = nu0, # number of observations of the 2D vector Z\n        mean = rep(0, p), # mean 0\n        sigma = S0inv) # prior variance\nSigma = solve(t(Z) %*% Z)\neigen(Sigma)$values\n\n[1] 0.7821737 0.4174527\n\nSigma\n\n           [,1]      [,2]\n[1,]  0.5271834 -0.167273\n[2,] -0.1672730  0.672443\n\n\nExercise/show offline: why does this work? Hint: what is \\(cov[\\boldsymbol{z}]\\)?\nWe can also use the monomvn package to simulate from a Wishart more succinctly,\n\nlibrary(monomvn)\n\nset.seed(360)\nSigma = solve(rwish(nu0, S0inv))\neigen(Sigma)$values\n\n[1] 0.692529 0.160428\n\nSigma\n\n          [,1]      [,2]\n[1,] 0.1899212 0.1217519\n[2,] 0.1217519 0.6630358"
  },
  {
    "objectID": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "href": "slides/lab-5.html#full-conditionals-are-proportional-to-the-joint",
    "title": "Full conditionals",
    "section": "Full conditionals are proportional to the joint",
    "text": "Full conditionals are proportional to the joint\nSuppose \\(X, Y, Z, \\theta, \\phi\\) are random variables,\n\\[\n\\begin{aligned}\np(x| y, z, \\theta, \\phi) &=\n\\frac{p(x, y, z, \\theta, \\phi)}{\\int p(x,y,z,\\theta, \\phi) dx}\\\\\n&\\propto_x p(x| y, z, \\theta, \\phi)\n\\end{aligned}\n\\]\nSimilarly, each full conditional is proportional to the joint distribution.\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "quizzes/quiz05.html",
    "href": "quizzes/quiz05.html",
    "title": "Quiz 5",
    "section": "",
    "text": "Exercise 1\nWhat is the purpose of Gibbs sampling?\n\n\nExercise 2\n\\(\\mathbf{x}\\) is a \\(p \\times 1\\) vector.\nWhat is the dimension of \\(\\mathbf{x}^T \\Sigma \\mathbf{x}\\)?\n\n\nExercise 3\nLet \\(\\mathbf{y} = \\left[ {\\begin{array}{cc}  y_1 \\\\  y_2  \\end{array} } \\right]\\), \\(\\boldsymbol{\\theta} = \\left[ {\\begin{array}{cc}  4 \\\\  8  \\end{array} } \\right]\\), \\(\\Sigma = \\left[ {\\begin{array}{cc}  1 & .2 \\\\  .2 & 1.3\\\\  \\end{array} } \\right]\\).\nIf \\(\\mathbf{y} | \\boldsymbol{\\theta}, \\Sigma \\sim MVN(\\boldsymbol{\\theta}, \\Sigma)\\), then \\(y_1 \\sim N(a, b)\\). What is \\(a\\) and \\(b\\)?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html",
    "href": "notes/lec11-missing-data-mvn.html",
    "title": "Inference under MVN with missing data",
    "section": "",
    "text": "This example is from Hoff ch. 7.\nLoad libraries and data.\n\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(monomvn)\nlibrary(coda)\nY = read_csv(\"https://sta360-fa23.github.io/data/Pima.csv\") %>%\n  as.matrix() \ncolnames(Y) = NULL\n\nThis data set contains\n\nglu blood plasma glucose concentration\nbp diastolic blood pressure\nskin skin fold thickness\nbmi body mass index\n\nfor 200 women of Pima Indian heritage living near Phoenix, Arizona (Smith et al, 1988). Some observations are missing.\n\n\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]<-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA <- SIGMA <- Y.MISS <- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar <- apply(Y.full, 2 , mean)\n  Ln <- solve(solve(L0) + n * solve(Sigma))\n  mun <- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta <- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn <- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma <- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b <- (O[i, ] == 0)\n    a <- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa <- solve(Sigma[a, a])\n    beta.j <- Sigma[b, a] %*% iSa\n    s2.j   <- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j <- theta[b] + beta.j %*% (as.matrix(Y.full[i, a]) - theta[a])\n    Y.full[i, b] <- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA<-rbind(THETA,theta) ; SIGMA<-rbind(SIGMA,c(Sigma))\n  Y.MISS<-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\n\n\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/lec11-missing-data-mvn.html#inference-using-gibbs-sampling",
    "href": "notes/lec11-missing-data-mvn.html#inference-using-gibbs-sampling",
    "title": "Inference under MVN with missing data",
    "section": "Inference using Gibbs sampling",
    "text": "Inference using Gibbs sampling\nSetup prior parameters and starting values.\n\n## prior parameters\nn = nrow(Y); p = ncol(Y)\n# prior on theta\nmu0 = c(120, 64, 26, 26); sd0 = (mu0 / 2)\nL0 = matrix(.1, p, p)\ndiag(L0) = 1 \nL0 = L0 * outer(sd0, sd0) # \\Lambda_0\n# prior on Sigma\nnu0 = p + 2; \nS0 = L0\n###\n\n### starting values\nSigma = S0\nY.full = Y\nO = 1 * (!is.na(Y)) # indices for observe values of Y\n\nfor(j in 1:p) {\n  Y.full[is.na(Y.full[,j]),j]<-mean(Y.full[,j],na.rm=TRUE)\n} \n\nExercise: what does the code above set the starting values of \\(\\theta, \\Sigma\\) and \\(\\textbf{Y}_{\\text{mis}}\\) to?\nThe Gibbs sampler.\n\n### Gibbs sampler\nTHETA <- SIGMA <- Y.MISS <- NULL\nset.seed(360)\n\nfor(s in 1:1000) {\n\n  ###update theta\n  ybar <- apply(Y.full, 2 , mean)\n  Ln <- solve(solve(L0) + n * solve(Sigma))\n  mun <- Ln %*% (solve(L0) %*% mu0 + n * solve(Sigma) %*% ybar)\n  theta <- rmvnorm(1, mun, Ln)\n  ###\n  \n  ###update Sigma\n  Sn <- S0 + (t(Y.full) - c(theta)) %*% t(t(Y.full) - c(theta))\n  Sigma <- rwish(nu0 + n, solve(Sn))\n  ###\n  \n  ###update missing data\n  for(i in 1:n) { \n    b <- (O[i, ] == 0)\n    a <- (O[i, ] == 1)\n    if( sum(b) != 0) {\n    iSa <- solve(Sigma[a, a])\n    beta.j <- Sigma[b, a] %*% iSa\n    s2.j   <- Sigma[b, b] - Sigma[b, a] %*% iSa %*% Sigma[a, b]\n    theta.j <- theta[b] + beta.j %*% t((t(Y.full[i, a]) - theta[a]))\n    Y.full[i, b] <- rmvnorm(1, theta.j, s2.j)\n    }\n  }\n  \n  ### save results\n  THETA<-rbind(THETA,theta) ; SIGMA<-rbind(SIGMA,c(Sigma))\n  Y.MISS<-rbind(Y.MISS, Y.full[O==0] )\n  ###\n\n  if(s %% 250 == 0 | s == 1) {\n  cat(s,theta,\"\\n\")\n  }\n}\n\n1 129.6031 71.66437 28.97947 31.385 \n250 123.6105 70.56862 29.10075 30.97481 \n500 123.6067 70.36211 29.20791 31.03185 \n750 123.6179 70.78825 29.29216 30.90945 \n1000 123.6017 70.15369 29.22685 31.08064 \n\n#### Posterior mean and correlation matrix\napply(THETA,2,mean)\n\n[1] 123.60189  70.57085  29.16132  31.79352\n\nCOR <- array( dim=c(p,p,1000) )\nfor(s in 1:1000)\n{\n  Sig<-matrix( SIGMA[s,] ,nrow=p,ncol=p)\n  COR[,,s] <- Sig/sqrt( outer( diag(Sig),diag(Sig) ) )\n}\n\napply(COR,c(1,2),mean)\n\n            [,1]        [,2]        [,3]        [,4]\n[1,]  1.00000000 -0.05304617 -0.02145301 -0.02476015\n[2,] -0.05304617  1.00000000 -0.05261611 -0.05542203\n[3,] -0.02145301 -0.05261611  1.00000000 -0.24354650\n[4,] -0.02476015 -0.05542203 -0.24354650  1.00000000\n\n\nEffective sample size of THETA\n\n# effective sample size of THETA \napply(THETA, 2, effectiveSize)\n\n[1]  879.4569 3680.4806 4411.2164 7721.7664"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html",
    "href": "notes/lec12-hierarchical-intro.html",
    "title": "Hierarchical modeling",
    "section": "",
    "text": "Example from Hoff Ch. 8\n\nEach year, students across North Carolina take an identical standardized test. In our sample, we observe scores from students at \\(m\\) different schools. At the \\(j\\)th school, \\(n_j\\) students take the exam and \\(j \\in \\{1, \\ldots m\\}\\). The exam is designed to give an average score of 50 on a 0 to 100 scale.\n\n\n\n# load packages\nlibrary(tidyverse)\nlibrary(coda)\n\n\n# load data\nmathScores = read_csv(\"https://sta360-fa23.github.io/data/mathScores.csv\")\n\n\nhead(mathScores, n = 3)\n\n# A tibble: 3 × 2\n  school mathscore\n   <dbl>     <dbl>\n1      1      52.1\n2      1      57.6\n3      1      66.4\n\n\nCodebook\n\nschool: which school the math score came from\nmathScore: score from 0 to 100 of an individual student\n\n\n\n\n\n\n\n\nConvert data to list for downstream processing\nY.school.mathscore <- as.matrix(mathScores)\n#### Put data into list form.\nY <- list()\nJ <- max(Y.school.mathscore[, 1])\nn <- ybar <- ymed <- s2 <- rep(0, J)\nfor (j in 1:J) {\n  Y[[j]] <- Y.school.mathscore[Y.school.mathscore[, 1] == j, 2]\n}"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#questions-about-the-data",
    "href": "notes/lec12-hierarchical-intro.html#questions-about-the-data",
    "title": "Hierarchical modeling",
    "section": "Questions about the data",
    "text": "Questions about the data\n\nHow are the schools ranked?\nDoes school 51 have a higher average score than school 41?\nWhat is the probability a single student randomly selected from school 51 performs better on the exam than a single student randomly selected from school 41?"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#modeling",
    "href": "notes/lec12-hierarchical-intro.html#modeling",
    "title": "Hierarchical modeling",
    "section": "Modeling",
    "text": "Modeling"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#gibbs-sampling",
    "href": "notes/lec12-hierarchical-intro.html#gibbs-sampling",
    "title": "Hierarchical modeling",
    "section": "Gibbs sampling",
    "text": "Gibbs sampling\n\n#### MCMC approximation to posterior for the hierarchical normal model\n\n## weakly informative priors\nnu0 <- 1; s20 <- 100\neta0 <- 1; t20 <- 100\nmu0 <- 50; g20 <- 25\n\n## starting values\nm <- length(Y)\nn <- sv <- ybar <- rep(NA, m)\nfor (j in 1:m)\n{\n  ybar[j] <- mean(Y[[j]])\n  sv[j] <- var(Y[[j]])\n  n[j] <- length(Y[[j]])\n}\ntheta <- ybar\nsigma2 <- mean(sv)\nmu <- mean(theta)\ntau2 <- var(theta)\n\n## setup MCMC\nset.seed(1)\nS <- 5000\nTHETA <- matrix(nrow = S, ncol = m)\nMST <- matrix(nrow = S, ncol = 3)\npredictiveY = NULL\n\n## MCMC algorithm\nfor (s in 1:S)\n{\n  # sample new values of the thetas\n  for (j in 1:m)\n  {\n    vtheta <- 1 / (n[j] / sigma2 + 1 / tau2)\n    etheta <- vtheta * (ybar[j] * n[j] / sigma2 + mu / tau2)\n    theta[j] <- rnorm(1, etheta, sqrt(vtheta))\n  }\n  \n  #sample new value of sigma2\n  nun <- nu0 + sum(n)\n  ss <- nu0 * s20\n  for (j in 1:m) {\n    ss <- ss + sum((Y[[j]] - theta[j]) ^ 2)\n  }\n  sigma2 <- 1 / rgamma(1, nun / 2, ss / 2)\n  \n  #sample a new value of mu\n  vmu <- 1 / (m / tau2 + 1 / g20)\n  emu <- vmu * (m * mean(theta) / tau2 + mu0 / g20)\n  mu <- rnorm(1, emu, sqrt(vmu))\n  \n  # sample a new value of tau2\n  etam <- eta0 + m\n  ss <- eta0 * t20 + sum((theta - mu) ^ 2)\n  tau2 <- 1 / rgamma(1, etam / 2, ss / 2)\n  \n  #store results\n  THETA[s, ] <- theta\n  MST[s, ] <- c(mu, sigma2, tau2)\n  \n  # predictive sampling\n  y51 = rnorm(1, mean = theta[51], sd = sqrt(sigma2))\n  y41 = rnorm(1, mean = theta[41], sd = sqrt(sigma2))\n  predictiveY = rbind(predictiveY, c(y51, y41))\n  \n}\n\nmcmc1 <- list(THETA = THETA, MST = MST)"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#answers",
    "href": "notes/lec12-hierarchical-intro.html#answers",
    "title": "Hierarchical modeling",
    "section": "Answers",
    "text": "Answers\n\nHow are the schools ranked? How does the ordering compare to just ranking the schools by the sample means?\n\n\n# Ordering E[theta | data] and comparing to ybar\n\nposteriorMean = THETA %>%\n  apply(2, mean)\n\norderedTable = mathScores %>%\n  group_by(school) %>%\n  summarize(ybar = mean(mathscore),\n            n = n()) %>%\n  cbind(posteriorMean) %>%\n  arrange(posteriorMean) %>%\n  relocate(school, n, ybar, posteriorMean) %>%\n  mutate_if(is.numeric, round, digits = 2)\n\nDT::datatable(\n  orderedTable,\n  fillContainer = FALSE, options = list(pageLength = 10)\n)\n\n\n\n\n\n\nHow many of the schools are ranked in the same position in the posterior ordering as the sample mean ordering?\n\noutputcode\n\n\n\n\n[1] 46\n\n\n\n\n\npostOrdering = posteriorMean %>%\n  order()\n\nybarOrdering = mathScores %>%\n  group_by(school) %>%\n  summarize(ybar = mean(mathscore), \n            n = n()) %>%\n  arrange(ybar) %>%\n  pull(school)\n\nsum(postOrdering == ybarOrdering)\n\n\n\n\n\nDoes school 51 have a higher average score than school 41? Re-cast as a Bayesian question: what’s \\(p(\\theta_{51} > \\theta_{41} | \\text{data})\\)?\n\n\nmean(THETA[,51] > THETA[,41])\n\n[1] 0.9892\n\n\n\nWhat’s the probability a student randomly selected from school 51 performs better than a student selected randomly from school 41?\n\nBefore looking at the solution below, how would you answer this problem?\n\n\nSolution\nmean(predictiveY[,1] > predictiveY[,2])\n\n# output:\n# [1] 0.685"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#mcmc-diagnostics",
    "href": "notes/lec12-hierarchical-intro.html#mcmc-diagnostics",
    "title": "Hierarchical modeling",
    "section": "MCMC diagnostics",
    "text": "MCMC diagnostics\n\ntrace plots\n\nplotscode\n\n\n\n\n\n\n\n\n\n\ncolnames(MST) = c(\"mu\", \"sigma2\", \"tau2\")\nMST2 = MST %>%\n  as.data.frame() %>% \n  pivot_longer(cols = 1:3)\n\nMST2 %>%\n  ggplot(aes(x = seq(1, nrow(MST2)), y = value)) +\n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ name, scales = \"free_y\") +\n  labs(y = \"mu\",\n       x = \"iteration\",\n       title = \"Traceplot of 5000 Gibbs samples\")\n\n\n\n\n\n\neffective sample size and autocorrelation\n\neffectiveSize(MST)\n\n      mu    sigma      tau \n3925.336 4461.112 2905.517 \n\npar(mfrow=c(1,3))\nacf(MST[,1])\nacf(MST[,2]) \nacf(MST[,3]) \n\n\n\n\n\n\nposterior means and standard error\n\n# MC error of mu, sigma2, tau2\nMCERR <- apply(MST,2,sd)/sqrt( effectiveSize(MST) )\napply(MST,2,mean)\n\n      mu    sigma      tau \n48.12530 84.82892 24.79410 \n\nMCERR\n\n         mu       sigma         tau \n0.008528321 0.041664073 0.082344432 \n\n\nWe can do the exact same for the thetas, but the output will be 100 lines, so I suppress output below.\n\n# MC error of thetas\neffectiveSize(THETA) -> esTHETA\nTMCERR <- apply(THETA,2,sd)/sqrt( effectiveSize(THETA) )\nTMCERR"
  },
  {
    "objectID": "notes/lec12-hierarchical-intro.html#model",
    "href": "notes/lec12-hierarchical-intro.html#model",
    "title": "Hierarchical modeling",
    "section": "Model",
    "text": "Model\nSuppose students scores at school \\(j\\) are exchangeable for all \\(n_j\\). By de Finetti’s theorem, this means\n\\[\n\\{y_{1,j}, \\ldots y_{n_j,j} | \\phi_j \\} \\sim \\text{ i.i.d. } p(y|\\phi_j).\n\\]\nThat is, the student’s scores at school \\(j\\) are conditionally i.i.d. given some school specific parameters \\(\\phi_j\\). This describes our within-group sampling variability.\nNow suppose that all the schools we sampled are similar in some way. Maybe they belong to some larger population of schools across the country i.e. schools in North Carolina are somewhat distinct from schools in South Carolina. We might imagine that the school-specific parameters themselves are exchangeable for all \\(m\\). By de Finetti’s theorem, this means\n\\[\n\\{\\phi_1, \\ldots \\phi_m\\} \\sim \\text{ i.i.d. } p(\\phi|\\psi).\n\\]\nIn words, school-specific parameters are conditionally i.i.d. given some population specific parameters \\(\\psi\\). This describes our between-group sampling variability.\nFinally, if our hierarchy stops there, then to complete model specification, we may describe our prior beliefs about \\(\\psi\\) according to some prior density \\(p(\\psi)\\).\nExercise: Imagine variability among scores is the same across all schools, but there does exist heterogeneity in the mean scores of the schools. Write down the mathemtical form of a model that describes this using the normal distribution. What are some priors you could pick on relevant parameters to make sure full conditionals are easy to compute for Gibbs sampling? What are the full conditionals?\n\nSolution:\n\nsampling distributions:\n\n\\[\n\\begin{aligned}\ny_j | \\theta_j, \\sigma^2 &\\sim N(\\theta_j, \\sigma^2)\\\\\n\\theta_j | \\mu, \\tau^2 &\\sim N(\\mu, \\tau^2)\n\\end{aligned}\n\\]\n\npriors distributions:\n\n\\[\n\\begin{aligned}\n1/\\sigma^2 &\\sim \\text{ gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2/2)\\\\\n1/\\tau^2 &\\sim \\text{ gamma}(\\eta_0/2, \\eta_0 \\tau_0^2/2)\\\\\n\\mu &\\sim N(\\mu_0, \\gamma_0^2)\n\\end{aligned}\n\\]\n\nTo facilitate Gibbs sampling, notice\n\\[\np(\\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2 | \\mathbf{y}_1, \\ldots \\mathbf{y}_m) \\propto\np(\\mu, \\tau^2, \\sigma^2) p(\\theta_1, \\ldots \\theta_m | \\mu, \\tau^2, \\sigma^2) \\times p(\\mathbf{y}_1, \\ldots \\mathbf{y}_m| \\theta_1, \\ldots \\theta_m, \\mu, \\tau^2, \\sigma^2)\n\\]\nIt follows that the full conditionals are:\n\\[\n\\begin{aligned}\np(\\mu | \\cdot) &\\propto p(\\mu) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\tau^2 | \\cdot) &\\propto p(\\tau^2) \\prod_{j = 1}^m p(\\theta_j| \\mu, \\tau^2)\\\\\np(\\sigma^2|\\cdot) &\\propto p(\\sigma^2)\\prod_{j =1}^m \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\\\\\np(\\theta_j | \\cdot) &\\propto p(\\theta_j | \\mu, \\tau^2) \\prod_{i = 1}^{n_j} p(y_{i,j}|\\theta_j, \\sigma^2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lab06.html#exercise-1",
    "href": "slides/lab06.html#exercise-1",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet \\(p(\\theta_1, \\theta_2 | \\mathbf{y})\\) be our target distribution, i.e. the distribution we are interested in sampling.\nWe construct a Gibbs sampler and look at the trace plots of \\(\\theta_1\\) and \\(\\theta_2\\), produced below. Chat with your neighbor, describe what you observe. Has the chain converged for each parameter? How well is the sampler mixing? Do you think the parameters are correlated or uncorrelated?\nWrite down a description of the plots below, in 2 paragraphs or less, for a reader who has not taken this class. You may assume the reader has taken a course on probability (e.g. similar to STA230/240)."
  },
  {
    "objectID": "slides/lab06.html#exercise-2",
    "href": "slides/lab06.html#exercise-2",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nBased on the first 1000 iterations of your Gibbs sampler shown on the previous slide, which of the following joint densities is the most plausible for \\(\\theta_1, \\theta_2 | \\mathbf{y}\\)? Why? Hint: it may help to think about where your sampler starts and imagine a particle moving through space according to conditional updates.\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#exercise-1",
    "href": "slides/lab6-mcmc-d-practice.html#exercise-1",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet \\(p(\\theta_1, \\theta_2 | \\mathbf{y})\\) be our target distribution, i.e. the distribution we are interested in sampling.\nWe construct a Gibbs sampler and look at the trace plots of \\(\\theta_1\\) and \\(\\theta_2\\), produced below. Chat with your neighbor, describe what you observe. Has the chain converged for each parameter? How well is the sampler mixing? Do you think the parameters are correlated or uncorrelated?\nWrite down a description of the plots below, in 2 paragraphs or less, for a reader who has not taken this class. You may assume the reader has taken a course on probability (e.g. similar to STA230/240)."
  },
  {
    "objectID": "slides/lab6-mcmc-d-practice.html#exercise-2",
    "href": "slides/lab6-mcmc-d-practice.html#exercise-2",
    "title": "MCMC diagnostics practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nBased on the first 1000 iterations of your Gibbs sampler shown on the previous slide, which of the following joint densities is the most plausible for \\(\\theta_1, \\theta_2 | \\mathbf{y}\\)? Why? Hint: it may help to think about where your sampler starts and imagine a particle moving through space according to conditional updates.\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/lec13-regression-intro.html",
    "href": "notes/lec13-regression-intro.html",
    "title": "Intro to regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#section-1",
    "href": "notes/lec13-regression-intro.html#section-1",
    "title": "Intro to regression",
    "section": "Section 1",
    "text": "Section 1"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#basic-regression",
    "href": "notes/lec13-regression-intro.html#basic-regression",
    "title": "Intro to regression",
    "section": "Basic regression",
    "text": "Basic regression\nThe most basic form of linear regression states the following constraint:\n\\[\nE Y |X = \\beta^T \\mathbf{x} = \\beta_1 x_1 + \\beta_2 x_2 + \\ldots \\beta_p x_p\n\\]\nOften regression is motivated as “prediction”. Given a set of predictors \\(x_1, \\ldots x_p\\), what is our prediction, \\(\\hat{y}\\)? If our prediction \\(p(y|\\mathbf{x})\\), is centered on a mean (as above), then our prediction will be poor when \\(p(y|\\mathbf{x})\\) exhibits\n\nskewness\n\n\n\n\nxpower = function(x, p) {\n  if(p == 0) {\n    return(log(x))\n  }\n  else {\n  return((x^p - 1) / p)\n  }\n  # return(x^p)\n}\n\ndf = data.frame(x = seq(0.1, 4, by = 0.01))\n\np = df %>%\n  ggplot(aes(x = x)) +\n  theme_bw() +\n  labs(y = \"\")\n\npowList = -1:4\ncols = viridis::turbo(n=length(powList))\n\nfor (i in seq_along(powList)) {\n  p = p + \n  stat_function(fun = xpower, args = list(p = powList[i]), color = cols[i])\n}\n\np"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#linear-modeling",
    "href": "notes/lec13-regression-intro.html#linear-modeling",
    "title": "Intro to regression",
    "section": "Linear modeling",
    "text": "Linear modeling\n\n\n\n\n\n\\[\nE Y |X = \\beta^T \\mathbf{x} = \\beta_1 x_1 + \\beta_2 x_2 + \\ldots \\beta_p x_p\n\\] Often regression is motivated as “prediction”. Given a set of predictors \\(x_1, \\ldots x_p\\), what is our prediction, \\(\\hat{y}\\)? If our prediction \\(p(y|\\mathbf{x})\\), is centered on a mean (as above), then our prediction will be poor when \\(p(y|\\mathbf{x})\\) exhibits\n\nskewness\n\n\n\n\nxpower = function(x, p) {\n  if(p == 0) {\n    return(log(x))\n  }\n  else {\n  return((x^p - 1) / p)\n  }\n  # return(x^p)\n}\n\ndf = data.frame(x = seq(0.1, 4, by = 0.01))\n\np = df %>%\n  ggplot(aes(x = x)) +\n  theme_bw() +\n  labs(y = \"\")\n\npowList = -1:4\ncols = viridis::turbo(n=length(powList))\n\nfor (i in seq_along(powList)) {\n  p = p + \n  stat_function(fun = xpower, args = list(p = powList[i]), color = cols[i])\n}\n\np"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#linear-modeling-and-terminology",
    "href": "notes/lec13-regression-intro.html#linear-modeling-and-terminology",
    "title": "Intro to regression",
    "section": "Linear modeling and terminology",
    "text": "Linear modeling and terminology\n\n\n\n\n\n\nA generalized linear model states \\(E[Y|X] = g(X\\beta)\\), for some function \\(g\\).\nLinear regression is but a special case, \\(E[Y|X] = X \\beta\\). This is what we will focus on today.\nLeast squares regression (otherwise termed “ordinary least squares” or “OLS”) refers to a particular method of estimating \\(\\beta\\): minimize the sum of squared residuals.\n\n\\[\nE Y |X = \\beta^T \\mathbf{x} = \\beta_1 x_1 + \\beta_2 x_2 + \\ldots \\beta_p x_p\n\\] Often regression is motivated as “prediction”. Given a set of predictors \\(x_1, \\ldots x_p\\), what is our prediction, \\(\\hat{y}\\)? If our prediction \\(p(y|\\mathbf{x})\\), is centered on a mean (as above), then our prediction will be poor when \\(p(y|\\mathbf{x})\\) exhibits\n\nskewness\n\n\n\n\nxpower = function(x, p) {\n  if(p == 0) {\n    return(log(x))\n  }\n  else {\n  return((x^p - 1) / p)\n  }\n  # return(x^p)\n}\n\ndf = data.frame(x = seq(0.1, 4, by = 0.01))\n\np = df %>%\n  ggplot(aes(x = x)) +\n  theme_bw() +\n  labs(y = \"\")\n\npowList = -1:4\ncols = viridis::turbo(n=length(powList))\n\nfor (i in seq_along(powList)) {\n  p = p + \n  stat_function(fun = xpower, args = list(p = powList[i]), color = cols[i])\n}\n\np"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#background",
    "href": "notes/lec13-regression-intro.html#background",
    "title": "Intro to regression",
    "section": "Background",
    "text": "Background\n\nLinear modeling and terminology\n\n\n\n\n\n\nA generalized linear model states \\(E[Y|X] = g(X\\beta)\\), for some function \\(g\\).\nLinear regression is but a special case, \\(E[Y|X] = X \\beta\\). This is what we will focus on today.\nLeast squares regression (otherwise termed “ordinary least squares” or “OLS”) refers to a particular method of estimating \\(\\beta\\): minimize the sum of squared residuals.\n\n\\[\nE Y |X = \\beta^T \\mathbf{x} = \\beta_1 x_1 + \\beta_2 x_2 + \\ldots \\beta_p x_p\n\\] Often regression is motivated as “prediction”. Given a set of predictors \\(x_1, \\ldots x_p\\), what is our prediction, \\(\\hat{y}\\)? If our prediction \\(p(y|\\mathbf{x})\\), is centered on a mean (as above), then our prediction will be poor when \\(p(y|\\mathbf{x})\\) exhibits\n\nskewness\n\n\n\n\nxpower = function(x, p) {\n  if(p == 0) {\n    return(log(x))\n  }\n  else {\n  return((x^p - 1) / p)\n  }\n  # return(x^p)\n}\n\ndf = data.frame(x = seq(0.1, 4, by = 0.01))\n\np = df %>%\n  ggplot(aes(x = x)) +\n  theme_bw() +\n  labs(y = \"\")\n\npowList = -1:4\ncols = viridis::turbo(n=length(powList))\n\nfor (i in seq_along(powList)) {\n  p = p + \n  stat_function(fun = xpower, args = list(p = powList[i]), color = cols[i])\n}\n\np"
  },
  {
    "objectID": "notes/lec13-regression-intro.html#background-review",
    "href": "notes/lec13-regression-intro.html#background-review",
    "title": "Intro to regression",
    "section": "Background review",
    "text": "Background review\n\nLinear modeling and linear regression\n\n\n\n\n\n\nA generalized linear model states \\(E[Y|X] = g(X\\beta)\\), for some invertible “link” function \\(g\\).\nLinear regression is but a special case, \\(E[Y|X] = X \\beta\\). This is what we will focus on today.\nLeast squares regression (otherwise termed “ordinary least squares” or “OLS”) refers to a particular method of estimating \\(\\beta\\): minimize the sum of squared residuals.\n\n\n\nNotation\n\n\\(\\mathbf{y} = \\{y_1, \\ldots y_n\\}\\) is an \\(n \\times 1\\) vector outcomes. Also called the “response” or “dependent variable”. \\(y_i\\) is an individual observed outcome.\n\\(\\mathbf{x}_i\\) is a \\(p \\times 1\\) vector of predictors also called “regressors”, “independent variables”, “covariates”, or “features”.\n\\(X\\) is a \\(n \\times p\\) matrix of all covariates. This is often referred to as “the data matrix”.\n\\(\\beta\\) is a \\(p \\times 1\\) vector of constants. These are referred to as parameters. These are fixed, but unknown numbers. Being Bayesian, we will describe our uncertainty about this population parameter vector using probability statements.\n\n\n\nCommon convention\nThe linear model\n\\[\nE[Y | X\\beta] = X \\beta\n\\]\noften has the hidden convention that the first column of \\(X\\) is all 1s and \\(\\beta_1\\) is understood to be the intercept term. E.g.\n\\[\nE [ Y | X ]  =\n  \\begin{bmatrix}\n    1 & x_{12} & \\ldots & x_{1p} \\\\\n    1 & x_{22} & \\ldots & x_{2p} \\\\\n    \\vdots & \\vdots & & \\vdots\\\\\n    1 & x_{n2} & \\ldots & x_{np}\n  \\end{bmatrix}\n    \\begin{bmatrix}\n    \\beta_1\\\\\n    \\beta_2\\\\\n    \\vdots\\\\\n    \\beta_p\n  \\end{bmatrix}\n\\]\n\n\nIllustration of a linear model\n\nExample\nImagine we’ve collected 3 measurements on a number of penguins:\n\nbody mass (g)\nbill length (mm)\nflipper length (mm)\n\nThe first five entries of our data set are given below:\n\n\n# A tibble: 5 × 3\n  body_mass_g bill_length_mm flipper_length_mm\n        <int>          <dbl>             <int>\n1        3750           39.1               181\n2        3800           39.5               186\n3        3250           40.3               195\n4        3450           36.7               193\n5        3650           39.3               190\n\n\nIn all, our data set contains the measurements of 342 penguins. Because we’ve collected three measurements, each individual penguin can be represented as a point in three dimensional space:\n\n\n\n\n\nNow, imagine it’s hard to measure a penguin’s bodymass because it’s difficult to get them onto a scale. We wish to develop a linear model that uses bill length and flipper length to predict body mass,\n\\[\nE[Y|X] = X \\beta,\n\\]\nwhere\n\n\\(Y\\) is the body mass of the penguins and\n\\(X\\) contains covariates bill length and flipper length.\n\nWhat does our linear model look like?\n\n\n\n\n\nIn general, for \\(D\\) measurements, a linear model is a \\(D-1\\) dimensional hyperplane!\n\n\n\nTraditional way to find the hyperplane\nTo “fit” a linear regression model means to estimate \\(\\beta\\). One way to do this is to minimize some objective function. A really common function to minimize is the sum of square residuals SSR.\nA residual is defined as the distance our mean is from the true value:\n\\[\n\\begin{aligned}\nr_i &= y_i - E[y_i | \\mathbf{x}\\beta]\\\\\n&= y_i - \\beta^T\\mathbf{x}_i\n\\end{aligned}\n\\]\nThus the sum of square residuals is:\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n r_i^2 &= \\sum_{i=1}^n (y_i - \\beta^T \\mathbf{x}_i)^2\\\\\n&= (\\mathbf{y} -X\\beta)^T(\\mathbf{y} -X\\beta)\\\\\n&= \\mathbf{y}^T \\mathbf{y} - 2\\beta^T X^T\\mathbf{y} + \\beta^TX^TX\\beta)\n\\end{aligned}\n\\]\nExercise 1: what other objective functions could we optimize?\nThe ordinary least squares (OLS) estimate is\n\\[\n\\hat{\\beta}_{OLS} = (X^TX)^{-1}X^T \\mathbf{y}\n\\]\n\nSee the matrix cookbook by Petersen and Petersen for all your matrix algebra needs.\n\nExercise 2: is \\(\\hat{\\beta}_{OLS}\\) biased?\n\n\nNormal linear regression model\nSo far, we had not made any distributional assumptions, we only made an assumption about the expectation. Now for the normal linear regression model,\n\\[\nY = X \\beta + \\epsilon\n\\]\nand \\(\\epsilon \\sim N(0, \\sigma^2 I)\\) where \\(I\\) is a \\(n \\times n\\) identity matrix. This is a way of saying \\(\\epsilon_i \\sim_{iid} N(0, \\sigma^2)\\).\nTherefore,\n\\[\n\\mathbf{y} | X, \\beta, \\sigma^2 \\sim MVN(X\\beta, \\sigma^2 I)\n\\]\nExercise 3: What is \\(Var(\\hat{\\beta}_{OLS})\\) under the normal model?\n\n\n\n\n\n\nHint\n\n\n\nLet \\(z\\) be a random vector. \\(Var[Az] = A Var(z) A^T\\).\n\n\nExercise 4: What is \\(\\hat{\\beta}_{MLE}\\)?\n\n\nAssumptions\nA brief reminder about the flexibility and limitations of classical linear regression.\n\nLimitations so far:\n\nthe mean may not be a good summary of the conditional relationship, e.g. if \\(p(y|x)\\) is skewed, multimodal, or has heavy tails.\nerror may not be iid. In other words, the conditional variance of \\(Y\\) may change with the \\(\\mathbf{x}\\)s.\n\n\n\nFlexibility\nIs this an example of linear regression?\n\\[\ny_i = \\beta_1 + \\beta_2x_1 + \\beta_3 x_1^2 + \\beta_4 \\log x_1 + \\beta_5 x_2 + \\beta_6 x_1 x_2 + \\epsilon_i\n\\]\nWhat’s linear about linear regression? The parameters!\nThis is powerful, because nonlinear relationships between \\(X\\) and \\(\\mathbf{y}\\) can often be corrected by a power transformation of \\(X\\), \\(\\mathbf{y}\\) or of both variables."
  },
  {
    "objectID": "notes/lec13-regression-intro.html#bayesian-regression",
    "href": "notes/lec13-regression-intro.html#bayesian-regression",
    "title": "Intro to regression",
    "section": "Bayesian regression",
    "text": "Bayesian regression\nLet’s assume the normal sampling model (i.e. normal data generative process, aka normal likelihood),\n\\[\n\\mathbf{y} | X, \\beta, \\sigma^2 \\sim MVN(X\\beta, \\sigma^2I).\n\\]\nTo make inference about our model parameters, we will construct a posterior distribution,\n\\[\np(\\beta, \\sigma^2 | \\mathbf{y}, X) \\propto \\underbrace{ p(\\mathbf{y}|X, \\beta, \\sigma^2)}_{likelihood} \\underbrace{p(\\beta, \\sigma^2)}_{prior}\n\\]\n\nsemi-conjugate prior specification\nTo setup Gibbs sampling, let’s consider independent semi-conjugate priors, i.e. assume \\(p(\\beta, \\sigma^2) = p(\\beta) p(\\sigma^2)\\)\nBefore reading ahead, what do you think semi-conjugate priors will be for the parameters under the normal linear regression model?\n\nsemi-conjuate prior on \\(\\beta\\)\nIf\n\\[\n\\beta \\sim MVN(\\beta_0, \\Sigma_0)\n\\]\nthen\n\\[\n\\begin{aligned}\np(\\beta|\\mathbf{y}, X, \\sigma^2) &\\propto\np( \\mathbf{y} | X, \\beta, \\sigma^2) p(\\beta)\\\\\n&\\propto MVN(\\mathbf{m}, V)\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\nV = Var[\\beta | \\mathbf{y}, X, \\sigma^2] &=\n(\\Sigma_0^{-1} + X^TX / \\sigma^2)^{-1}\\\\\n\\mathbf{m} = E[\\beta | \\mathbf{y}, X, \\sigma^2] &= (\\Sigma_0^{-1} + X^T X/ \\sigma^2)^{-1}(\\Sigma_0^{-1} \\beta_0 + X^T\\mathbf{y} / \\sigma^2)\n\\end{aligned}\n\\]\n\n\nsemi-conjugate prior on \\(\\sigma^2\\)\nLet’s re-parameterize. Let \\(\\gamma = 1/\\sigma^2\\).\nIf\n\\[\n\\gamma \\sim \\text{gamma}(\\nu_0 /2, \\nu_0 \\sigma_0^2 / 2)\n\\]\nthen\n\\[\n\\begin{aligned}\np(\\gamma | \\mathbf{y}, X, \\beta) &\\propto p( \\mathbf{y} | X, \\beta, \\sigma^2) p(\\gamma)\\\\\n&\\propto\n\\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta)]/2)\n\\end{aligned}\n\\]\nExercise 5: write out the pseudo-code of a Gibbs sampler that samples from \\(p(\\beta, \\sigma^2| \\mathbf{y}, X)\\)."
  },
  {
    "objectID": "hw/hw07.html",
    "href": "hw/hw07.html",
    "title": "Homework 7",
    "section": "",
    "text": "7.3 from Hoff.\nRun the code below to load the data.\n\n\n\n\nlibrary(readr)\nbluecrab = read_csv(\"https://sta360-fa23.github.io/data/bluecrab.csv\")\norangecrab = read_csv(\"https://sta360-fa23.github.io/data/orangecrab.csv\")"
  },
  {
    "objectID": "hw/hw07.html#exercise-2",
    "href": "hw/hw07.html#exercise-2",
    "title": "Homework 7",
    "section": "Exercise 2",
    "text": "Exercise 2\n8.1 from Hoff. Note there is a typo in this exercise. Every \\(\\theta_i\\) in the exercise prompt should be replaced by \\(\\theta_j\\)."
  },
  {
    "objectID": "hw/hw07.html#exercise-3",
    "href": "hw/hw07.html#exercise-3",
    "title": "Homework 7",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n\n\n8.3 from Hoff\nRun the code below to load the data.\n\nlibrary(readr)\nlibrary(glue)\n\nfor(i in 1:8) {\nassign(paste0(\"school\", i), \n       read_csv(glue(\"https://sta360-fa23.github.io/data/school{i}.csv\")))\n}"
  },
  {
    "objectID": "notes/lec14-BayesianRegression2.html",
    "href": "notes/lec14-BayesianRegression2.html",
    "title": "Bayesian regression II",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(patchwork)\nlibrary(tidymodels)\nlibrary(scatterplot3d)\nlibrary(palmerpenguins)\nlibrary(mvtnorm)\nlibrary(coda)\nlibrary(animation)"
  },
  {
    "objectID": "notes/lec14-BayesianRegression2.html#gibbs-sampler",
    "href": "notes/lec14-BayesianRegression2.html#gibbs-sampler",
    "title": "Bayesian regression II",
    "section": "Gibbs sampler",
    "text": "Gibbs sampler\n\nLast time\nWe set up the model,\n\\[\n\\begin{aligned}\n\\mathbf{y} | X, \\beta, \\sigma^2 &\\sim MVN(X\\beta, \\sigma^2 I)\\\\\n\\beta &\\sim MVN(\\beta_0, \\Sigma_0)\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2/2)\n\\end{aligned}\n\\]\nand derived the full conditionals\n\\[\n\\begin{aligned}\n\\beta | \\mathbf{y}, X, \\sigma^2 &\\sim MVN(\\mathbf{m}, V),\\\\\n1/\\sigma^2 | \\mathbf{y}, X, \\beta & \\sim\n\\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta)]/2),\n\\end{aligned}\n\\]\nwhere\n\\[\n\\begin{aligned}\nV = Var[\\beta | \\mathbf{y}, X, \\sigma^2] &=\n(\\Sigma_0^{-1} + X^TX / \\sigma^2)^{-1},\\\\\n\\mathbf{m} = E[\\beta | \\mathbf{y}, X, \\sigma^2] &= (\\Sigma_0^{-1} + X^T X/ \\sigma^2)^{-1}(\\Sigma_0^{-1} \\beta_0 + X^T\\mathbf{y} / \\sigma^2).\n\\end{aligned}\n\\]\n\n\nDiffuse prior\nTo complete model specification, we must choose \\(\\beta_0\\), \\(\\Sigma_0\\), \\(\\sigma_0^2\\) and \\(\\nu_0\\).\nIf we know very little about the relationships between \\(X\\) and \\(\\mathbf{y}\\), we might wish to consider a “diffuse” prior that prescribes a large mass of uncertainty around each parameter.\n\nmath of priorpicture of prior\n\n\n\\[\n\\begin{aligned}\n\\beta & \\sim MVN(0, 1000 I)\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(1, 10)\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\nSampler pseudo-code\n\n\n\n\n\n\npseudo-code\n\n\n\n\npick a starting \\(\\sigma^{2(0)}\\), set \\(s = 0\\). Now for \\(s\\) in 1:S perform 1-3:\nupdate \\(\\beta\\):\n\n\ncompute \\(V\\) and \\(\\mathbf{m}\\)\nsample \\(\\beta^{(s+1)} \\sim MVN(\\mathbf{m}, V)\\)\n\n\nupdate \\(\\sigma^{2}\\):\n\n\ncompute \\(SSR(\\beta^{(s+1)})\\)\nsample \\(1/\\sigma^{2(s+1)} \\sim \\text{gamma}([\\nu_0 + n]/2, [\\nu_0 \\sigma_0^2 + SSR(\\beta^{s+1})]/2)\\)\n\n\nsave the states of \\(\\beta\\) and \\(\\sigma^2\\).\n\n\n\n\n\nCode\nThe Gibbs sampler for our penguin example:\n\n\nCode to reproduce penguins_subset\n# our example examines just a subset of the penguin data\npenguins_subset = penguins %>%\n  select(body_mass_g, flipper_length_mm, bill_length_mm) %>%\n  drop_na() %>%\n  mutate(body_mass_kg = body_mass_g / 1000) %>%\n  select(-body_mass_g)\n\nX = penguins_subset %>%\n  select(-body_mass_kg) %>%\n  mutate(one = rep(1, nrow(penguins_subset))) %>%\n  relocate(one) %>%\n  as.matrix() \n\ny = select(penguins_subset, \n           body_mass_kg) %>%\n  as.matrix()\n\n\n\nset.seed(360)\n# prior hyperparameters \np = 2 # number of covariates\nSigma0 = 1000 * diag(rep(1, p+1)) # p + 1 for intercept term\nb0 = rep(0, p + 1)\nnu0 = 2\nsigma02 = 10\nn = nrow(y)\n\n# starting values\n## note: gamma = 1 / sigma^2\ngamma = 1 / var(penguins_subset$body_mass_kg)\n\n# values we should compute just once\nSigmaInv = solve(Sigma0)\nX2 = t(X) %*% X\nXy = t(X) %*% y\nSIB0 = SigmaInv %*% b0\na = (nu0 + n) / 2\nnu0s02 = nu0 * sigma02\n\n## empty objects to fill\nBETA = NULL\nGAMMA = NULL\n\nS = 2000\nfor (s in 1:S) {\n  ### UPDATE BETA\n  V = solve(SigmaInv + (gamma * X2))\n  m = V %*% (Xy * gamma) # simplified since b0 = 0\n  beta = rmvnorm(1, mean = m, sigma = V)\n  \n  ### UPDATE SIGMA\n  SSR1 = (y - (X %*% t(beta)))\n  SSRB = t(SSR1) %*% SSR1\n  gamma = rgamma(1, a, ((nu0s02 + SSRB) / 2))\n  \n  ### SAVE STATES\n  GAMMA = c(GAMMA, gamma)\n  BETA = rbind(BETA, beta)\n}\n\n\n\nESS?\neffectiveSize(BETA)\n\n\nvar1 var2 var3 \n2000 2000 2000 \n\n\nESS?\neffectiveSize(GAMMA)\n\n\nvar1 \n2000 \n\n\nHow do posterior mean estimates compare to the OLS estimates?\n\nposteriorMean = apply(BETA, 2, mean)\nOLS = lm(body_mass_kg ~ flipper_length_mm + bill_length_mm, data = penguins_subset) \nOLS = OLS$coefficients\nrbind(OLS, posteriorMean)\n\n              (Intercept) flipper_length_mm bill_length_mm\nOLS             -5.736897        0.04814486    0.006047488\nposteriorMean   -5.723741        0.04801443    0.006336029\n\n\nWe might have figured out this is what we were going to see already based on the the fact that the expressions for \\(E[\\beta | \\mathbf{y}, X]\\) and \\(Var[\\beta | \\mathbf{y}, X]\\) look just like \\(E[\\hat{\\beta}_{OLS} | \\beta]\\) and \\(Var[\\hat{\\beta}_{OLS} | \\beta]\\) when the prior information is diffuse.\nWhat was the point of all that extra work? Well, we don’t just have a point estimate and a confidence interval, we have a whole posterior! We can quantify uncertainty about \\(\\beta\\) in an easy and intuitive way.\nUsing the posterior, we may find 95% posterior CI, compute \\(p(\\beta_i > 0 | \\mathbf{y}, X)\\), compute \\(p(\\beta_i > \\beta_j | \\mathbf{y}, X)\\), compute the posterior median, and a whole host of additional queries quickly and intuitively.\nLet’s take a look at the marginal posteriors.\n\n\n\n\n\nExercise: is flipper length or bill length a “more important” predictor of penguin body mass? Why?\n\n\nVisually\nFor each iteration of our Gibbs sampler, we’re sampling a hyperplane, i.e. a set of \\(\\beta\\)s.\n\n\n\n\nExercise: discuss how autocorrelation of \\(\\beta\\)s would affect our sampler based on the animation above."
  },
  {
    "objectID": "notes/lec14-BayesianRegression2.html#subtelty-of-prior-parameters",
    "href": "notes/lec14-BayesianRegression2.html#subtelty-of-prior-parameters",
    "title": "Bayesian regression II",
    "section": "Subtelty of prior parameters",
    "text": "Subtelty of prior parameters"
  },
  {
    "objectID": "notes/lec14-BayesianRegression2.html#ridge-regression-and-the-normal-prior",
    "href": "notes/lec14-BayesianRegression2.html#ridge-regression-and-the-normal-prior",
    "title": "Bayesian regression II",
    "section": "Ridge regression and the normal prior",
    "text": "Ridge regression and the normal prior\nWhat if \\(p > n\\)? In words: what if we have more predictors than observations? \\(X\\) will be wide and therefore have linearly dependent columns.\nIn this case, \\(X^T X\\) is \\(p \\times p\\) but is of rank \\(n < p\\), i.e. \\(X^TX\\) is not full rank and thus not invertible. Therefore, \\(\\hat{\\beta}_{OLS}\\) satisfying \\((X^T X)\\hat{\\beta}_{OLS} = X^T \\mathbf{y}\\) does not exist uniquely.\nSeparately, in the case of multicollinearity, where the columns of \\(X\\) are highly correlated, some eigenvalues of \\(X^TX\\) will be very small, which means \\((X^TX)^{-1}\\) will have very large eigenvalues, i.e. \\(Var(\\hat{\\beta}_{OLS})\\) will be very large.\n\nIntuitively: we can fix this by shrinking some of the \\(\\beta_i\\) towards zero (reducing \\(p\\)).\nAlgebraically: one way we can fix this is by adding some positive quantity on the diagonals.\n\nFrequentists call this sort of algebraic fix “ridge regression” and define the problem thus:\n\\[\n\\hat{\\beta}_{ridge} = \\underset{\\beta}{\\mathrm{argmin}} \\underbrace{(\\mathbf{y} - X\\beta)^T (\\mathbf{y} - X \\beta)}_{\\text{SSR}(\\beta)} + \\underbrace{\\lambda \\beta^T \\beta}_{L_2^2 ~\\text{penalty}}\n\\]\nwhere \\(\\lambda\\) is a tuning parameter called the “ridge coefficient”.\nBayesians obtain the same objective via the following prior on \\(\\beta\\),\n\\[\n\\beta \\sim MVN(0, \\sigma^2 I /\\lambda)\n\\]\nExercise: show that \\(\\hat{\\beta}_{ridge} = E[\\beta | \\mathbf{y}, X, \\sigma^2] = ((X^TX) + \\lambda I)^{-1} X^T \\mathbf{y}\\)."
  },
  {
    "objectID": "notes/lec14-BayesianRegression2.html#g-prior",
    "href": "notes/lec14-BayesianRegression2.html#g-prior",
    "title": "Bayesian regression II",
    "section": "g-prior",
    "text": "g-prior"
  },
  {
    "objectID": "quizzes/quiz06.html",
    "href": "quizzes/quiz06.html",
    "title": "Quiz 6",
    "section": "",
    "text": "Exercise 1\n\\[\nY = X\\beta\n\\]\nWrite down \\(\\hat{\\beta}_{OLS}\\) as a function of \\(X\\) and \\(Y\\). Assume \\(X\\) is full rank.\n\n\nExercise 2\nTRUE or FALSE\n\\(\\hat{\\beta}_{OLS}\\) is biased.\n\n\nExercise 3\nTRUE or FALSE\n\\(y_i = \\beta_0 + \\beta_1 x_i^2\\) is a linear model.\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "hw/hw08.html",
    "href": "hw/hw08.html",
    "title": "Homework 8",
    "section": "",
    "text": "Weighted regression: Suppose \\(y_i \\sim N(\\beta x_i, \\sigma^2 / w_i)\\) independently for \\(i = 1,\\ldots n\\), where \\(x_1, \\ldots, x_n\\) and \\(w_1, \\ldots w_n\\) are known scalars, and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nFind the formula for the OLS estimator \\(\\hat{\\beta}_{OLS}\\) and compute its variance \\(V[\\hat{\\beta}_{OLS} | \\beta, \\sigma^2]\\).\nWrite out the sampling density \\(p(y_1, \\ldots, y_n | \\sigma^2, \\beta)\\) as a function of \\(\\beta\\) (i.e. the likelihood) and find the value of \\(\\beta\\) that maximizes this function (the MLE). Denote this maximizing value as \\(\\hat{\\beta}_{MLE}\\). Compute \\(V[\\hat{\\beta}_{MLE} | \\beta, \\sigma^2]\\) and compare it to that of \\(\\hat{\\beta}_{OLS}\\).\nUnder the prior distribution \\(\\beta \\sim N(0, \\tau^2)\\), find \\(E[\\beta | y_1, \\ldots, y_n, \\sigma^2]\\). What does this estimator get close to as the prior precision goes to zero (\\(\\tau^2 \\rightarrow \\infty\\))?"
  },
  {
    "objectID": "hw/hw08.html#exercise-2",
    "href": "hw/hw08.html#exercise-2",
    "title": "Homework 8",
    "section": "Exercise 2",
    "text": "Exercise 2\nRidge regression theory: Let \\(y \\sim N_n(X \\beta, \\sigma^2 I)\\). Consider estimating \\(\\beta\\) with the prior distribution \\(\\beta | \\sigma^2 \\sim N_p(0, \\sigma^2 I / \\lambda)\\), where \\(\\lambda\\) is known and \\(\\beta\\) and \\(\\sigma^2\\) are unknown.\n\nDerive the conditional distribution of \\(\\beta | y, \\sigma^2\\) and, in particular, show that \\(E[\\beta | y] = (X^TX + I \\lambda)^{-1} X^Ty\\). Denote this expectation \\(\\hat{\\beta}_\\lambda\\), which we can use as an estimator of \\(\\beta\\). What happens to \\(\\hat{\\beta}_\\lambda\\) as \\(\\lambda \\rightarrow 0\\)?\nConsider the special case that \\(X^TX\\) is a diagonal matrix with entries \\(x_1^T x_1, \\ldots, x_p^T x_p\\). Find the mathematical relationship between each element of \\(\\hat{\\beta}_{\\lambda}\\) and the corresponding element of the OLS estimator \\(\\hat{\\beta}_{OLS}\\). Explain in words the effect of \\(\\lambda\\)."
  },
  {
    "objectID": "hw/hw08.html#exercise-3",
    "href": "hw/hw08.html#exercise-3",
    "title": "Homework 8",
    "section": "Exercise 3",
    "text": "Exercise 3\nRidge regression application: The data set yX.diabetes.train contains data on diabetes progression (first column) and 64 predictor variables. These data can be loaded with with command\n\nyX<-dget(url(\"https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.diabetes.train\"))\n\n\nFor each value of \\(\\lambda \\in \\{0, 1, \\ldots, 99, 100 \\}\\) compute the estimator \\(\\hat{\\beta}_{\\lambda}\\) and plot this in some way (maybe using matplot).\nLoad the data set yX.diabetes.test using the code below\n\n\nyX.diabetes.test<-dget(\n  url(\"https://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.diabetes.test\"))\n\nUse yX.diabetes.test to evaluate the predictive performance of each estimate you obtained in part a. Specifically, compute the predictive error sum of squares \\(PSS(\\lambda) = ||y_{test} - X_{test} \\hat{\\beta}_{\\lambda}||^2\\) for each value of \\(\\lambda\\) (IMPORTANT: \\(\\hat{\\beta}_{\\lambda}\\) is obtained from the training data in part a, not the test data). Make a plot of PSS versus \\(\\lambda\\). How good is the unbiased OLS estimate for prediction, relative to the other estimates?\n\nIdentify the value of \\(\\lambda\\) that has the best predictive performance. For this best value of \\(\\lambda\\), report which x-variables have the largest effects."
  },
  {
    "objectID": "hw/hw08.html#exercise-4",
    "href": "hw/hw08.html#exercise-4",
    "title": "Homework 8",
    "section": "Exercise 4",
    "text": "Exercise 4\nFor this exercise, use the code below to load the data\n\nyX = readRDS(\n  url(\"http://www2.stat.duke.edu/~pdh10/Teaching/360/Materials/yXSS.rds\"))\n\nSource separation: The first column y of the dataset yXSS.rds is the vectorization of a spectroscopy image of a water sample taken from the Neuse River in North Carolina. You can view the image with the following code: y<-yX[,1] ; image(matrix(y,151,43)). The water sample is of unknown origin, but it is assumed that it is a mix of water from 9 different categories, whose average spectroscopy images are given by the remaining 9 columns \\(X\\) of yX. You can view these images with the same code above, applied to each column of \\(X\\).\n\nFrom \\(y\\) and \\(X\\), infer the sources of the water sample using the linear model \\(E[y|X, \\beta] = X\\beta\\). Assuming the normal linear model and with priors \\(\\beta \\sim N_9(1/9, \\ldots 1/9), I_9)\\), \\(1/\\sigma^2 \\sim \\text{gamma}(1, 1)\\), use a Gibbs sampler to obtain a posterior distribution of \\(\\beta\\) and \\(\\sigma^2\\) given \\(y\\). Plot the posterior density of \\(\\sigma^2\\), and obtain posterior 95% confidence intervals for each element of \\(\\beta\\). Which of the nine categories are the main sources of the water sample?\nEvaluate the assumptions of the normal linear model using some residual plots, addressing the assumption that the entries of \\(y\\) have constant variance, are uncorrelated, and are normally distributed.\nFor this problem it doesn’t make sense for the coefficients of \\(\\beta\\) to be negative. Think of a modification to the prior distribution for \\(\\beta\\) that takes this fact into account, and describe how a Gibbs sampler could be constructed to sample from the corresponding posterior distribution."
  },
  {
    "objectID": "hw/hw09.html",
    "href": "hw/hw09.html",
    "title": "Homework 9",
    "section": "",
    "text": "To load the data for this exercise, run the code below.\n\n\n\n\nyX = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-train.csv\")\nyX.test = readr::read_csv(\"https://sta360-fa23.github.io/data/azdiabetes-test.csv\")\n\nThe file azdiabetes-train.csv contains data on health-related variables of a population of 432 women. In this exercise we will be modeling the conditional distribution of glucose level (glu) as a linear combination of the other variables, excluding the variable diabetes.\n\nFit a regression model using the g-prior with \\(g = n\\), \\(\\nu_0 = 2\\) and \\(\\sigma_0^2 = 1\\). Obtain 95% posterior confidence intervals for all of the parameters. Note: you do not need a Gibbs sampler for this problem, see p 159 of Hoff.\nFit a MVN linear model using rstanarm with priors \\(\\beta_i \\sim N(0, 1)\\) and a flat prior on \\(\\sigma\\). Report the posterior mean and 95% confidence intervals for all parameters.\nPerform the model selection and averaging procedure described in section 9.3. See secton 9.3.1 for the model and pg 168 for sample code to sample \\(\\mathbf{z}\\). Obtain \\(Pr(\\beta_j \\neq 0 | y)\\), as well as posterior confidence intervals for all of the parameters. Compare to the results in part (a) and (b). Additionally, compare the average squared error of predictions using the data set azdiabetes-test.csv under all three fitted models."
  },
  {
    "objectID": "hw/hw09.html#exercise-2",
    "href": "hw/hw09.html#exercise-2",
    "title": "Homework 9",
    "section": "Exercise 2",
    "text": "Exercise 2\nExercise 10.2 from Hoff.\nTo load the data for this exercise, run the code below,\n\nyXsparrow = readr::read_csv(\"https://sta360-fa23.github.io/data/yXsparrow.csv\")\n\nInstead of 1000, please run your chain until you reach at least 100 effective sample size."
  },
  {
    "objectID": "hw/hw09.html#exercise-3",
    "href": "hw/hw09.html#exercise-3",
    "title": "Homework 9",
    "section": "Exercise 3",
    "text": "Exercise 3\nCode for this exercise is provided below,\n\n# load the data\ntrans.prob.mat = readRDS(url(\"https://sta360-fa23.github.io/data/trans-prob-mat.rds\"))\ncipher_text = readLines(\"https://sta360-fa23.github.io/data/ciphertext.txt\")\n\npl = function(decoded) {\n  logprob = 0\n  prevletter = \"SPACE\"\n  for (i in 1:nchar(decoded)) {\n    curletter = substring(decoded, i, i)\n    if(curletter == \" \") {\n      curletter = \"SPACE\"\n    }\n    logprob = logprob + log(trans.prob.mat[rownames(trans.prob.mat) == prevletter,\n                                             colnames(trans.prob.mat) == curletter])\n    prevletter = curletter\n  }\n  return(logprob)\n} \n\nIn this exercise we will re-create the cryptanalysis tool described here to decrypt a secret message. Read pages 1-3 of the article by Persi Diaconis linked above.\n\nLoad the object trans.prob.matrix using the code above and examine. Based on your reading of the article, how can you interpret the entries of this matrix? Is it symmetric or not? Why does this make sense? The function pl(), given above, computes the “plausibility” score for a given decoding. Explain in detail what the code comprising pl() does.\nFollow the pseudo-code outlined on page 2 of the article to write a MCMC algorithm and decrypt the secret message. Run your Markov chain for at least 1000 iterations and report the decoding with the highest plausibility score."
  },
  {
    "objectID": "chapterSummaries.html#chapter-5",
    "href": "chapterSummaries.html#chapter-5",
    "title": "Chapter summaries",
    "section": "Chapter 5",
    "text": "Chapter 5\n\nConjugate prior to the normal model\nIf\n\\[\n\\begin{aligned}\nY_i | \\theta, \\sigma^2 &\\sim N(\\theta, \\sigma^2)\\\\\n\\theta | \\sigma^2 & \\sim N(\\mu_0, \\sigma^2/\\kappa_0)\\\\\n\\frac{1}{\\sigma^2} &\\sim \\text{gamma}(\\frac{\\nu_0}{2}, \\frac{\\nu_0}{2} \\sigma_0^2)\n\\end{aligned}\n\\]\nthen\n\\[\n\\begin{aligned}\n\\theta | \\sigma^2, y_1,\\ldots y_n &\\sim \\text{normal}\\\\\n\\sigma^2 | y_1,\\ldots y_n &\\sim \\text{gamma}\n\\end{aligned}\n\\]\nand since\n\\[\n\\begin{aligned}\np(\\theta, \\sigma^2 | y_1, \\ldots y_n) &= p(\\theta |\\sigma^2, y_1,\\ldots y_n) p(\\sigma^2 | y_1,\\ldots y_n),\n\\end{aligned}\n\\]\nwe can sample directly from the joint posterior by sampling from \\(p(\\sigma^2 | y_1,\\ldots y_n)\\) and then from \\(p(\\theta | \\sigma^2, y_1,\\ldots y_n)\\).\n\n\nEstimators\nBe able to define and compute the bias, variance and MSE of an estimator.\n\n\n\n\n\n\nDefinition\n\n\n\nBias is the the difference between the expected value of the estimator and the true value of the parameter.\n\n\\(E[\\hat{\\theta} | \\theta = \\theta_ 0] - \\theta_0\\) is the bias of \\(\\hat{\\theta}\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] = \\theta_0\\), then we say \\(\\hat{\\theta}\\) is an unbiased estimator of \\(\\theta\\).\nIf \\(E[\\hat{\\theta} | \\theta = \\theta_0] \\neq \\theta_0\\), then we say \\(\\hat{\\theta}\\) is a biased estimator of \\(\\theta\\).\n\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nRecall: variance is average squared distance from the mean. In this context, the variance of an estimator refers to the variance of the sampling distribution of \\(\\hat{\\theta}\\). We write this mathematically,\n\\[\nVar[\\hat{\\theta} | \\theta_0] = E[(\\hat{\\theta} - m)^2 |\\theta_0]\n\\]\nwhere \\(m = E[\\hat{\\theta}|\\theta_0]\\).\n\n\n\n\n\n\n\n\nDefinition\n\n\n\nMean squared error (MSE) is (as the name suggests) the expected value of the squared difference between the estimator and true parameter value. Equivalently, MSE is the variance plus the square bias of the estimator.\n\\[\n\\begin{aligned}\nMSE[\\hat{\\theta}|\\theta_0] &= E[(\\hat{\\theta} - \\theta_0)^2 | \\theta_0]\\\\\n&= Var[\\hat{\\theta} | \\theta_0] + Bias^2[\\hat{\\theta}|\\theta_0]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "chapterSummaries.html#chapter-6",
    "href": "chapterSummaries.html#chapter-6",
    "title": "Chapter summaries",
    "section": "Chapter 6",
    "text": "Chapter 6\n\nGibbs sampling procedure\nHow can we look at a joint posterior, e.g. \\(p(\\theta_1,\\ldots \\theta_p | y_1,\\ldots y_n)\\), if we have non-conjugate priors?\nWell if we do have the full conditionals, \\(p(\\theta_i | \\theta_{-i}, y_1,\\ldots y_n)\\) then we can sample from the joint posterior via Gibbs sampling. Note: \\(\\theta_{-i}\\) denotes \\(\\{\\theta\\} \\backslash \\theta_i\\), i.e. the set of all theta except \\(\\theta_i\\).\nGibbs sampling proceeds:\nPick a starting point \\(\\theta_2^{(0)}, \\ldots \\theta_p^{(0)}\\), then for s in 1:S,\n\nSample \\(\\theta_1^{(s)} \\sim p(\\theta_1 | \\theta_{2}^{(s-1)}, \\ldots, \\theta_{p}^{(s-1)}, y_1,\\ldots y_n)\\)\nSample \\(\\theta_2^{(s)} \\sim p(\\theta_2 | \\theta_{1}^{(s)}, \\theta_{3}^{(s-1)} \\ldots, \\theta_{p}^{(s-1)}, y_1,\\ldots y_n)\\)\n\n\\(\\vdots\\)\n\nSample \\(\\theta_p^{(s)} \\sim p(\\theta_2 | \\theta_{1}^{(s)}, \\ldots, \\theta_{p-1}^{(s)}, y_1,\\ldots y_n)\\)\n\nIt follows that we have a sequence of dependent samples from the joint posterior. The sequence \\(\\{\\theta^{(s)}\\}\\) is called a Markov chain.\n\\[\n\\frac{1}{S} \\sum_{s=1}^S g(\\theta^{(s)})  \\rightarrow E[g(\\theta)]\n\\]\nGibbs sampling is a form of Markov chain Monte Carlo (MCMC).\n\n\nMCMC diagnostics\nEffective sample size (ESS), autocorrelation, and traceplots are diagnostic tools we use to assess how well our Markov chain approximates the posterior. You should be able to define these terms and interpret their output. See this lecture for details.\nSpecifically, ESS is the number of independent Monte Carlo samples necessary to give the same precision as the MCMC samples. Typically, ESS is a criterion used to figure out how many samples to generate, i.e. how long to run your Markov chain."
  },
  {
    "objectID": "chapterSummaries.html#chapter-7",
    "href": "chapterSummaries.html#chapter-7",
    "title": "Chapter summaries",
    "section": "Chapter 7",
    "text": "Chapter 7\n\nDensity\nWe say a \\(p\\) dimensional vector \\(\\boldsymbol{Y}\\) has a multivariate normal distribution if its sampling density is given by\n\\[\np(\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma) = (2\\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp\\{\n-\\frac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\theta})^T \\Sigma^{-1} (\\boldsymbol{y}- \\boldsymbol{\\theta})\n\\}\n\\]\nwhere\n\\[\n\\boldsymbol{y}=  \\left[ {\\begin{array}{cc}\n   y_1 \\\\\n   y_2\\\\\n   \\vdots\\\\\n   y_p\n  \\end{array} } \\right]\n  ~~~\n   \\boldsymbol{\\theta}= \\left[ {\\begin{array}{cc}\n   \\theta_1 \\\\\n   \\theta_2\\\\\n   \\vdots\\\\\n   \\theta_p\n  \\end{array} } \\right]\n  ~~~\n  \\Sigma =\n  \\left[ {\\begin{array}{cc}\n   \\sigma_1^2 & \\sigma_{12}& \\ldots & \\sigma_{1p}\\\\\n   \\sigma_{12} & \\sigma_2^2 &\\ldots & \\sigma_{2p}\\\\\n   \\vdots & \\vdots & & \\vdots\\\\\n   \\sigma_{1p} & \\ldots & \\ldots & \\sigma_p^2\n  \\end{array} } \\right].\n\\]\n\nKey facts\n\n\\(\\boldsymbol{y}\\in \\mathbb{R}^p\\) ; \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^p\\); \\(\\Sigma > 0\\)\n\\(E[\\boldsymbol{y}] = \\boldsymbol{\\theta}\\)\n\\(V[\\boldsymbol{y}] = E[(\\boldsymbol{y}- \\boldsymbol{\\theta})(\\boldsymbol{y}- \\boldsymbol{\\theta})^T] = \\Sigma\\)\nMarginally, \\(y_i \\sim N(\\theta_i, \\sigma_i^2)\\).\nIf \\(\\boldsymbol{\\theta}\\) is a MVN random vector, then the kernel is \\(\\exp\\{-\\frac{1}{2} \\boldsymbol{\\theta}^T A \\boldsymbol{\\theta}+ \\boldsymbol{\\theta}^T \\boldsymbol{b} \\}\\). The mean is \\(A^{-1}\\boldsymbol{b}\\) and the covariance is \\(A^{-1}\\).\n\n\n\n\nsemi-conjugate prior for \\(\\boldsymbol{\\theta}\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\boldsymbol{\\theta}&\\sim MVN(\\mu_0, \\Lambda_0),\n\\end{aligned}\n\\]\nthen\n\\[\n\\boldsymbol{\\theta}| \\boldsymbol{y}, \\Sigma \\sim MVN\n\\]\n\n\nsemiconjugate prior for \\(\\Sigma\\)\nIf\n\\[\n\\begin{aligned}\n\\boldsymbol{y}| \\boldsymbol{\\theta}, \\Sigma &\\sim MVN(\\boldsymbol{\\theta}, \\Sigma),\\\\\n\\Sigma &\\sim \\text{inverse-Wishart}(\\nu_0, S_0^{-1}),\n\\end{aligned}\n\\]\nthen\n\\[\n\\Sigma | \\boldsymbol{y}, \\boldsymbol{\\theta}\\sim \\text{inverse-Wishart}\n\\]\n\n\nWishart as sum of squares matrix\nFor a given \\(\\nu_0\\) and and a \\(p \\times p\\) covariance matrix \\(S_0\\), we can generate samples from a MVN by the following procedure:\n\nsample \\(\\boldsymbol{z}_1, \\ldots \\boldsymbol{z}_{\\nu_0} \\sim \\text{ i.i.d. } MVN(\\mathbf{0}, S_0)\\)\ncalculate \\(\\mathbf{Z}^T \\mathbf{Z} = \\sum_{i =1}^{\\nu_0} \\boldsymbol{z}_i \\boldsymbol{z}_i^T\\).\n\nIt follows that \\(\\mathbf{Z}^T \\mathbf{Z} > 0\\) and symmetric. \\(E[\\mathbf{Z}^T \\mathbf{Z}] = \\nu_0 S_0\\)"
  },
  {
    "objectID": "chapterSummaries.html#chapter-8",
    "href": "chapterSummaries.html#chapter-8",
    "title": "Chapter summaries",
    "section": "Chapter 8",
    "text": "Chapter 8\nBe able to write a hierarchical model. Review and be able to explain all aspects of the example here."
  },
  {
    "objectID": "slides/lab7-exam2-prep.html#exercise-1",
    "href": "slides/lab7-exam2-prep.html#exercise-1",
    "title": "Practice",
    "section": "Exercise 1",
    "text": "Exercise 1\n\\[\n\\begin{aligned}\nY_1, \\ldots, Y_n &\\sim \\text{ i.i.d. binary}(\\theta)\\\\\n\\theta &\\sim \\text{beta}(a, b)\n\\end{aligned}\n\\]\n\nCompute \\(\\hat{\\theta}_{MLE}\\)\nCompute \\(\\hat{\\theta}_{B} = E[\\theta | y_1,\\ldots y_n]\\).\nCompare \\(MSE(\\hat{\\theta}_{MLE})\\) to \\(MSE(\\hat{\\theta}_{B})\\)). Under what conditions is the MSE of \\(\\hat{\\theta}_B\\) smaller?"
  },
  {
    "objectID": "slides/lab7-exam2-prep.html#exercise-2",
    "href": "slides/lab7-exam2-prep.html#exercise-2",
    "title": "Practice",
    "section": "Exercise 2",
    "text": "Exercise 2\nConsider a single observation \\((y_1, y_2)\\) drawn from a bivariate normal distribution with mean \\((\\theta_1, \\theta_2)\\) and fixed, known \\(2 \\times 2\\) covariance matrix \\(\\Sigma = \\left[ {\\begin{array}{cc}  1 & .5 \\\\  .5 & 1  \\end{array} } \\right]\\). Consider a uniform prior on \\(\\theta = (\\theta_1, \\theta_2)\\) : \\(p(\\theta_1, \\theta_2) \\propto 1\\).\n(a.) Derive the joint posterior for \\(\\theta_1, \\theta_2 | y_1, y_2, \\Sigma\\). Describe a direct sampler for this distribution.\n(b.) Write down full conditionals \\(p(\\theta_1 | \\theta_2, y_1, y_2, \\Sigma)\\) and \\(p(\\theta_2 | \\theta_1, y_1, y_2, \\Sigma)\\). Write pseudo-code to describe a Gibbs sampling procedure. Hint: you can use the result from HW6 Ex 3.\n(c.) Will the direct sampler from part (a) or the Gibbs sampler in part (b) have higher ESS? Why?\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/additionalRegressionNotes.html",
    "href": "notes/additionalRegressionNotes.html",
    "title": "Additional regression notes",
    "section": "",
    "text": "Setup:\n\\[\ny_i = z_1 \\beta_1 x_{i, 1} + \\cdots + z_p \\beta_p x_{i, p} + \\epsilon_i\n\\]\n\n\\(y_i \\in \\mathbb{R}\\)\n\\(\\beta_i \\in \\mathbb{R}\\)\n\\(z_i \\in \\{0, 1\\}\\)\n\nThe \\(z_j\\)’s indicate which regression coefficients are non-zero.\n\n\n\n\n\n\nNote\n\n\n\nNotice that every set of values \\(\\mathbf{z} = \\{z_1, \\ldots z_p \\}\\) corresponds to a different model. So a prior \\(p(z)\\) may be thought of as a prior distribution over models.\n\n\nBayesian model selection proceeds by obtaining a posterior distribution for \\(\\mathbf{z}\\):\n\\[\np(\\mathbf{z}| \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})}{\\sum_\\mathbf{\\tilde{z}} p(\\mathbf{\\tilde{z}}) p(\\mathbf{y}| \\mathbf{X}, \\mathbf{\\tilde{z}})}\n\\]\nAlternatively, we may prefer to compare any two models with the posterior odds:\n\\[\n\\text{odds}(\\mathbf{z}_a, \\mathbf{z}_b | \\mathbf{y}, \\mathbf{X}) = \\frac{p(\\mathbf{z}_a | \\mathbf{y}, \\mathbf{X})}{p(\\mathbf{z}_b | \\mathbf{y}, \\mathbf{X})} = \\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)} \\times \\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\n\\]\nNotice that when examining the odds of one model vs another, we avoid computing the denominator of \\(p(\\mathbf{z}| \\mathbf{y}, \\mathbf{X})\\), and thereby exhaustively computing the probability of every model.\n\n\n\n\n\n\nDefinitions\n\n\n\n\n\\(\\frac{p(\\mathbf{z}_a)}{p(\\mathbf{z}_b)}\\) is called the “prior odds”.\n\\(\\frac{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_a)}{p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z}_b)}\\) is called the “Bayes factor” i.e. how much the data favor model \\(\\mathbf{z}_a\\) over model \\(\\mathbf{z}_b\\).\n\n\n\nThis formulation above elicits a need to compute \\(p(\\mathbf{y}| \\mathbf{X}, \\mathbf{z})\\). To compute this in closed form, we will choose a few special priors (given a MVN data generative process).\n\\[\n\\begin{aligned}\n\\mathbf{y}| \\mathbf{X}, \\mathbf{z}, \\sigma^2 &\\sim MVN(X \\text{diag}(\\mathbf{z})\\beta, \\sigma^2 I)\\\\\n\\beta_z | \\mathbf{X}_z, \\sigma^2 &\\sim MVN(\\boldsymbol{0}, g\\sigma^2 [\\mathbf{X}_z^T \\mathbf{X}_z]^{-1})\\\\\n1/\\sigma^2 &\\sim \\text{gamma}(\\nu_0/2, \\nu_0 \\sigma_0^2 /2)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "notes/extra-regression-readings.html",
    "href": "notes/extra-regression-readings.html",
    "title": "Optional readings on linear regression",
    "section": "",
    "text": "For going beyond the ridge regression discussed in class, see this discussion of the Bayesian Lasso by Park and Casella (2008) that places Bayesian ridge within the broader class of exponential power priors.\nFor additional discussion of rstanarm, see continuous data in rstanarm. This is an introductory tutorial to using stan within the rstanarm package.\nFox-Ch12 - some pages from Ch12 of John Fox’s Applied Regression Analysis and GLMs (a favorite book of mine) on assessing the standard assumptions of linear regression, and specifically how residual plots help. This is very relevant to Ex4 of HW8, but again, the bare minimum you need for this exercise is a residual plot and a QQ plot + discussion."
  },
  {
    "objectID": "slides/lab8-rstan.html#download",
    "href": "slides/lab8-rstan.html#download",
    "title": "Easy Bayesian linear modeling",
    "section": "Download",
    "text": "Download\nTo download rstanarm and bayesplot run the code below\n\ninstall.packages(\"rstanarm\", \"bayesplot\")\n\nTo load the package, run\n\nlibrary(rstanarm)\nlibrary(bayesplot)"
  },
  {
    "objectID": "slides/lab8-rstan.html#overview",
    "href": "slides/lab8-rstan.html#overview",
    "title": "Easy Bayesian linear modeling",
    "section": "Overview",
    "text": "Overview\n\nrstanarm contains a host of functions to make Bayesian linear modeling in R easy. See https://mc-stan.org/rstanarm/articles/ for a variety of tutorials.\n\npros: fast and easy to test Bayesian linear models\ncons: limited in scope, e.g. requires differentiable objective and small model adjustments can be cumbersome to implement, e.g. placing a prior on variance versus standard deviation of normal model.\n\nbayesplot contains many useful plotting wrappers that work out of the box with objects created by rstanarm in an intuitive way."
  },
  {
    "objectID": "slides/lab8-rstan.html#basics-fitting-a-normal-linear-model",
    "href": "slides/lab8-rstan.html#basics-fitting-a-normal-linear-model",
    "title": "Easy Bayesian linear modeling",
    "section": "Basics: fitting a normal linear model",
    "text": "Basics: fitting a normal linear model\nLet’s consider the model below:\n\\[\ny_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_p x_p + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim \\text{ i.i.d.} N(0, \\sigma^2)\\). We complete model specification with the priors:\n\\[\n\\begin{aligned}\n\\beta_0 &\\sim N(0, 100)\\\\\n\\beta_i &\\sim \\text{ i.i.d } N(0, 1) \\text{ for all } i > 0\n\\end{aligned}\n\\]\nLet’s look at building this model using the stan_glm function of rstanarm.\n\n\n\n\n\n\nNote\n\n\nWe’ll always want to access the object we create, so you should save the result, e.g. model1 below.\n\n\n\n\n# save the result as \"model1\"\nmodel1 = stan_glm(mercury ~ ., data = bass, # remove the intercept\n                 family = gaussian(link = \"identity\"),\n                 seed = 360, # sets a random starting seed\n                 prior_intercept = normal(0, 100), # sets the intercept prior\n                 prior = normal(0, 1), # sets the beta prior\n                 prior_aux = NULL) # set a flat prior on sigma"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise",
    "href": "slides/lab8-rstan.html#exercise",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise",
    "text": "Exercise\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-1",
    "href": "slides/lab8-rstan.html#exercise-1",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise",
    "text": "Exercise\nLet \\(Y_1,\\ldots Y_n\\) be iid random variables with expectation \\(\\theta\\) and variance \\(\\sigma^2\\).\nShow that \\(\\frac{1}{n} \\sum_{i = 1}^n (Y_i -\\bar{Y})^2\\) is a biased estimator of \\(\\sigma^2\\).\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab8-rstan.html#example",
    "href": "slides/lab8-rstan.html#example",
    "title": "Easy Bayesian linear modeling",
    "section": "Example",
    "text": "Example\n\ncodeoutput\n\n\n\nlibrary(tidyverse)\nbass = read_csv(\n     \"https://sta101-fa22.netlify.app/static/appex/data/bass.csv\")\nglimpse(bass)\n\n\n\n\n\nRows: 171\nColumns: 5\n$ river   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ station <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ length  <dbl> 47.0, 48.7, 55.7, 45.2, 44.7, 43.8, 38.5, 45.8, 44.0, 40.4, 47…\n$ weight  <dbl> 1616, 1862, 2855, 1199, 1320, 1225, 870, 1455, 1220, 1033, 337…\n$ mercury <dbl> 1.60, 1.50, 1.70, 0.73, 0.56, 0.51, 0.48, 0.95, 1.40, 0.50, 0.…\n\n\n\n\n\nDescription\nMercury, is a naturally occurring element that can have toxic effects on the nervous, digestive and immune systems of humans. In local rivers microbes transform mercury into the highly toxic methyl mercury. Fish accumulate methyl mercury (since they are unable to excrete it) in their tissue over the course of their life.\nBass from the Waccamaw and Lumber Rivers were caught randomly, weighed, and measured. In addition, a filet from each fish caught was sent to the lab so that the tissue concentration of mercury could be determined for each fish. Each fish caught corresponds to a single row of the data frame. A code book is provided below.\n\nriver: 0=Lumber, 1=Waccamaw\nstation that the fish was collected at\nlength of the fish in centimeters\nweight of the fish in grams\nmercury: concentration of mercury in parts per million (ppm)\n\nThe data come from Craig Stowe, Nicholas School of the Environment circa 1990s"
  },
  {
    "objectID": "slides/lab8-rstan.html#fitting-a-normal-linear-model",
    "href": "slides/lab8-rstan.html#fitting-a-normal-linear-model",
    "title": "Easy Bayesian linear modeling",
    "section": "Fitting a normal linear model",
    "text": "Fitting a normal linear model\nLet’s consider the model below:\n\\[\ny_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_p x_p + \\epsilon_i\n\\]\nwhere \\(\\epsilon_i \\sim \\text{ i.i.d.} N(0, \\sigma^2)\\). We complete model specification with the priors:\n\\[\n\\begin{aligned}\n\\beta_0 &\\sim N(0, 100)\\\\\n\\beta_i &\\sim \\text{ i.i.d } N(0, 1) \\text{ for all } i > 0\\\\\n\\sigma &\\sim \\text{uniform}(0, \\infty)\n\\end{aligned}\n\\]\nLet’s look at building this model using the stan_glm function of rstanarm.\n\n\n\n\n\n\nNote\n\n\nWe’ll always want to access the object we create, so you should save the result, e.g. model1 below.\n\n\n\n\n# save the result as \"model1\"\nmodel1 = stan_glm(mercury ~ ., data = bass, # remove the intercept\n                 family = gaussian(link = \"identity\"),\n                 seed = 360, # sets a random starting seed\n                 prior_intercept = normal(0, 100), # sets the intercept prior\n                 prior = normal(0, 1), # sets the beta prior\n                 prior_aux = NULL, # set a flat prior on sigma\n                 )"
  },
  {
    "objectID": "slides/lab8-rstan.html#examining-the-output",
    "href": "slides/lab8-rstan.html#examining-the-output",
    "title": "Easy Bayesian linear modeling",
    "section": "Examining the output",
    "text": "Examining the output\n\nDid stan_glm do what we think it did? Did the Markov chain converge?\n\n\nquick lookcheck priorstrace plotsmarginal posteriorsplotting tipsresidual plotget chainsummarize\n\n\n\nsummary(model1)\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      mercury ~ .\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 171\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -1.4    0.3 -1.9  -1.4  -1.0 \nriver       -0.5    0.2 -0.8  -0.5  -0.3 \nstation      0.1    0.0  0.1   0.1   0.1 \nlength       0.1    0.0  0.0   0.1   0.1 \nweight       0.0    0.0  0.0   0.0   0.0 \nsigma        0.6    0.0  0.5   0.6   0.6 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 1.2    0.1  1.1   1.2   1.3  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  2864 \nriver         0.0  1.0  1857 \nstation       0.0  1.0  1828 \nlength        0.0  1.0  2814 \nweight        0.0  1.0  2861 \nsigma         0.0  1.0  2819 \nmean_PPD      0.0  1.0  3069 \nlog-posterior 0.0  1.0  1616 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\n\n\n\n\nprior_summary(model1)\n\nPriors for model 'model1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 0, scale = 100)\n\nCoefficients\n ~ normal(location = [0,0,0,...], scale = [1,1,1,...])\n\nAuxiliary (sigma)\n ~ flat\n------\nSee help('prior_summary.stanreg') for more details\n\n\n\n\n\nmcmc_trace(model1)\n\n\n\n\n\n\n\nmcmc_hist(model1)\n\n\n\n\n\n\nTo plot specific parameters, use the arguemnt pars, e.g.\n\nmcmc_trace(model1, pars = c(\"river\", \"station\")\nmcmc_hist(model1, pars = \"length\")\n\nTo read more about bayesplot functionality, see https://mc-stan.org/bayesplot/articles/plotting-mcmc-draws.html\n\n\n\ndf = data.frame(yhat = model1$fitted.values,\n                residual = model1$residuals)\n\ndf %>%\n  ggplot(aes(x = yhat, y = residual)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\nchain_draws = as_draws(model1)\nprint(names(chain_draws))\n\n[1] \"(Intercept)\" \"river\"       \"station\"     \"length\"      \"weight\"     \n[6] \"sigma\"       \".chain\"      \".iteration\"  \".draw\"      \n\nchain_draws$river[1:5] # first 5 samples of the first chain run by stan\n\n[1] -0.3748586 -0.2472218 -0.8788921 -0.4870408 -0.6565987\n\n\n\ntry the following command: View(chain_draws)\n\n\n\nReport posterior mean, posterior median and 90% posterior CI.\n\nposteriorMean = apply(chain_draws[,1:6], 2, mean)\nposteriorMedian = model1$coefficients\nposteriorCI = posterior_interval(model1, prob = 0.9)\ncbind(posteriorMean, posteriorMedian, posteriorCI)\n\n            posteriorMean posteriorMedian            5%           95%\n(Intercept) -1.4320242215    -1.435098280 -2.0129526891 -8.767706e-01\nriver       -0.5368486696    -0.538925449 -0.8441961657 -2.299097e-01\nstation      0.0777090920     0.078115486  0.0461303215  1.092244e-01\nlength       0.0622405968     0.062062419  0.0429862421  8.203404e-02\nweight      -0.0001059707    -0.000104737 -0.0002995203  8.105592e-05\nsigma        0.5568710635    -1.435098280  0.5088456218  6.111942e-01"
  },
  {
    "objectID": "slides/lab8-rstan.html#code",
    "href": "slides/lab8-rstan.html#code",
    "title": "Easy Bayesian linear modeling",
    "section": "code",
    "text": "code\n\nlibrary(tidyverse)\nbass = read_csv(\n     \"https://sta101-fa22.netlify.app/static/appex/data/bass.csv\")\nglimpse(bass)"
  },
  {
    "objectID": "slides/lab8-rstan.html#output",
    "href": "slides/lab8-rstan.html#output",
    "title": "Easy Bayesian linear modeling",
    "section": "output",
    "text": "output\n\n\nRows: 171\nColumns: 5\n$ river   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ station <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ length  <dbl> 47.0, 48.7, 55.7, 45.2, 44.7, 43.8, 38.5, 45.8, 44.0, 40.4, 47…\n$ weight  <dbl> 1616, 1862, 2855, 1199, 1320, 1225, 870, 1455, 1220, 1033, 337…\n$ mercury <dbl> 1.60, 1.50, 1.70, 0.73, 0.56, 0.51, 0.48, 0.95, 1.40, 0.50, 0.…\n\n\nMercury, is a naturally occurring element that can have toxic effects on the nervous, digestive and immune systems of humans (see WHO for more details). In local rivers (and other bodies of water), microbes transform mercury into the highly toxic methyl mercury. Fish accumulate methyl mercury (since they are unable to excrete it) in their tissue over the course of their life.\nBass from the Waccamaw and Lumber Rivers were caught randomly, weighed, and measured. In addition, a filet from each fish caught was sent to the lab so that the tissue concentration of mercury could be determined for each fish. Each fish caught corresponds to a single row of the data frame. A code book is provided below (copied from here).\n\nriver: 0=Lumber, 1=Waccamaw\nstation that the fish was collected at\nlength of the fish in centimeters\nweight of the fish in grams\nmercury: concentration of mercury in parts per million (ppm)\n\nThe data come from Craig Stowe, Nicholas School of the Environment circa 1990s"
  },
  {
    "objectID": "slides/lab8-rstan.html#quick-look",
    "href": "slides/lab8-rstan.html#quick-look",
    "title": "Easy Bayesian linear modeling",
    "section": "quick look",
    "text": "quick look\n\nsummary(model1)\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      mercury ~ .\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 171\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -1.4    0.3 -1.9  -1.4  -1.0 \nriver       -0.5    0.2 -0.8  -0.5  -0.3 \nstation      0.1    0.0  0.1   0.1   0.1 \nlength       0.1    0.0  0.0   0.1   0.1 \nweight       0.0    0.0  0.0   0.0   0.0 \nsigma        0.6    0.0  0.5   0.6   0.6 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 1.2    0.1  1.1   1.2   1.3  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  2864 \nriver         0.0  1.0  1857 \nstation       0.0  1.0  1828 \nlength        0.0  1.0  2814 \nweight        0.0  1.0  2861 \nsigma         0.0  1.0  2819 \nmean_PPD      0.0  1.0  3069 \nlog-posterior 0.0  1.0  1616 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1)."
  },
  {
    "objectID": "slides/lab8-rstan.html#check-priors",
    "href": "slides/lab8-rstan.html#check-priors",
    "title": "Easy Bayesian linear modeling",
    "section": "check priors",
    "text": "check priors\n\nprior_summary(model1)\n\nPriors for model 'model1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 0, scale = 100)\n\nCoefficients\n ~ normal(location = [0,0,0,...], scale = [1,1,1,...])\n\nAuxiliary (sigma)\n ~ flat\n------\nSee help('prior_summary.stanreg') for more details"
  },
  {
    "objectID": "slides/lab8-rstan.html#trace-plots",
    "href": "slides/lab8-rstan.html#trace-plots",
    "title": "Easy Bayesian linear modeling",
    "section": "trace plots",
    "text": "trace plots\n\nmcmc_trace(model1, pars = c(\"river\", \"station\", \"length\"))"
  },
  {
    "objectID": "slides/lab8-rstan.html#exercise-bayesian-logistic-regression",
    "href": "slides/lab8-rstan.html#exercise-bayesian-logistic-regression",
    "title": "Easy Bayesian linear modeling",
    "section": "Exercise: Bayesian logistic regression",
    "text": "Exercise: Bayesian logistic regression\nUsing the bass data set, see how well you can predict which river a bass came from, given only its length and mercury level. In other words,\n\\[\np(y_i = 1) = \\frac{1}{1 + \\exp [- (\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2)]}\n\\]\nUse the priors\n\\[\n\\beta_i \\sim N(0, 4) \\text{ for } i \\in (0, 1, 2)\n\\]\nA template for fitting logistic regression using rstanarm can be found at https://mc-stan.org/rstanarm/articles/binomial.html.\n\nDoes your chain converge?\nReport \\(E[\\beta_i | y]\\) and 80% posterior CI for each \\(\\beta\\), i.e. \\(i \\in (0, 1, 2)\\)\nIs length or mercury a more important predictor of which river the bass came from? Why?\n\n\n\n\n\n\n\n\n\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "hw/hw09.html#exercise-4",
    "href": "hw/hw09.html#exercise-4",
    "title": "Homework 9",
    "section": "Exercise 4",
    "text": "Exercise 4\nExercise 10.2 from Hoff."
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html",
    "href": "notes/lec15-MetropolisHastings.html",
    "title": "Metropolis-Hastings",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(patchwork)\nlibrary(tidymodels)\nlibrary(mvtnorm)\nlibrary(coda)\nlibrary(animation)"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#notation",
    "href": "notes/lec15-MetropolisHastings.html#notation",
    "title": "Metropolis-Hastings",
    "section": "Notation",
    "text": "Notation\n\n\\(\\theta\\) is some parameter of interest.\n\\(\\pi(\\theta)\\) represents the target distribution of the parameter.\n\nQuestion: what does the phrase “explore parameter space” mean?"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#metropolis-algorithm",
    "href": "notes/lec15-MetropolisHastings.html#metropolis-algorithm",
    "title": "Metropolis-Hastings",
    "section": "Metropolis algorithm",
    "text": "Metropolis algorithm\n\nSample \\(\\theta^* | \\theta^{(s)} \\sim J(\\theta | \\theta^{(s)})\\)\nCompute the acceptance ratio \\(r = \\frac{\\pi(\\theta^*)}{\\pi(\\theta^{(s)})}\\)\nLet\n\n\\[\n\\theta^{(s+1)} =\n\\begin{cases}\n\\theta^* \\text{ with probability } \\min(r, 1)\\\\\n\\theta^{(s)} \\text{ with probability } 1 - \\min(r, 1)\n\\end{cases}\n\\]\n\nExample 1\nLet \\(\\pi(\\theta) = \\text{dnorm}(\\theta, 10, 1)\\) and let \\(J(\\theta | \\theta^{(s)}) = \\text{normal}(\\theta^{(s)},\\delta^2)\\).\nWe have to choose \\(\\delta\\). How should we choose it? Let’s gain some intuition by trying out three different values of \\(\\delta\\).\n\nset.seed(360)\ntheta_s = 0 # starting point\nTHETA = NULL # empty object to save iterations in\nS = 10000 # number of iteations\ndelta = 1 # proposal variance\naccept = 0 # keep track of acceptance rate\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ### generate proposal and compute ratio r ###\n  theta_proposal = rnorm(1, mean = theta_s, sd = delta) \n  log.r = dnorm(theta_proposal, mean = 10, sd = 1, log = TRUE) - \n    dnorm(theta_s, mean = 10, sd = 1, log = TRUE)\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) < log.r)  {\n    theta_s = theta_proposal\n    accept = accept + 1 \n  }\n  THETA = c(THETA, theta_s)\n}\n\n\n\n\nLet’s look at a trace plot\n\ntrace plotcode\n\n\n\n\n\n\n\n\n\n\ndf = data.frame(theta = THETA)\ndf %>%\n  ggplot(aes(x = 1:nrow(df), y = theta)) + \n  geom_line() +\n  theme_bw() +\n  labs(x = \"iteration\", y = TeX(\"\\\\theta\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s look at how various \\(\\delta\\) let us sample the target:\n\n\\(\\delta = 1\\)\\(\\delta = 4\\)\\(\\delta = 0.1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\nThe fledglings of female song sparrows. To begin, let’s load the data.\n\n\nLoad the data\nyX = structure(c(3, 1, 1, 2, 0, 0, 6, 3, 4, 2, 1, 6, 2, 3, 3, 4, 7, \n2, 2, 1, 1, 3, 5, 5, 0, 2, 1, 2, 6, 6, 2, 2, 0, 2, 4, 1, 2, 5, \n1, 2, 1, 0, 0, 2, 4, 2, 2, 2, 2, 0, 3, 2, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, \n2, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, \n5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 6, 1, 1, 9, 9, 1, 1, 1, 1, 1, 1, \n1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 25, 16, 16, 16, 16, 16, \n16, 16, 16, 16, 16, 16, 16, 25, 16, 16, 16, 16, 25, 25, 25, 25, \n9, 9, 9, 9, 9, 9, 9, 36, 1, 1), .Dim = c(52L, 4L), .Dimnames = list(\n    NULL, c(\"fledged\", \"intercept\", \"age\", \"age2\")))\n\n\n\nyX %>%\n  head(n = 5)\n\n     fledged intercept age age2\n[1,]       3         1   3    9\n[2,]       1         1   3    9\n[3,]       1         1   1    1\n[4,]       2         1   1    1\n[5,]       0         1   1    1\n\ny = yX[,1]\nX = yX[,-1]\n\nThe model:\n\\[\n\\begin{aligned}\nY | X &\\sim \\text{Poisson}(\\exp[ \\beta^T \\boldsymbol{x}])\\\\\n\\beta &\\sim MVN(0, \\sqrt{10})\n\\end{aligned}\n\\]\nThe Metropolis algorithm with\n\\[\nJ(\\beta | \\beta^{(s)}) = MVN(\\beta^{(s)}, \\hat{\\sigma}^2(X^TX)^{-1})\n\\]\nwhere \\(\\hat{\\sigma}^2\\) is the sample variance of \\(\\{\\log(y_1 + 1/2), \\ldots, \\log(y_n + 1/2)\\}\\).\n\n\n\n\n\n\nNote\n\n\n\n\nThis variance is intuitively useful choice for \\(\\delta\\) since the posterior variance would be \\(\\sigma^2 (X^TX)^{-1}\\) in a normal regression problem.\nWe use \\(\\log(y + 1/2)\\) instead of \\(\\log y\\) because if \\(y=0\\), \\(\\log y\\) would be \\(-\\infty\\).\n\n\n\n\nset.seed(360)\nn = length(y)\np = ncol(X)\n\npmn.beta = rep(0, p) # prior mean beta\npsd.beta = rep(10, p) # prior sd beta\n\nvar.prop = var(log(y + 1/2)) * solve(t(X) %*% X) # proposal variance\n\nS = 10000\nbeta = rep(0, p); accepts = 0\nBETA = matrix(0, nrow = S, ncol = p)\nset.seed(1)\n\nfor (s in 1:S) {\n  # multivariate proposal of beta\n  beta.p = t(rmvnorm(1, beta, var.prop))\n  \n  # log ratio\n  lhr = sum(dpois(y, exp(X %*%beta.p), log = TRUE)) -\n    sum(dpois(y, exp(X %*% beta), log = TRUE)) + \n    sum(dnorm(beta.p, pmn.beta, psd.beta, log = TRUE)) -\n    sum(dnorm(beta, pmn.beta, psd.beta, log = TRUE)) \n  \n  if (log(runif(1)) < lhr) {\n    beta = beta.p ; accepts = accepts + 1\n  }\n  \n  BETA[s,] = beta\n}\n\nThe acceptance ratio is 0.428\nLet’s examine convergence.\n\ntrace plotsplot codeESSacf\n\n\n\n\n\n\n\n\n\n\nvalue = c(BETA[,1], BETA[,2], BETA[,3])\nn = length(value)\nbeta = c(rep(\"beta1\", n/3), rep(\"beta2\", n/3), rep(\"beta3\", n/3))\ndf = data.frame(value = value,\n                beta = beta) \n\ndf %>%\n  ggplot(aes(x = 1:nrow(df), y = value)) + \n  geom_line() + \n  facet_wrap(~ beta, scales = \"free_x\") +\n  theme_bw() +\n  labs(x = \"iteration\")\n\n\n\n\n# effective sample size\nBETA %>%\n  apply(2, effectiveSize)\n\n[1] 867.4750 825.6214 692.0495\n\n\n\n\n\npar(mfrow=c(1,3))\nacf(BETA[,1])\nacf(BETA[,2])\nacf(BETA[,3])"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#metropolis-hastings",
    "href": "notes/lec15-MetropolisHastings.html#metropolis-hastings",
    "title": "Metropolis-Hastings",
    "section": "Metropolis-Hastings",
    "text": "Metropolis-Hastings\nIf we have a vector of parameters \\(\\theta = \\theta_1, \\ldots \\theta_p\\) then we can choose a proposal \\(J(\\theta | \\theta^{(s)})\\) that updates all \\(\\theta\\) elements simultaneously (as seen above with \\(J(\\beta | \\beta^{(s)})\\).\nAlternatively, we could update blocks of \\(\\theta\\), e.g. propose an update for the first \\(j\\) elements of \\(\\theta\\), \\(J_1(\\theta_1,\\ldots \\theta_j | \\theta_1^{(s)}, \\ldots \\theta_j^{(s)})\\) and then an update for the \\(p-j\\) remaining elements, \\(J(\\theta_{j+1}, \\ldots, \\theta_{p} | \\theta_{j+1}^{(s)}, \\ldots, \\theta_{p}^{(s)})\\).\nSeparately, we could even update each element of \\(\\theta\\) individually, e.g. have an individual, different proposal on each \\(\\theta_i\\), \\(i \\in \\{1, \\ldots p\\}\\).\nWe might even combine block updates with individual updates.\nQuestion: Where have we seen block updates and individual updates within MCMC before?\nThe Metropolis-Hastings algorithm is a generalization of both the Metropolis algorithm and the Gibbs sampler.\n\nThe Metropolis-Hastings algorithm\nLet \\(\\pi(\\theta_1, \\theta_2)\\) be the target distribution. The Metropolis-Hastings algorithm proceeds:\n\nUpdate \\(\\theta_1\\):\n\n\nsample \\(\\theta_1^* \\sim J_1(\\theta_1 | \\theta_1^{(s)}, \\theta_2^{(s)})\\);\ncompute the acceptance ratio\n\n\\[\nr = \\frac{\\pi(\\theta_1^*, \\theta_2^{(s)})}{\\pi(\\theta_1^{(s)}, \\theta_2^{(s)})} \\times \\frac{J_1(\\theta_1^{(s)}| \\theta_1^*, \\theta_2^{(s)})}{\nJ_1(\\theta_1^{*}| \\theta_1^{(s)}, \\theta_2^{(s)})\n}\n\\]\n\nset \\(\\theta_1^{(s+1)}\\) to \\(\\theta_1^*\\) with probability \\(\\min(1, r)\\), otherwise set \\(\\theta_1^{(s+1)}\\) to \\(\\theta_1^{(s)}\\).\n\n\nRepeat the above to update \\(\\theta_2\\) given \\(\\theta_1^{(s+1)}\\).\n\n\n\n\n\n\n\nImportant\n\n\n\nHere, the proposal distribution \\(J\\) need not be symmetric!"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#trace-plot",
    "href": "notes/lec15-MetropolisHastings.html#trace-plot",
    "title": "Metropolis-Hastings",
    "section": "trace plot",
    "text": "trace plot"
  },
  {
    "objectID": "notes/lec15-MetropolisHastings.html#code",
    "href": "notes/lec15-MetropolisHastings.html#code",
    "title": "Metropolis-Hastings",
    "section": "code",
    "text": "code\n\ndf = data.frame(theta = THETA)\ndf %>%\n  ggplot(aes(x = 1:nrow(df), y = theta)) + \n  geom_line() +\n  theme_bw() +\n  labs(x = \"iteration\", y = TeX(\"\\\\theta\"))\n\n\n\n\n\n\n\n\n\n\nLet’s look at how various \\(\\delta\\) let us sample the target:\n\n\\(\\delta = 1\\)\\(\\delta = 4\\)\\(\\delta = 0.1\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 2\nThe fledglings of female song sparrows. To begin, let’s load the data.\n\n\nLoad the data\nyX = structure(c(3, 1, 1, 2, 0, 0, 6, 3, 4, 2, 1, 6, 2, 3, 3, 4, 7, \n2, 2, 1, 1, 3, 5, 5, 0, 2, 1, 2, 6, 6, 2, 2, 0, 2, 4, 1, 2, 5, \n1, 2, 1, 0, 0, 2, 4, 2, 2, 2, 2, 0, 3, 2, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, \n1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, \n2, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 5, \n5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 6, 1, 1, 9, 9, 1, 1, 1, 1, 1, 1, \n1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 25, 25, 16, 16, 16, 16, 16, \n16, 16, 16, 16, 16, 16, 16, 25, 16, 16, 16, 16, 25, 25, 25, 25, \n9, 9, 9, 9, 9, 9, 9, 36, 1, 1), .Dim = c(52L, 4L), .Dimnames = list(\n    NULL, c(\"fledged\", \"intercept\", \"age\", \"age2\")))\n\n\n\nyX %>%\n  head(n = 5)\n\n     fledged intercept age age2\n[1,]       3         1   3    9\n[2,]       1         1   3    9\n[3,]       1         1   1    1\n[4,]       2         1   1    1\n[5,]       0         1   1    1\n\ny = yX[,1]\nX = yX[,-1]\n\nThe model:\n\\[\n\\begin{aligned}\nY | X &\\sim \\text{Poisson}(\\exp[ \\beta^T \\boldsymbol{x}])\\\\\n\\beta &\\sim MVN(0, \\sqrt{10})\n\\end{aligned}\n\\]\nThe Metropolis algorithm with\n\\[\nJ(\\beta | \\beta^{(s)}) = MVN(\\beta^{(s)}, \\hat{\\sigma}^2(X^TX)^{-1})\n\\]\nwhere \\(\\hat{\\sigma}^2\\) is the sample variance of \\(\\{\\log(y_1 + 1/2), \\ldots, \\log(y_n + 1/2)\\}\\).\n\n\n\n\n\n\nNote\n\n\n\n\nThis variance is intuitively useful choice for \\(\\delta\\) since the posterior variance would be \\(\\sigma^2 (X^TX)^{-1}\\) in a normal regression problem.\nWe use \\(\\log(y + 1/2)\\) instead of \\(\\log y\\) because if \\(y=0\\), \\(\\log y\\) would be \\(-\\infty\\).\n\n\n\n\nset.seed(360)\nn = length(y)\np = ncol(X)\n\npmn.beta = rep(0, p) # prior mean beta\npsd.beta = rep(10, p) # prior sd beta\n\nvar.prop = var(log(y + 1/2)) * solve(t(X) %*% X) # proposal variance\n\nS = 10000\nbeta = rep(0, p); accepts = 0\nBETA = matrix(0, nrow = S, ncol = p)\nset.seed(1)\n\nfor (s in 1:S) {\n  # multivariate proposal of beta\n  beta.p = t(rmvnorm(1, beta, var.prop))\n  \n  # log ratio\n  lhr = sum(dpois(y, exp(X %*%beta.p), log = TRUE)) -\n    sum(dpois(y, exp(X %*% beta), log = TRUE)) + \n    sum(dnorm(beta.p, pmn.beta, psd.beta, log = TRUE)) -\n    sum(dnorm(beta, pmn.beta, psd.beta, log = TRUE)) \n  \n  if (log(runif(1)) < lhr) {\n    beta = beta.p ; accepts = accepts + 1\n  }\n  \n  BETA[s,] = beta\n}\n\nThe acceptance ratio is 0.428\nLet’s examine convergence.\n\ntrace plotsplot codeESSacf\n\n\n\n\n\n\n\n\n\n\nvalue = c(BETA[,1], BETA[,2], BETA[,3])\nn = length(value)\nbeta = c(rep(\"beta1\", n/3), rep(\"beta2\", n/3), rep(\"beta3\", n/3))\ndf = data.frame(value = value,\n                beta = beta) \n\ndf %>%\n  ggplot(aes(x = 1:nrow(df), y = value)) + \n  geom_line() + \n  facet_wrap(~ beta, scales = \"free_x\") +\n  theme_bw() +\n  labs(x = \"iteration\")\n\n\n\n\n# effective sample size\nBETA %>%\n  apply(2, effectiveSize)\n\n[1] 867.4750 825.6214 692.0495\n\n\n\n\n\npar(mfrow=c(1,3))\nacf(BETA[,1])\nacf(BETA[,2])\nacf(BETA[,3])"
  },
  {
    "objectID": "quizzes/quiz07.html",
    "href": "quizzes/quiz07.html",
    "title": "Quiz 7",
    "section": "",
    "text": "Exercise 1\nTRUE or FALSE: The Metropolis-Hastings algorithm is a generalization of both the Metropolis algorithm and the Gibbs sampler.\n\n\nExercise 2\nTRUE or FALSE: the Metropolis-Hastings algorithm requires symmetric proposal \\(J(\\theta^* | \\theta^{(s)})\\).\n\n\nExercise 3\nTRUE or FALSE: for any valid proposal distribution J, \\(J(\\theta^* | \\theta^{(1)}, \\ldots, \\theta^{(s)}) = J(\\theta^* | \\theta^{(s)})\\).\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#execise",
    "href": "slides/lab9-MH-MCMC.html#execise",
    "title": "MCMC Practice",
    "section": "Execise",
    "text": "Execise\nSuppose the target distribution we wish to sample from is given by probability mass function\n\\[\n\\pi(\\theta) = \\theta / w \\text{ for } \\theta \\in \\{1, 2, \\ldots 6\\}\n\\]\nin words, we wish to roll a die with probability \\(1/w\\) of landing on face 1, \\(2/w\\) of landing on face 2, etc.\n\nWrite a Metropolis algorithm to approximate the target distribution using a proposal \\(J(\\theta = j | \\theta^{(s)} = i) = 1/6\\) for all \\(j\\), i.e. propose a new state \\(j\\) uniformly. Run your Markov chain for \\(S=10000\\) states.\nPlot a histogram of the output. Does the plot match your intuition?\nCompare the estimated probabilities of each outcome to the truth (compute \\(w\\)).\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#exercise",
    "href": "slides/lab9-MH-MCMC.html#exercise",
    "title": "MCMC Practice",
    "section": "Exercise",
    "text": "Exercise\nSuppose the target distribution we wish to sample from is given by probability mass function\n\\[\n\\pi(\\theta) = \\theta / w \\text{ for } \\theta \\in \\{1, 2, \\ldots 6\\}\n\\]\nin words, we wish to roll a die with probability \\(1/w\\) of landing on face 1, \\(2/w\\) of landing on face 2, etc.\n\nWrite a Metropolis algorithm to approximate the target distribution using a proposal \\(J(\\theta = j | \\theta^{(s)} = i) = 1/6\\) for all \\(j\\), i.e. propose a new state \\(j\\) uniformly. Run your Markov chain for \\(S=10000\\) states.\nThe Metropolis algorithm requires a symmetric proposal \\(J\\). Explain why this proposal is symmetric.\nPlot a histogram of the output. Does the plot match your intuition?\nCompare the estimated probabilities of each outcome to the truth (compute \\(w\\))."
  },
  {
    "objectID": "slides/lab9-MH-MCMC.html#exercise-1",
    "href": "slides/lab9-MH-MCMC.html#exercise-1",
    "title": "MCMC Practice",
    "section": "Exercise",
    "text": "Exercise\nMetropolis-Hastings lets us work with non-symmetric proposals. Re-write the algorithm of the previous exercise using the non-symmetric proposal \\(J(\\theta = j | \\theta^{(s)} = i)\\) such that\n\\[\n\\theta  = \\begin{cases}\n1 & \\text{ with prob } & 0.05\\\\\n2 & \\text{ with prob } & 0.15\\\\\n3 & \\text{ with prob } & 0.2\\\\\n4 & \\text{ with prob } & 0.15\\\\\n5 & \\text{ with prob } & 0.15\\\\\n6 & \\text{ with prob } & 0.3\\\\\n\\end{cases}\n\\]\n\ncompare your results to that those of the previous exercise. In particular, compare the ESS of \\(\\theta\\) in each chain. Which do you prefer? How might you explain this difference in ESS?\n\n\n\n\n\n\n🔗 sta360-fa23.github.io"
  },
  {
    "objectID": "notes/lec16-MCMC-and-HMC.html",
    "href": "notes/lec16-MCMC-and-HMC.html",
    "title": "MCMC and HMC",
    "section": "",
    "text": "See libraries used in these notes\nlibrary(tidyverse)\nlibrary(latex2exp)\nlibrary(mvtnorm)\nlibrary(coda)"
  },
  {
    "objectID": "notes/lec16-MCMC-and-HMC.html#ergodic-theorem",
    "href": "notes/lec16-MCMC-and-HMC.html#ergodic-theorem",
    "title": "MCMC and HMC",
    "section": "Ergodic theorem",
    "text": "Ergodic theorem\nUnder what conditions does Metropolis-Hastings MCMC work?\nErgodic theorem: If \\(\\{\\theta^{(1)}, \\theta^{(2)}, \\ldots \\}\\) is an irreducible, aperiodic and recurrent Markov chain, then there is a unique probability distribution \\(\\pi\\) such that as \\(s \\rightarrow \\infty\\),\n\n\\(Pr(\\theta^{(s)} \\in \\mathcal{A}) \\rightarrow \\pi(\\mathcal{A})\\) for any set \\(\\mathcal{A}\\);\n\\(\\frac{1}{S} \\sum g(\\theta^{(s)}) \\rightarrow \\int g(x) \\pi(x) dx\\)."
  },
  {
    "objectID": "notes/lec16-MCMC-and-HMC.html#definitions",
    "href": "notes/lec16-MCMC-and-HMC.html#definitions",
    "title": "MCMC and HMC",
    "section": "Definitions",
    "text": "Definitions\n\nstationary distribution\n\\(\\pi\\) is called the stationary distribution of the Markov chain because if \\(\\theta^{(s)} \\sim \\pi\\) and \\(\\theta^{(s+1)}\\) is generated from the Markov chain starting at \\(\\theta^{(s)}\\), then \\(Pr(\\theta^{(s+1)} \\in \\mathcal{A}) = \\pi(\\mathcal{A})\\).\n\n\nirreducible\nA chain is reducible if the state-space can be divided into non-overlapping sets (due to some \\(J\\)). In practice, the proposal \\(J(\\theta^* | \\theta^{(s)})\\) needs to let us go from any value of \\(\\theta\\) to any other, eventually.\n\n\naperiodic\nWe want our Markov chain to be aperiodic. A value \\(\\theta\\) is said to be periodic with period \\(k>1\\) if it can only be visited every \\(k\\)th iteration. A Markov chain without periodic states is aperiodic.\n\n\nrecurrent\nA value \\(\\theta\\) is recurrent if we are guaranteed to return to it eventually.\n\noffline\nProof that the stationary distribution \\(\\pi(\\theta)\\) is the same as our target distribution \\(p_0(\\theta)\\)."
  },
  {
    "objectID": "notes/lec16-MCMC-and-HMC.html#hamiltonian-monte-carlo",
    "href": "notes/lec16-MCMC-and-HMC.html#hamiltonian-monte-carlo",
    "title": "MCMC and HMC",
    "section": "Hamiltonian Monte Carlo",
    "text": "Hamiltonian Monte Carlo\nHamiltonian Monte Carlo (HMC) is a proposal mechanism \\(J(\\theta | \\theta^{(s)})\\), that uses Hamiltonian dynamics to generate proposals that are far away from the current state of the chain with high acceptance probability. These proposals are subsequently accepted or rejected according to the Metropolis-Hastings acceptance ratio.\n\nMotivation: the banana target\n\ntarget distributioncodeplot\n\n\nposterior:\n\\[\np(\\theta | y_1, \\ldots y_n) \\propto \\underbrace{\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1)}_{\\text{likelihood}} \\cdot \\underbrace{\\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)}_{\\text{priors}}\n\\]\n\n\n\nlogPosterior = function(theta) {\n  c = theta[1] + (theta[2] ^ 2)\n  logLikelihood = sum(dnorm(y, mean = c, sd = 1, log = TRUE))\n  logPrior = dnorm(theta[1], 0, 1, log = TRUE) +\n    dnorm(theta[2], 0, 1, log = TRUE)\n    return(logLikelihood + logPrior)\n}\n\n\n# simulated data y\nset.seed(360)\nn = 30\ntheta1 = .75\ntheta2 = .5\ny = rnorm(n, (theta1 + (theta2^2)), 1)\ny\n\n [1]  2.4374945977  1.3225732383  0.7957033706  0.0009050433  0.9624998552\n [6]  0.2485689217  0.3494050797  0.8481528753  0.1619672883  1.5373043843\n[11]  1.9319327323  2.1723549678  0.5916180759  1.5788760946 -0.2521989302\n[16] -0.0956751145  2.1896602700  2.7428271328 -0.8507334992 -0.3434228915\n[21]  0.7158629051  2.9076884521 -0.0258688807  2.7880781640  1.3319085255\n[26]  1.0734242350  1.3910936322  1.8806039555  1.6171004720  1.4077704842\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion: What about this target distribution could challenge a Metropolis sampler with \\(J(\\theta_i | \\theta_i^{(s)}) = \\text{normal}(\\theta_i, \\delta)\\)?\nLet’s try it out.\n\nMetropolis samplertrajectoryESSautocorrelationtrace plots\n\n\n\n# sample from posterior\nset.seed(360)\ntheta1 = 0 # starting point\ntheta2 = 0\nTHETA1 = NULL # empty object to save iterations in\nTHETA2 = NULL\nS = 10000 # number of iterations\ndelta = .5 # proposal variance\naccept1 = 0 # keep track of acceptance rate\naccept2 = 0\n\nfor (s in 1:S) {\n  # log everything for numerical stability #\n  \n  ### generate proposal 1 and compute ratio r ###\n  theta1star = rnorm(1, mean = theta1, sd = delta) \n  log.r = logPosterior(c(theta1star, theta2)) - \n    logPosterior(c(theta1, theta2))\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) < log.r)  {\n    theta1 = theta1star\n    accept1 = accept1 + 1 \n  }\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n  \n   ### generate proposal 2 and compute ratio r ###\n  theta2star = rnorm(1, mean = theta2, sd = delta) \n  log.r = logPosterior(c(theta1, theta2star)) - \n    logPosterior(c(theta1, theta2))\n  \n  ### accept or reject proposal and add to chain ###\n  if(log(runif(1)) < log.r)  {\n    theta2 = theta2star\n    accept2 = accept2 + 1 \n  }\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n}\n\n\n\n\n\n\n\n\n\n\n\neffectiveSize(THETA1)\n\n    var1 \n38.28904 \n\neffectiveSize(THETA2)\n\n    var1 \n40.44706 \n\n\n\n\n\npar(mfrow=c(1,2))\nacf(THETA1)\nacf(THETA2)\n\n\n\n\n\n\n\nN = length(THETA1)\ndf = data.frame(theta = c(THETA1, THETA2), \n                theta_id = c(rep(\"theta1\", N), rep(\"theta2\", N)),\n                step = rep(1:N, 2))  \ndf %>%\n  ggplot(aes(x = step, y = theta, col = theta_id)) + \n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ theta_id) +\n  labs(x = \"iteration\", y = \"value\")\n\n\n\n\n\n\n\n\n\nHamiltonian dynamics\nIf we view the state of the Markov chain as the physical location of a particle in parameter space, then what happens if we pretend the laws of physics apply to this physical space? More specifically, let’s suppose the steps of the Markov chain are akin to a particle moving through Euclidean space and obeying Hamiltonian dynamics. The Hamiltonian of a system specifies its total energy.\nTo be a Hamiltonian system, the particle will have:\n\na location (the position in parameter space)\npotential energy\nkinetic energy\n\nQuestion: we are going to match up the negative log-posterior to either the kinetic energy or the potential energy. Which one do you think makes more sense? Why does the negative sign make sense when we think of what we are trying to do in the context of this as a physical system?\nMathematically, let \\(q\\) be the position of the particle (in parameter space) and let \\(p\\) be the momentum of the particle. So \\(q\\) and \\(p\\) are both vectors of the same dimension (the dimension of parameter space). Then the Hamiltonian, \\(H = U(q) + K(p)\\) where \\(U(q)\\) and \\(K(p)\\) are the potential and kinetic energy respectively. We will let \\(U(q) = - \\log \\pi(q)\\) where \\(\\pi(q)\\) is our target distribution.\nHamilton’s equations of motion state\n\\[\n\\begin{aligned}\n\\frac{dq_i}{dt} &= \\frac{\\partial{H}}{\\partial p_i}\\\\\n\\frac{dp_i}{dt} &= -\\frac{\\partial{H}}{\\partial q_i}\\\\\n\\end{aligned}\n\\]\nThese equations govern the motion of the particle. They let us map from the state at time \\(t\\) to the state of the system at any future state \\(t + s\\). And it can be shown that \\(\\frac{d}{dt} H = 0\\). In words, energy is conserved.\n\n\n\n\n\n\nImportant\n\n\n\nThe above equations elicit a need to compute \\(-\\frac{\\partial H}{\\partial q_i} = \\frac{\\partial}{\\partial q_i} \\log \\pi(q)\\), i.e. the gradient of the log-posterior.\n\n\nA simple choice of kinetic energy is:\n\\[\nK(p) = \\frac{1}{2} p^T M^{-1}p\n\\]\nwhere \\(M\\) is called the “mass matrix”.\nQuestion: this looks like the log of a kernel you know… which one?\n\n\nAlgorithm\nFundamentally, HMC is just the Metropolis algorithm with proposals generated via Hamiltonian dynamics. The equations of motion above describe a vector field, and if we integrate them numerically, we can follow the flow through joint space of parameters and momentum.\nLet’s tackle the banana target from before in an example.\n\ngradientHMC codetrajectoryESSautocorrelationtrace plots\n\n\nWe need the gradient of the log-posterior\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\theta_1} \\log \\pi(\\theta_1, \\theta_2 | y_1,\\ldots y_n) &=\n\\frac{\\partial}{\\partial\\theta_1} \\log\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1) \\cdot \\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)\\\\\n&= n \\bar{y} - n \\theta_1 - n\\theta_2^2 - \\theta_1\\\\\n&= n\\bar{y} - n\\theta_2^2 - \\theta_1(n + 1)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial\\theta_2} \\log \\pi(\\theta_1, \\theta_2 | y_1,\\ldots y_n) &=\n\\frac{\\partial}{\\partial\\theta_2} \\log\\prod_{i=1}^n \\text{dnorm}(y_i; \\theta_1 + \\theta_2^2, 1) \\cdot \\text{dnorm}(\\theta_1; 0, 1) \\text{dnorm}(\\theta_2; 0, 1)\\\\\n&= 2n \\bar{y} \\theta_2 - 2 n \\theta_1 \\theta_2 - 2n\\theta_2^3\n\\end{aligned}\n\\]\n\nn = length(y)\nybar = mean(y)\ngradLogPosterior = function(theta) {\n  gradTheta1 = (n*ybar) - (n * (theta[2]^2)) - ((theta[1])*(n+1))\n  gradTheta2 = (2 * n * ybar * theta[2]) - (2 * n * theta[1] * theta[2]) - \n    (2 * n * (theta[2]^3))\n  return(c(gradTheta1, gradTheta2))\n}\n\n\n\nHMC code block below from Neal (2011), see the references\n\nHMC = function (U, grad_U, epsilon, L, current_q) { \n  q = current_q\n  p = rnorm(length(q), 0, 1) # independent standard normal variates\n  current_p = p\n  # Make a half step for momentum at the beginning\n  p = p - epsilon * grad_U(q) / 2\n  # Alternate full steps for position and momentum\n  for (i in 1:L) {\n    # Make a full step for the position\n    q = q + epsilon * p\n    # Make a full step for the momentum, except at end of trajectory\n    if (i != L)\n      p = p - epsilon * grad_U(q)\n  }\n  # Make a half step for momentum at the end.\n  p = p - epsilon * grad_U(q) / 2\n  # Negate momentum at end of trajectory to make the proposal symmetric\n  p = -p\n  # Evaluate potential and kinetic energies at start and end of trajectory\n  current_U = U(current_q)\n  current_K = sum(current_p ^ 2) / 2\n  proposed_U = U(q)\n  proposed_K = sum(p ^ 2) / 2\n  # Accept or reject the state at end of trajectory, returning either\n  # the position at the end of the trajectory or the initial position\n  if (runif(1) < exp(current_U - proposed_U + current_K - proposed_K))\n  {\n    return (q) # accept\n  }\n  else\n  {\n    return (current_q) # reject\n  }\n}\n\n\nset.seed(360)\nS = 10000\nTHETA1 = NULL\nTHETA2 = NULL\ncurrent_q = c(1, 0)\n\nU = function(theta) {\n  return(-1 * logPosterior(theta))\n}\n\ngradU = function(theta) {\n  return(-1 * gradLogPosterior(theta))\n}\n\n\nfor(s in 1:S) {\n  current_q = HMC(U, gradU, epsilon = .05, L = 10, current_q)\n  theta1 = current_q[1]\n  theta2 = current_q[2]\n  THETA1 = c(THETA1, theta1)\n  THETA2 = c(THETA2, theta2)\n}\n\n\n\n\ntrajectoryDF = data.frame(theta1 = THETA1, theta2 = THETA2) %>%\n  head(n = 300)\n\nTHETA %>%\n  ggplot(aes(x = theta1, y = theta2)) +\n  stat_density_2d(aes(fill = ..level..), geom = \"polygon\") +\n  theme_bw() +\n  labs(x = TeX(\"$\\\\theta_1$\"), y = TeX(\"$\\\\theta_2$\"), fill = \"density\",\n       title = \"Trajectory of first 300 steps of HMC\") +\n  geom_path(data = trajectoryDF, color = \"orange\", alpha = 0.6, size=0.5)\n\n\n\n\n\n\n\neffectiveSize(THETA1)\n\n    var1 \n765.6712 \n\neffectiveSize(THETA2)\n\n    var1 \n301.3347 \n\n\n\n\n\npar(mfrow=c(1,2))\nacf(THETA1)\nacf(THETA2)\n\n\n\n\n\n\n\nN = length(THETA1)\ndf = data.frame(theta = c(THETA1, THETA2), \n                theta_id = c(rep(\"theta1\", N), rep(\"theta2\", N)),\n                step = rep(1:N, 2))  \ndf %>%\n  ggplot(aes(x = step, y = theta, col = theta_id)) + \n  geom_line() +\n  theme_bw() +\n  facet_wrap(~ theta_id) +\n  labs(x = \"iteration\", y = \"value\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\nGreat it works… but how do I know this is producing an ergodic Markov chain?\n\nMichael Betancourt’s conceptual intro\nRadford Neal’s comprehensive book chapter\nHow is it implemented in stan?"
  }
]